# RAG 評估儀表板評分規則

本文檔整理了儀表板「📊 評估總覽」中四個核心指標的計算方式以及建議的表現區間，協助解讀分數與追蹤優化成效。

## 1. 綜合評分（📈）
- **資料來源**：`RAGEvaluatorV2.evaluate_answer` 內的 `final_score` 計算（`rag_evaluation_two_models_v2.py:483-486`）。
- **計分方式**：
  - 對每一題，先取得三層分數：
    - 關鍵詞覆蓋率（第一層）
    - 語義相似度（第二層，若停用則為 0）
    - GPT overall（第三層，若未輸入則為 0）
  - 依照當下設定的權重 `weights = {"keyword", "semantic", "gpt"}` 進行加權平均：
    
    ```text
    final_score = keyword_score * weight_keyword
                + semantic_score * weight_semantic
                + gpt_overall    * weight_gpt
    ```
  - 儀表板顯示的是所有題目 `final_score` 的平均值，並在下方列出優化版與原始版的平均分差。
- **評分區間建議**：
  - ≥ 85 分：表現優秀，三層評估整體達標。
  - 70 – 84.9 分：尚可，建議檢視語義或 GPT 評分較弱的題目。
  - < 70 分：需優先改善，可由關鍵詞與語義層逐項修正。

## 2. 關鍵詞覆蓋率（🎯）
- **資料來源**：`calculate_keyword_coverage` 函式（`rag_evaluation_two_models_v2.py:236-270`）。
- **計分方式**：
  1. 由「應回答之詞彙」欄位抽取關鍵詞，保留常見專有名詞並搭配 jieba 分詞。
  2. 判斷回答是否包含關鍵詞或同義詞（`_is_similar_term`）。
  3. 命中關鍵詞數 ÷ 應回答關鍵詞總數 × 100，即為每題的覆蓋率。
  4. 儀表板呈現所有題目的平均值，並顯示優化版本相較原始版的平均提升幅度。
- **評分區間建議**：
  - ≥ 90%：優秀，核心資訊幾乎完整覆蓋。
  - 75% – 89.9%：普通，建議補齊缺漏關鍵詞或調整用詞。
  - < 75%：不足，需檢查回答是否遺漏多數要求資訊。

## 3. 語義相似度（🔤）
- **資料來源**：`calculate_semantic_similarity` 函式（`rag_evaluation_two_models_v2.py:292-333`）與 Sentence-Transformers 模型。
- **計分方式**：
  1. 使用 `paraphrase-multilingual-MiniLM-L12-v2` 將「應回答內容」與實際回答轉換為向量（採 CPU 推論，避免設備限制）。
  2. 透過 NumPy 計算兩向量的餘弦相似度。
  3. 乘以 100 後限制於 0–100 分區間。
  4. 儀表板顯示所有題目的平均語義分數及優化版相對原始版的平均差值。
- **評分區間建議**：
  - ≥ 80%：語義高度吻合，回答內容與參考資訊一致。
  - 60% – 79.9%：語義有部分偏差，可檢查是否出現多餘或缺漏的敘述。
  - < 60%：語義契合度低，常見於回答過度延伸或主題偏離。
- **備註**：若語義模型未成功載入，系統會自動停用該層並顯示 0 分，此時應先確認 `sentence-transformers` 與 `torch` 套件是否安裝。

## 4. GPT 評分（🤖）
- **資料來源**：在「GPT 人工評審」頁籤貼入 ChatGPT JSON 後，儀表板將 `overall` 分數存入 `st.session_state.gpt_responses_*`（`streamlit_dashboard_v2_with_manual_gpt.py:639-727`），並於總覽中彙整。
- **計分方式**：
  1. 對於完成人工評審的題目，記錄手動輸入的 `overall` 分數。
  2. 在總覽卡片中計算：
     - 若優化版已有 GPT 評分，顯示其平均值。
     - 若僅有原始版，顯示原始版平均值，以利檢視目前可用的人工結果。
     - 若兩版本皆有評分，計算平均差異並顯示上升/下降箭頭。
  3. 底部保留「已評審題數：x/總題數」以掌握人工覆蓋率。
- **評分區間建議**：
  - ≥ 90 分：GPT 人工評價極佳，回答品質全面達標。
  - 75 – 89.9 分：表現良好，可再針對 GPT 評語中的建議微調內容。
  - < 75 分：需改善，通常代表回答在完整性、準確性或忠實度上存在明顯缺口。

## 5. 改善幅度（↑ / ↓ 數值）
- 綜合評分、關鍵詞覆蓋率、語義相似度、GPT 評分皆會顯示優化版相較原始版的平均差值。
- 正值（↑）代表優化後整體績效提升；負值（↓）則需檢視優化內容是否造成退步。
- 對 GPT 指標而言，僅在「原始版 + 優化版」都完成人工評審時計算差值，避免部分樣本造成誤判。

---

以上規則可協助快速解讀評分儀表板，也可在優化流程中當作檢核表，逐項提升關鍵詞命中、語義一致性與人工審核品質。

## 6. 實際案例解析：語義相似度為何偏低？

以下以儀表板中常見的「問題 1：工作許可證申請資料項目有哪些？」為例，說明三個指標在實際情境下的差異。

### 6.1 參考資料與兩個回答版本

- **參考內容（應回答之詞彙）**：
  ```text
  1. 申請日期
  2. 施工轄區
  3. 包商名稱
  4. 工作時段
  5. 作業內容及詳細位置描述
  6. 承包商現場負責人簽名
  7. 承包商現場工安業務主管簽名
  8. 施工人員簽名
  ```
- **原始版本回答（節錄）**：採段落敘述，除逐項列出資料外，額外補充「不同作業類型…還需進行安全檢查」等說明。
- **優化版本回答（節錄）**：同樣以段落說明，但為每一項補上用途、注意事項，以及安全監測等延伸描述。

### 6.2 為什麼語義分數〈關鍵詞分數仍高〉

| 指標               | 原始版本 | 優化版本 | 原因解析 |
|--------------------|---------|---------|-----------|
| 關鍵詞覆蓋率       | 100%    | 100%    | 八個關鍵詞名稱都出現在回答中（或命中了同義詞），因此覆蓋率滿分。 |
| 語義相似度         | 67.3%   | 75.6%   | 比對的是整句語意：參考資料只有「包商名稱」這種名詞片語，回答則是「註明承攬該作業的廠商名稱」等長句，向量距離拉大；延伸段落（安全檢查、目的）也降低相似度。 |
| GPT 人工評分（overall） | 99      | 98      | 人工評審認為內容完整且正確，額外補充也合理，因此仍給出接近滿分的主觀評價。 |

### 6.3 儀表板「🔤 語義分析」頁籤觀察到的差異

- **缺漏關鍵詞**：兩個版本皆無缺漏，證明語義分數偏低不是因為漏掉必填項目。
- **低相似度參考句**：
  - 例如「包商名稱」在原始版的相似度只有 23%，優化版也僅 30%。因為參考資料是短語，而回答是「註明承攬該作業的廠商名稱」，語句長度與措辭差異造成餘弦相似度偏低。
  - 「作業內容及詳細位置描述」在優化版得到 43.9%，主因是回答加入「具體說明」以外的背景、目的與安全注意事項，與原始短語不完全對齊。

### 6.4 建議的寫法與調整方向

- **要提升語義分數**：讓回答格式更貼近參考資料，例如直接列出「1. 申請日期」「2. 施工轄區」…，或在短語後面加一句簡短補充（如「施工轄區：填寫作業所在區域」）。
- **保留補充資訊**：若仍想保留延伸說明，可將主要列表放最前面、額外補充另起段落。這樣核心短語與參考內容對齊，語義分數就會接近 90% 以上，同時兼顧說明完整度。
- **與 GPT 評分對照**：儀表板會同時顯示 GPT 人工評分，若語義分數低但 GPT 評價高，表示「資訊正確但句型不同」。可依用途選擇是否調整語氣或保留補充文字。

透過上述案例，可以清楚看出「關鍵詞／語義／GPT」三種分數的著眼點不同，也能在儀表板的語義分析分頁直接檢視缺漏與相似句，幫助團隊討論如何改寫回答。
