import pandas as pd
import re
import jieba
import numpy as np
from typing import List, Dict, Tuple
from datetime import datetime

class RAGEvaluatorSingleModel:
    """å–®ä¸€æ¨¡å‹è©•ä¼°å™¨ - é©ç”¨æ–¼åªæœ‰ä¸€å€‹AIå›ç­”çš„æ¸¬è©¦æª”æ¡ˆ"""
    
    def __init__(self, excel_path: str):
        """åˆå§‹åŒ–è©•ä¼°å™¨"""
        self.df = pd.read_csv(excel_path) if excel_path.endswith('.csv') else pd.read_excel(excel_path)
        jieba.setLogLevel(20)
        
    def extract_keywords(self, text: str) -> List[str]:
        """å¾å›ç­”é‡é»ä¸­æå–é—œéµè©"""
        if pd.isna(text):
            return []
        
        # ç§»é™¤ç·¨è™Ÿå’Œæ¨™é»ç¬¦è™Ÿ
        text = re.sub(r'\d+\.', '', text)
        text = re.sub(r'[ï¼š:ã€‚ï¼Œ,ã€\(\)]', ' ', text)
        
        # æå–é—œéµè©
        keywords = []
        
        # ä¿ç•™å®Œæ•´çš„å°ˆæœ‰åè©
        special_terms = [
            "è·æ¥­ç½å®³", "é€šå ±", "å‹å‹•æª¢æŸ¥æ©Ÿæ§‹", "æ­»äº¡ç½å®³",
            "æ°¸ä¹…å…¨å¤±èƒ½", "ä½é™¢æ²»ç™‚", "8å°æ™‚", "è·æ¥­å®‰å…¨è¡›ç”Ÿ",
            "è·æ¥­ç—…", "è·æ¥­å‚·å®³", "å¾©å·¥", "è£œåŠ©"
        ]
        
        for term in special_terms:
            if term in text:
                keywords.append(term)
                text = text.replace(term, " ")
        
        # ä½¿ç”¨jiebaåˆ†è©è™•ç†å‰©é¤˜æ–‡å­—
        words = jieba.cut(text)
        for word in words:
            if len(word.strip()) > 1 and word.strip() not in keywords:
                keywords.append(word.strip())
        
        return keywords
    
    def calculate_coverage_score(self, answer: str, keywords: List[str]) -> Tuple[float, List[str]]:
        """è¨ˆç®—é—œéµè©è¦†è“‹ç‡è©•åˆ†"""
        if pd.isna(answer) or not keywords:
            return 0.0, []
        
        matched_keywords = []
        answer_lower = answer.lower()
        
        for keyword in keywords:
            if keyword.lower() in answer_lower:
                matched_keywords.append(keyword)
            elif self._is_similar_term(keyword, answer):
                matched_keywords.append(keyword)
        
        coverage_rate = len(matched_keywords) / len(keywords) if keywords else 0
        return coverage_rate * 100, matched_keywords
    
    def _is_similar_term(self, keyword: str, answer: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦æœ‰ç›¸ä¼¼è©å½™"""
        synonyms = {
            "è·ç½": ["è·æ¥­ç½å®³", "è·æ¥­å‚·å®³", "å·¥å‚·"],
            "é€šå ±": ["å ±å‘Š", "ç”³å ±", "å‘ŠçŸ¥"],
            "è£œåŠ©": ["è£œè²¼", "æ´¥è²¼", "çµ¦ä»˜"],
            "å¾©å·¥": ["è¿”å›å·¥ä½œ", "é‡è¿”è·å ´", "å›åˆ°å´—ä½"]
        }
        
        answer_lower = answer.lower()
        for key, similar_terms in synonyms.items():
            if key in keyword:
                for term in similar_terms:
                    if term in answer_lower:
                        return True
        return False
    
    def evaluate_faithfulness(self, answer: str, keywords: List[str]) -> Tuple[float, str]:
        """è©•ä¼°å›ç­”çš„å¿ èª åº¦ - ä½¿ç”¨èˆ‡åŸå§‹ç³»çµ±ç›¸åŒçš„ç®—æ³•"""
        if pd.isna(answer):
            return 100, "ç„¡å›ç­”ï¼ˆç„¡è™›æ§‹é¢¨éšªï¼‰"
        
        # åˆ†æå›ç­”å…§å®¹
        analysis = {
            "extra_numbers": [],
            "extra_dates": [],
            "reasonable_explanations": 0
        }
        
        # å°‡å›ç­”åˆ†å¥
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', answer)
        total_sentences = len([s for s in sentences if s.strip()])
        
        # æª¢æŸ¥æ•¸å­—å’Œæ—¥æœŸ
        numbers_in_answer = re.findall(r'\b\d+\b', answer)
        dates_in_answer = re.findall(r'\d{4}[-/]\d{1,2}[-/]\d{1,2}|\d{1,2}[-/]\d{1,2}', answer)
        
        # æª¢æŸ¥åƒè€ƒç­”æ¡ˆä¸­çš„æ•¸å­—å’Œæ—¥æœŸ
        reference_text = ' '.join(keywords)
        numbers_in_ref = re.findall(r'\b\d+\b', reference_text)
        dates_in_ref = re.findall(r'\d{4}[-/]\d{1,2}[-/]\d{1,2}|\d{1,2}[-/]\d{1,2}', reference_text)
        
        # æ‰¾å‡ºé¡å¤–çš„æ•¸å­—å’Œæ—¥æœŸ
        analysis["extra_numbers"] = [n for n in numbers_in_answer if n not in numbers_in_ref]
        analysis["extra_dates"] = [d for d in dates_in_answer if d not in dates_in_ref]
        
        # è©•ä¼°å¿ èª åº¦
        faithfulness_score = 100  # å¾æ»¿åˆ†é–‹å§‹
        
        # æª¢æŸ¥æ˜¯å¦æœ‰è§£é‡‹æ€§è©å½™ï¼ˆé€™äº›é€šå¸¸æ˜¯åˆç†çš„ï¼‰
        explanation_words = ["å› æ­¤", "æ‰€ä»¥", "åŒ…æ‹¬", "ä¾‹å¦‚", "å¦‚", "å³", "ä¹Ÿå°±æ˜¯", "ç”¨æ–¼", "ç›®çš„"]
        explanation_count = sum(1 for word in explanation_words if word in answer)
        
        # æ ¹æ“šé¡å¤–å…§å®¹æ‰£åˆ†
        if len(analysis["extra_numbers"]) > 2 or len(analysis["extra_dates"]) > 1:
            faithfulness_score = 50
            desc = "ä¸­åº¦å¿ å¯¦ï¼šåŒ…å«å¤šå€‹æœªæåŠçš„å…·é«”æ•¸æ“š"
        elif len(analysis["extra_numbers"]) > 0 or len(analysis["extra_dates"]) > 0:
            faithfulness_score = 75
            desc = "é«˜åº¦å¿ å¯¦ï¼šåŒ…å«å°‘é‡é¡å¤–æ•¸æ“š"
        elif explanation_count > 3:
            faithfulness_score = 90
            desc = "æ¥µé«˜å¿ å¯¦ï¼šæ·»åŠ åˆç†è§£é‡‹"
        else:
            faithfulness_score = 100
            desc = "å®Œå…¨å¿ å¯¦ï¼šå®Œå…¨åŸºæ–¼åŸå§‹è³‡æ–™"
        
        return faithfulness_score, desc
    
    def evaluate_all(self) -> pd.DataFrame:
        """åŸ·è¡Œè©•ä¼°"""
        # æ·»åŠ è©•ä¼°æ¬„ä½
        self.df['é—œéµè©åˆ—è¡¨'] = ""
        self.df['è¦†è“‹ç‡åˆ†æ•¸'] = 0
        self.df['åŒ¹é…é—œéµè©'] = ""
        self.df['å¿ èª åº¦åˆ†æ•¸'] = 100
        self.df['å¿ èª åº¦æè¿°'] = ""
        self.df['ç¶œåˆè©•åˆ†'] = 0
        
        # å°æ¯ä¸€è¡Œé€²è¡Œè©•ä¼°
        for idx, row in self.df.iterrows():
            # æå–é—œéµè©
            keywords = self.extract_keywords(row['å›ç­”é‡é»'])
            self.df.at[idx, 'é—œéµè©åˆ—è¡¨'] = ', '.join(keywords)
            
            # è¨ˆç®—è¦†è“‹ç‡
            coverage_score, matched = self.calculate_coverage_score(row['UPGPTå›ç­”'], keywords)
            self.df.at[idx, 'è¦†è“‹ç‡åˆ†æ•¸'] = coverage_score
            self.df.at[idx, 'åŒ¹é…é—œéµè©'] = ', '.join(matched)
            
            # è©•ä¼°å¿ èª åº¦ï¼ˆä½¿ç”¨èˆ‡åŸå§‹ç³»çµ±ç›¸åŒçš„æ–¹æ³•ï¼‰
            faithfulness_score, faithfulness_desc = self.evaluate_faithfulness(
                row['UPGPTå›ç­”'], keywords
            )
            self.df.at[idx, 'å¿ èª åº¦åˆ†æ•¸'] = faithfulness_score
            self.df.at[idx, 'å¿ èª åº¦æè¿°'] = faithfulness_desc
            
            # è¨ˆç®—ç¶œåˆè©•åˆ†
            self.df.at[idx, 'ç¶œåˆè©•åˆ†'] = (coverage_score * 0.5 + faithfulness_score * 0.5)
        
        return self.df
    
    def generate_summary(self) -> Dict:
        """ç”Ÿæˆè©•ä¼°æ‘˜è¦"""
        summary = {
            'ç¸½é¡Œæ•¸': len(self.df),
            'å¹³å‡è¦†è“‹ç‡': self.df['è¦†è“‹ç‡åˆ†æ•¸'].mean(),
            'å¹³å‡å¿ èª åº¦': self.df['å¿ èª åº¦åˆ†æ•¸'].mean(),
            'å¹³å‡ç¶œåˆè©•åˆ†': self.df['ç¶œåˆè©•åˆ†'].mean(),
            'é«˜è¦†è“‹ç‡é¡Œæ•¸': (self.df['è¦†è“‹ç‡åˆ†æ•¸'] >= 80).sum(),
            'é«˜å¿ èª åº¦é¡Œæ•¸': (self.df['å¿ èª åº¦åˆ†æ•¸'] >= 90).sum(),
            'å„ªç§€ç¶œåˆè©•åˆ†é¡Œæ•¸': (self.df['ç¶œåˆè©•åˆ†'] >= 85).sum()
        }
        return summary
    
    def save_results(self, output_path: str):
        """å„²å­˜è©•ä¼°çµæœ"""
        # å»ºç«‹æ™‚é–“æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"{output_path}_è©•ä¼°çµæœ_{timestamp}.xlsx"
        
        # é¸æ“‡è¦è¼¸å‡ºçš„æ¬„ä½
        output_columns = ['ç·¨è™Ÿ', 'å•é¡Œ', 'å›ç­”é‡é»', 'UPGPTå›ç­”', 
                         'é—œéµè©åˆ—è¡¨', 'è¦†è“‹ç‡åˆ†æ•¸', 'åŒ¹é…é—œéµè©',
                         'å¿ èª åº¦åˆ†æ•¸', 'å¿ èª åº¦æè¿°', 'ç¶œåˆè©•åˆ†']
        
        output_df = self.df[output_columns].copy()
        
        # å¯«å…¥Excel
        with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:
            output_df.to_excel(writer, sheet_name='è©•ä¼°çµæœ', index=False)
            
            # æ·»åŠ æ‘˜è¦é 
            summary_df = pd.DataFrame([self.generate_summary()]).T
            summary_df.columns = ['æ•¸å€¼']
            summary_df.to_excel(writer, sheet_name='è©•ä¼°æ‘˜è¦')
            
            # æ ¼å¼è¨­å®š
            workbook = writer.book
            worksheet = writer.sheets['è©•ä¼°çµæœ']
            
            # è¨­å®šåˆ—å¯¬
            worksheet.set_column('A:A', 10)   # ç·¨è™Ÿ
            worksheet.set_column('B:B', 40)   # å•é¡Œ
            worksheet.set_column('C:D', 60)   # å›ç­”å…§å®¹
            worksheet.set_column('E:J', 20)   # è©•åˆ†æ¬„ä½
        
        print(f"âœ… è©•ä¼°çµæœå·²å„²å­˜è‡³: {output_file}")
        return output_file

# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    evaluator = RAGEvaluatorSingleModel("AIæŒ‡å°å“¡-è·ç½ä¿è­·QA-æ¸¬è©¦é¡Œç›®.csv")
    results = evaluator.evaluate_all()
    summary = evaluator.generate_summary()
    
    print("\nğŸ“Š è©•ä¼°æ‘˜è¦:")
    for key, value in summary.items():
        if isinstance(value, float):
            print(f"   {key}: {value:.2f}")
        else:
            print(f"   {key}: {value}")
    
    # å„²å­˜çµæœ
    evaluator.save_results("è·ç½ä¿è­·QA")