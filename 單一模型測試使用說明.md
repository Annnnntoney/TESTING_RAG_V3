# 單一模型測試使用說明

## 🎯 概述
您的測試檔案「AI指導員-職災保護QA-測試題目.csv」與現有系統的欄位格式不同。這裡提供三個解決方案來處理這個問題。

## 📋 欄位差異
- **您的檔案**: 編號 | 問題 | 回答重點 | UPGPT回答
- **系統預期**: 序號 | 測試資料 | 測試問題 | 應回答之詞彙 | 4個不同方法的回答

## 🔧 解決方案

### 方案一：轉換檔案格式（最簡單）
將您的檔案轉換為系統相容格式，然後使用原始儀表板。

```bash
# 執行轉換程式
python convert_test_file.py

# 轉換後的檔案會儲存在 test_data/ 資料夾
# 然後使用原始儀表板
streamlit run streamlit_dashboard.py
```

**優點**: 
- 可以使用完整的原始儀表板功能
- 可以比較不同方法（雖然都是同樣的回答）

**缺點**:
- 需要先轉換檔案
- 四個方法會顯示相同結果

### 方案二：使用單一模型評估器（推薦）
直接評估您的單一模型測試結果。

```bash
# 方法A: 使用新的儀表板介面
streamlit run streamlit_single_model_dashboard.py

# 方法B: 直接執行評估程式
python rag_evaluation_single_model.py
```

**優點**:
- 專為單一模型設計
- 無需轉換檔案
- 提供針對性的評估指標

**缺點**:
- 無法比較多個方法

### 方案三：手動調整檔案
您可以手動編輯CSV檔案，添加缺少的欄位。

1. 將「編號」改為「序號」
2. 新增「測試資料」欄位（填入"職災保護QA"）
3. 將「問題」改為「測試問題」
4. 將「回答重點」改為「應回答之詞彙」
5. 複製「UPGPT回答」到4個不同的方法欄位

## 💡 建議

**快速測試**: 使用方案二的單一模型儀表板
```bash
streamlit run streamlit_single_model_dashboard.py
```

**完整功能**: 使用方案一轉換後再使用原始儀表板
```bash
python convert_test_file.py
streamlit run streamlit_dashboard.py
```

## 📊 評估指標說明
- **覆蓋率**: AI回答涵蓋了多少關鍵詞（越高越好）
- **忠誠度**: AI回答是否忠實於原始資料，沒有額外虛構（越高越好）
- **綜合評分**: 覆蓋率和忠誠度的平均值

## 🚀 快速開始
1. 確保已安裝相依套件：`pip install -r requirements.txt`
2. 選擇一個方案執行
3. 檢視評估結果