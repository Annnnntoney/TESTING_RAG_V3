# RAG評估系統權重係數說明

## 權重選擇的理論基礎

### 學術研究現況
根據文獻調查，目前學術界對於RAG評估中的幻覺懲罰權重並無統一標準。不同研究採用不同方法：

1. **RAGAS Framework**
   - Faithfulness = 支持的聲明數 / 總聲明數
   - 沒有使用懲罰權重，而是直接計算比例

2. **DeepEval**
   - 使用補數方式：Score = 1 - HallucinationScore
   - 相當於100%權重的懲罰

3. **Contrastive Decoding**
   - penalty_alpha = 0.6（用於多樣性，非幻覺懲罰）

## 我們的權重選擇理由

### 原始設計（權重 = 0.5）
```
綜合評分 = 覆蓋率 - (幻覺分數 × 0.5)
```

**選擇理由**：
- 平衡準確性和完整性
- 50%權重表示幻覺和遺漏同等重要
- 簡單直觀，易於理解

### 改進版設計（權重 = 0.3）
```
綜合評分 = 覆蓋率 - (幻覺分數 × 0.3)
```

**調整理由**：
1. **實務考量**：RAG系統常會加入解釋性內容以提高可讀性
2. **避免過度懲罰**：原始權重導致綜合評分過低（8-25%）
3. **參考業界實踐**：許多商用系統容許適度的擴充說明

## 建議的權重選擇框架

根據不同應用場景，建議使用不同權重：

### 1. 高精確度場景（醫療、法律、金融）
```python
權重 = 0.7-1.0  # 嚴格懲罰幻覺
綜合評分 = 覆蓋率 - (幻覺分數 × 0.8)
```
- 錯誤資訊可能造成嚴重後果
- 寧可資訊不完整，也不要錯誤

### 2. 一般商業應用
```python
權重 = 0.4-0.6  # 平衡準確與完整
綜合評分 = 覆蓋率 - (幻覺分數 × 0.5)
```
- 平衡資訊準確性和完整性
- 允許合理的補充說明

### 3. 教育或解釋性應用
```python
權重 = 0.2-0.4  # 寬容解釋性內容
綜合評分 = 覆蓋率 - (幻覺分數 × 0.3)
```
- 重視理解和學習
- 允許更多解釋和範例

## 實證調整方法

### 步驟1：基準測試
1. 收集人工評分的測試集
2. 測試不同權重的相關性
3. 選擇與人工評分最相關的權重

### 步驟2：ROC曲線分析
```python
import numpy as np
from sklearn.metrics import roc_curve, auc

# 測試不同權重
weights = np.arange(0.1, 1.1, 0.1)
best_auc = 0
best_weight = 0.5

for w in weights:
    scores = coverage - (hallucination * w)
    fpr, tpr, _ = roc_curve(human_labels, scores)
    roc_auc = auc(fpr, tpr)
    
    if roc_auc > best_auc:
        best_auc = roc_auc
        best_weight = w
```

### 步驟3：A/B測試
- 在實際應用中測試不同權重
- 收集使用者反饋
- 選擇滿意度最高的權重

## 結論

權重的選擇應該：
1. 基於具體應用場景
2. 通過實證數據驗證
3. 持續根據反饋調整
4. 文檔化選擇理由

目前我們選擇0.3是基於：
- 初步測試顯示原始評分過低
- 需要容許RAG系統的解釋性內容
- 可根據後續反饋進一步調整