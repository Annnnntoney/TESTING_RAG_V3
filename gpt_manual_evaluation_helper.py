"""
GPT äººå·¥è©•å¯©è¼”åŠ©å·¥å…·
====================

åŠŸèƒ½ï¼š
1. ç”Ÿæˆæ¨™æº–åŒ–çš„ GPT è©•å¯© prompt
2. æ”¯æ´æ‰¹æ¬¡ç”Ÿæˆï¼ˆä¸€æ¬¡ç”Ÿæˆå¤šé¡Œï¼‰
3. æ”¯æ´å–®é¡Œæ·±åº¦åˆ†æ
4. è‡ªå‹•æ ¼å¼åŒ–çµæœè¼¸å…¥æ¬„ä½

ä½¿ç”¨æ–¹å¼ï¼š
1. åŸ·è¡Œæ­¤è…³æœ¬ç”Ÿæˆ prompts
2. è¤‡è£½ prompt åˆ° ChatGPT
3. å°‡ ChatGPT çš„å›æ‡‰è²¼å›æŒ‡å®šæ¬„ä½
4. ç³»çµ±è‡ªå‹•è§£æä¸¦æ•´åˆåˆ°è©•ä¼°çµæœ

ç‰ˆæœ¬ï¼š2.0
"""

import pandas as pd
import json
import os
from datetime import datetime
from typing import List, Dict, Tuple


class GPTManualEvaluationHelper:
    """GPT äººå·¥è©•å¯©è¼”åŠ©å·¥å…·"""

    def __init__(self, excel_path: str):
        """
        åˆå§‹åŒ–è¼”åŠ©å·¥å…·

        åƒæ•¸:
            excel_path: Excel æˆ– CSV æª”æ¡ˆè·¯å¾‘
        """
        if excel_path.lower().endswith('.csv'):
            self.df = pd.read_csv(excel_path, encoding='utf-8-sig')
        else:
            self.df = pd.read_excel(excel_path)

        print(f"âœ… å·²è¼‰å…¥ {len(self.df)} å€‹å•é¡Œ")

    def generate_single_prompt(
        self,
        question_idx: int,
        version: str = "optimized"
    ) -> str:
        """
        ç”Ÿæˆå–®é¡Œè©•å¯© prompt

        åƒæ•¸:
            question_idx: å•é¡Œç´¢å¼•ï¼ˆå¾ 0 é–‹å§‹ï¼‰
            version: "original" æˆ– "optimized"

        è¿”å›:
            æ ¼å¼åŒ–çš„ prompt æ–‡å­—
        """
        if question_idx >= len(self.df):
            return f"âŒ éŒ¯èª¤: å•é¡Œç´¢å¼• {question_idx} è¶…å‡ºç¯„åœï¼ˆå…± {len(self.df)} é¡Œï¼‰"

        row = self.df.iloc[question_idx]

        # è‡ªå‹•åµæ¸¬æ¬„ä½åç¨±
        answer_col = self._detect_answer_column(version)

        if not answer_col:
            return f"âŒ éŒ¯èª¤: ç„¡æ³•æ‰¾åˆ° {version} ç‰ˆæœ¬çš„å›ç­”æ¬„ä½"

        question = row['æ¸¬è©¦å•é¡Œ']
        reference_keywords = row['æ‡‰å›ç­”ä¹‹è©å½™']
        answer = row[answer_col]

        prompt = f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ RAG ç³»çµ±è©•ä¼°å°ˆå®¶ã€‚è«‹è©•ä¼°ä»¥ä¸‹å›ç­”çš„å“è³ªã€‚

ã€å•é¡Œ {row['åºè™Ÿ']}ã€‘
{question}

ã€æ‡‰åŒ…å«çš„é—œéµè³‡è¨Šã€‘
{reference_keywords}

ã€å¯¦éš›å›ç­”ï¼ˆ{version}ç‰ˆæœ¬ï¼‰ã€‘
{answer}

è«‹å¾ä»¥ä¸‹å››å€‹ç¶­åº¦è©•åˆ†ï¼ˆ0-100åˆ†ï¼‰ï¼š

1. **ç›¸é—œæ€§ (Relevance)**: å›ç­”æ˜¯å¦åˆ‡é¡Œã€æ˜¯å¦å›æ‡‰äº†å•é¡Œæ ¸å¿ƒ
2. **å®Œæ•´æ€§ (Completeness)**: æ˜¯å¦åŒ…å«äº†æ‰€æœ‰å¿…è¦çš„é—œéµè³‡è¨Š
3. **æº–ç¢ºæ€§ (Accuracy)**: è³‡è¨Šæ˜¯å¦æ­£ç¢ºã€ç„¡æ˜é¡¯éŒ¯èª¤
4. **å¿ å¯¦åº¦ (Faithfulness)**: æ˜¯å¦åŸºæ–¼åŸå§‹è³‡æ–™ï¼Œç„¡è™›æ§‹æˆ–éåº¦æ¨æ¸¬

è«‹ä»¥ JSON æ ¼å¼å›å‚³è©•åˆ†çµæœï¼ˆè«‹å‹™å¿…ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼‰ï¼š
{{
  "question_id": {row['åºè™Ÿ']},
  "relevance": <0-100>,
  "completeness": <0-100>,
  "accuracy": <0-100>,
  "faithfulness": <0-100>,
  "overall": <0-100>,
  "reasoning": "ç°¡çŸ­èªªæ˜è©•åˆ†ç†ç”±ï¼ˆ2-3å¥è©±ï¼‰",
  "strengths": ["å„ªé»1", "å„ªé»2"],
  "weaknesses": ["ç¼ºé»1", "ç¼ºé»2"]
}}

æ³¨æ„ï¼š
- overall æ˜¯å››å€‹ç¶­åº¦çš„å¹³å‡åˆ†æ•¸
- è«‹ä¿æŒå®¢è§€å…¬æ­£
- é‡é»è©•ä¼°å›ç­”æ˜¯å¦å®Œæ•´ä¸”å¿ å¯¦æ–¼åŸå§‹è³‡æ–™
"""

        return prompt

    def generate_batch_prompts(
        self,
        start_idx: int = 0,
        end_idx: int = None,
        version: str = "optimized",
        questions_per_batch: int = 5
    ) -> List[str]:
        """
        ç”Ÿæˆæ‰¹æ¬¡è©•å¯© prompts

        åƒæ•¸:
            start_idx: èµ·å§‹å•é¡Œç´¢å¼•
            end_idx: çµæŸå•é¡Œç´¢å¼•ï¼ˆNone è¡¨ç¤ºåˆ°æœ€å¾Œï¼‰
            version: "original" æˆ– "optimized"
            questions_per_batch: æ¯å€‹ prompt åŒ…å«çš„å•é¡Œæ•¸é‡

        è¿”å›:
            prompt åˆ—è¡¨
        """
        if end_idx is None:
            end_idx = len(self.df)

        prompts = []

        for batch_start in range(start_idx, end_idx, questions_per_batch):
            batch_end = min(batch_start + questions_per_batch, end_idx)
            batch_prompts = []

            for idx in range(batch_start, batch_end):
                single_prompt = self.generate_single_prompt(idx, version)
                batch_prompts.append(single_prompt)

            # å°‡æ‰¹æ¬¡ prompts åˆä½µ
            combined_prompt = "\n\n" + "="*80 + "\n\n".join(batch_prompts)
            prompts.append(combined_prompt)

        return prompts

    def save_prompts_to_file(
        self,
        output_folder: str = "gpt_prompts",
        version: str = "optimized"
    ):
        """
        å°‡æ‰€æœ‰ prompts å„²å­˜åˆ°æª”æ¡ˆ

        åƒæ•¸:
            output_folder: è¼¸å‡ºè³‡æ–™å¤¾è·¯å¾‘
            version: "original" æˆ– "optimized"
        """
        if not os.path.exists(output_folder):
            os.makedirs(output_folder)

        # ç”Ÿæˆæ‰€æœ‰ prompts
        for idx in range(len(self.df)):
            prompt = self.generate_single_prompt(idx, version)

            # å„²å­˜åˆ°æª”æ¡ˆ
            filename = f"{output_folder}/prompt_q{idx+1}_{version}.txt"
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(prompt)

        print(f"âœ… å·²ç”Ÿæˆ {len(self.df)} å€‹ prompt æª”æ¡ˆåˆ° {output_folder}/")

        # ç”Ÿæˆæ‰¹æ¬¡æª”æ¡ˆï¼ˆ5 é¡Œä¸€çµ„ï¼‰
        batch_prompts = self.generate_batch_prompts(version=version, questions_per_batch=5)

        for batch_idx, batch_prompt in enumerate(batch_prompts):
            filename = f"{output_folder}/batch_prompt_{batch_idx+1}_{version}.txt"
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(batch_prompt)

        print(f"âœ… å·²ç”Ÿæˆ {len(batch_prompts)} å€‹æ‰¹æ¬¡ prompt æª”æ¡ˆ")

    def parse_gpt_response(self, response_text: str) -> Dict:
        """
        è§£æ ChatGPT çš„ JSON å›æ‡‰

        åƒæ•¸:
            response_text: ChatGPT çš„å›æ‡‰æ–‡å­—

        è¿”å›:
            è§£æå¾Œçš„å­—å…¸
        """
        try:
            # å˜—è©¦ç›´æ¥è§£æ JSON
            result = json.loads(response_text)
            return result
        except json.JSONDecodeError:
            # å¦‚æœç›´æ¥è§£æå¤±æ•—ï¼Œå˜—è©¦å¾æ–‡å­—ä¸­æå– JSON
            import re
            json_match = re.search(r'\{[^}]+\}', response_text, re.DOTALL)
            if json_match:
                try:
                    result = json.loads(json_match.group())
                    return result
                except:
                    pass

            return {
                "error": "ç„¡æ³•è§£æ GPT å›æ‡‰",
                "raw_response": response_text
            }

    def create_response_template(
        self,
        output_file: str = "gpt_responses_template.xlsx"
    ):
        """
        å»ºç«‹ GPT å›æ‡‰è¼¸å…¥æ¨¡æ¿

        é€™å€‹ Excel æª”æ¡ˆè®“æ‚¨å¯ä»¥ï¼š
        1. çœ‹åˆ°æ¯å€‹å•é¡Œçš„ prompt
        2. è²¼ä¸Š ChatGPT çš„ JSON å›æ‡‰
        3. ç³»çµ±è‡ªå‹•è§£æä¸¦æ•´åˆ

        åƒæ•¸:
            output_file: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        template_data = []

        for idx, row in self.df.iterrows():
            template_data.append({
                'åºè™Ÿ': row['åºè™Ÿ'],
                'æ¸¬è©¦å•é¡Œ': row['æ¸¬è©¦å•é¡Œ'],
                'æ‡‰å›ç­”ä¹‹è©å½™': row['æ‡‰å›ç­”ä¹‹è©å½™'],
                'Prompt_å·²ç”Ÿæˆ': "è«‹åƒè€ƒ gpt_prompts è³‡æ–™å¤¾",
                'ChatGPTå›æ‡‰_åŸå§‹ç‰ˆæœ¬': "",  # ç•™ç©ºè®“ä½¿ç”¨è€…å¡«å…¥
                'ChatGPTå›æ‡‰_å„ªåŒ–ç‰ˆæœ¬': "",  # ç•™ç©ºè®“ä½¿ç”¨è€…å¡«å…¥
                'ç‹€æ…‹': "å¾…è©•ä¼°"
            })

        template_df = pd.DataFrame(template_data)

        with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:
            template_df.to_excel(writer, sheet_name='GPTè©•å¯©å›æ‡‰', index=False)

            workbook = writer.book
            worksheet = writer.sheets['GPTè©•å¯©å›æ‡‰']

            # è¨­å®šæ¬„å¯¬
            worksheet.set_column('A:A', 8)   # åºè™Ÿ
            worksheet.set_column('B:B', 40)  # æ¸¬è©¦å•é¡Œ
            worksheet.set_column('C:C', 50)  # æ‡‰å›ç­”ä¹‹è©å½™
            worksheet.set_column('D:D', 30)  # Prompt
            worksheet.set_column('E:E', 80)  # ChatGPTå›æ‡‰_åŸå§‹
            worksheet.set_column('F:F', 80)  # ChatGPTå›æ‡‰_å„ªåŒ–
            worksheet.set_column('G:G', 15)  # ç‹€æ…‹

            # è¨­å®šæ¨™é¡Œæ ¼å¼
            header_format = workbook.add_format({
                'bold': True,
                'bg_color': '#4CAF50',
                'font_color': 'white',
                'border': 1
            })

            for col_num, value in enumerate(template_df.columns.values):
                worksheet.write(0, col_num, value, header_format)

        print(f"âœ… å·²å»ºç«‹ GPT å›æ‡‰è¼¸å…¥æ¨¡æ¿: {output_file}")
        print(f"\nğŸ“ ä½¿ç”¨æ­¥é©Ÿ:")
        print(f"1. æ‰“é–‹ {output_file}")
        print(f"2. å¾ gpt_prompts/ è³‡æ–™å¤¾è¤‡è£½ prompt åˆ° ChatGPT")
        print(f"3. å°‡ ChatGPT çš„ JSON å›æ‡‰è²¼åˆ°å°æ‡‰æ¬„ä½")
        print(f"4. åŸ·è¡Œ integrate_gpt_responses() æ•´åˆçµæœ")

    def integrate_gpt_responses(
        self,
        response_file: str = "gpt_responses_template.xlsx",
        output_file: str = None
    ):
        """
        æ•´åˆ GPT è©•å¯©å›æ‡‰åˆ°è©•ä¼°çµæœ

        åƒæ•¸:
            response_file: åŒ…å« GPT å›æ‡‰çš„ Excel æª”æ¡ˆ
            output_file: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼ˆNone å‰‡è‡ªå‹•å‘½åï¼‰
        """
        # è®€å–å›æ‡‰æª”æ¡ˆ
        response_df = pd.read_excel(response_file)

        print(f"ğŸ”„ é–‹å§‹æ•´åˆ GPT è©•å¯©çµæœ...")

        # åˆå§‹åŒ–çµæœæ¬„ä½
        self.df['GPT_RELEVANCE_ORIGINAL'] = 0
        self.df['GPT_COMPLETENESS_ORIGINAL'] = 0
        self.df['GPT_ACCURACY_ORIGINAL'] = 0
        self.df['GPT_FAITHFULNESS_ORIGINAL'] = 0
        self.df['GPT_OVERALL_ORIGINAL'] = 0
        self.df['GPT_REASONING_ORIGINAL'] = ""

        self.df['GPT_RELEVANCE_OPTIMIZED'] = 0
        self.df['GPT_COMPLETENESS_OPTIMIZED'] = 0
        self.df['GPT_ACCURACY_OPTIMIZED'] = 0
        self.df['GPT_FAITHFULNESS_OPTIMIZED'] = 0
        self.df['GPT_OVERALL_OPTIMIZED'] = 0
        self.df['GPT_REASONING_OPTIMIZED'] = ""

        success_count = 0
        error_count = 0

        # è§£ææ¯ä¸€è¡Œçš„ GPT å›æ‡‰
        for idx, row in response_df.iterrows():
            # è§£æåŸå§‹ç‰ˆæœ¬å›æ‡‰
            if pd.notna(row['ChatGPTå›æ‡‰_åŸå§‹ç‰ˆæœ¬']) and row['ChatGPTå›æ‡‰_åŸå§‹ç‰ˆæœ¬'].strip():
                parsed = self.parse_gpt_response(row['ChatGPTå›æ‡‰_åŸå§‹ç‰ˆæœ¬'])

                if 'error' not in parsed:
                    self.df.at[idx, 'GPT_RELEVANCE_ORIGINAL'] = parsed.get('relevance', 0)
                    self.df.at[idx, 'GPT_COMPLETENESS_ORIGINAL'] = parsed.get('completeness', 0)
                    self.df.at[idx, 'GPT_ACCURACY_ORIGINAL'] = parsed.get('accuracy', 0)
                    self.df.at[idx, 'GPT_FAITHFULNESS_ORIGINAL'] = parsed.get('faithfulness', 0)
                    self.df.at[idx, 'GPT_OVERALL_ORIGINAL'] = parsed.get('overall', 0)
                    self.df.at[idx, 'GPT_REASONING_ORIGINAL'] = parsed.get('reasoning', '')
                    success_count += 1
                else:
                    error_count += 1
                    print(f"âš ï¸ å•é¡Œ {row['åºè™Ÿ']} åŸå§‹ç‰ˆæœ¬è§£æå¤±æ•—")

            # è§£æå„ªåŒ–ç‰ˆæœ¬å›æ‡‰
            if pd.notna(row['ChatGPTå›æ‡‰_å„ªåŒ–ç‰ˆæœ¬']) and row['ChatGPTå›æ‡‰_å„ªåŒ–ç‰ˆæœ¬'].strip():
                parsed = self.parse_gpt_response(row['ChatGPTå›æ‡‰_å„ªåŒ–ç‰ˆæœ¬'])

                if 'error' not in parsed:
                    self.df.at[idx, 'GPT_RELEVANCE_OPTIMIZED'] = parsed.get('relevance', 0)
                    self.df.at[idx, 'GPT_COMPLETENESS_OPTIMIZED'] = parsed.get('completeness', 0)
                    self.df.at[idx, 'GPT_ACCURACY_OPTIMIZED'] = parsed.get('accuracy', 0)
                    self.df.at[idx, 'GPT_FAITHFULNESS_OPTIMIZED'] = parsed.get('faithfulness', 0)
                    self.df.at[idx, 'GPT_OVERALL_OPTIMIZED'] = parsed.get('overall', 0)
                    self.df.at[idx, 'GPT_REASONING_OPTIMIZED'] = parsed.get('reasoning', '')
                    success_count += 1
                else:
                    error_count += 1
                    print(f"âš ï¸ å•é¡Œ {row['åºè™Ÿ']} å„ªåŒ–ç‰ˆæœ¬è§£æå¤±æ•—")

        # è¨ˆç®—æ”¹å–„å¹…åº¦
        self.df['GPT_IMPROVEMENT'] = (
            self.df['GPT_OVERALL_OPTIMIZED'] - self.df['GPT_OVERALL_ORIGINAL']
        )

        # å„²å­˜çµæœ
        if output_file is None:
            output_file = f"è©•ä¼°çµæœ_å«GPT_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"

        self.df.to_excel(output_file, index=False)

        print(f"\nâœ… æ•´åˆå®Œæˆï¼")
        print(f"  - æˆåŠŸè§£æ: {success_count} å€‹å›æ‡‰")
        print(f"  - è§£æå¤±æ•—: {error_count} å€‹å›æ‡‰")
        print(f"  - çµæœå·²å„²å­˜åˆ°: {output_file}")

        return self.df

    def _detect_answer_column(self, version: str) -> str:
        """è‡ªå‹•åµæ¸¬å›ç­”æ¬„ä½åç¨±"""
        columns = self.df.columns.tolist()

        if version == "original":
            for col in columns:
                if 'å‘é‡' in col and 'åŸå§‹' in col:
                    return col
                elif 'ANSWER_ORIGINAL' in col:
                    return col
        elif version == "optimized":
            for col in columns:
                if ('æ™ºæ…§' in col or 'æ–‡æª”' in col) and 'å½™æ•´' in col:
                    return col
                elif 'ANSWER_OPTIMIZED' in col:
                    return col

        return None

    def generate_comparison_prompt(self, question_idx: int) -> str:
        """
        ç”ŸæˆåŸå§‹ç‰ˆæœ¬ vs å„ªåŒ–ç‰ˆæœ¬çš„å°æ¯”è©•å¯© prompt

        é€™å€‹ prompt è®“ ChatGPT ä¸€æ¬¡è©•ä¼°å…©å€‹ç‰ˆæœ¬ä¸¦ç›´æ¥æ¯”è¼ƒ
        """
        if question_idx >= len(self.df):
            return f"âŒ éŒ¯èª¤: å•é¡Œç´¢å¼• {question_idx} è¶…å‡ºç¯„åœ"

        row = self.df.iloc[question_idx]

        original_col = self._detect_answer_column("original")
        optimized_col = self._detect_answer_column("optimized")

        if not original_col or not optimized_col:
            return "âŒ éŒ¯èª¤: ç„¡æ³•æ‰¾åˆ°å›ç­”æ¬„ä½"

        prompt = f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ RAG ç³»çµ±è©•ä¼°å°ˆå®¶ã€‚è«‹æ¯”è¼ƒè©•ä¼°ä»¥ä¸‹å…©å€‹ç‰ˆæœ¬çš„å›ç­”å“è³ªã€‚

ã€å•é¡Œ {row['åºè™Ÿ']}ã€‘
{row['æ¸¬è©¦å•é¡Œ']}

ã€æ‡‰åŒ…å«çš„é—œéµè³‡è¨Šã€‘
{row['æ‡‰å›ç­”ä¹‹è©å½™']}

ã€ç‰ˆæœ¬ Aï¼šåŸå§‹ç‰ˆæœ¬ã€‘
{row[original_col]}

ã€ç‰ˆæœ¬ Bï¼šå„ªåŒ–ç‰ˆæœ¬ã€‘
{row[optimized_col]}

è«‹å°å…©å€‹ç‰ˆæœ¬åˆ†åˆ¥è©•åˆ†ï¼Œä¸¦æä¾›å°æ¯”åˆ†æï¼š

è«‹ä»¥ JSON æ ¼å¼å›å‚³ï¼ˆè«‹å‹™å¿…ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼‰ï¼š
{{
  "question_id": {row['åºè™Ÿ']},
  "version_a": {{
    "relevance": <0-100>,
    "completeness": <0-100>,
    "accuracy": <0-100>,
    "faithfulness": <0-100>,
    "overall": <0-100>
  }},
  "version_b": {{
    "relevance": <0-100>,
    "completeness": <0-100>,
    "accuracy": <0-100>,
    "faithfulness": <0-100>,
    "overall": <0-100>
  }},
  "comparison": {{
    "improvement": <Bçš„overall - Açš„overall>,
    "better_version": "A" or "B",
    "key_differences": ["å·®ç•°1", "å·®ç•°2", "å·®ç•°3"],
    "recommendation": "å„ªåŒ–å»ºè­°"
  }},
  "reasoning": "æ•´é«”è©•ä¼°èªªæ˜ï¼ˆ3-5å¥è©±ï¼‰"
}}
"""

        return prompt


# ä½¿ç”¨ç¯„ä¾‹å’Œå‘½ä»¤è¡Œä»‹é¢
if __name__ == "__main__":
    import sys

    print("=" * 80)
    print("GPT äººå·¥è©•å¯©è¼”åŠ©å·¥å…· v2.0")
    print("=" * 80)

    # æª¢æŸ¥æ˜¯å¦æä¾›äº†æª”æ¡ˆè·¯å¾‘
    if len(sys.argv) < 2:
        excel_file = input("\nè«‹è¼¸å…¥ Excel æª”æ¡ˆè·¯å¾‘ï¼ˆæˆ–ç›´æ¥æŒ‰ Enter ä½¿ç”¨é è¨­è·¯å¾‘ï¼‰: ").strip()
        if not excel_file:
            excel_file = "test_data/AIæŒ‡å°å“¡_æ¸¬è©¦è…³æœ¬_v2æ‹·è².xlsx"
    else:
        excel_file = sys.argv[1]

    try:
        helper = GPTManualEvaluationHelper(excel_file)

        print("\nè«‹é¸æ“‡æ“ä½œ:")
        print("1. ç”Ÿæˆæ‰€æœ‰ prompts åˆ°æª”æ¡ˆ")
        print("2. é¡¯ç¤ºå–®é¡Œ promptï¼ˆå¯è¤‡è£½åˆ° ChatGPTï¼‰")
        print("3. ç”Ÿæˆå°æ¯”è©•å¯© prompt")
        print("4. å»ºç«‹ GPT å›æ‡‰è¼¸å…¥æ¨¡æ¿")
        print("5. æ•´åˆ GPT å›æ‡‰åˆ°è©•ä¼°çµæœ")

        choice = input("\nè«‹è¼¸å…¥é¸é … (1-5): ").strip()

        if choice == "1":
            version = input("ç‰ˆæœ¬ (original/optimized, é è¨­ optimized): ").strip() or "optimized"
            helper.save_prompts_to_file(version=version)

        elif choice == "2":
            idx = int(input(f"å•é¡Œç·¨è™Ÿ (1-{len(helper.df)}): ")) - 1
            version = input("ç‰ˆæœ¬ (original/optimized, é è¨­ optimized): ").strip() or "optimized"
            prompt = helper.generate_single_prompt(idx, version)
            print("\n" + "=" * 80)
            print("è«‹è¤‡è£½ä»¥ä¸‹å…§å®¹åˆ° ChatGPT:")
            print("=" * 80)
            print(prompt)
            print("=" * 80)

        elif choice == "3":
            idx = int(input(f"å•é¡Œç·¨è™Ÿ (1-{len(helper.df)}): ")) - 1
            prompt = helper.generate_comparison_prompt(idx)
            print("\n" + "=" * 80)
            print("è«‹è¤‡è£½ä»¥ä¸‹å…§å®¹åˆ° ChatGPT:")
            print("=" * 80)
            print(prompt)
            print("=" * 80)

        elif choice == "4":
            helper.create_response_template()
            helper.save_prompts_to_file(version="original")
            helper.save_prompts_to_file(version="optimized")

        elif choice == "5":
            response_file = input("GPT å›æ‡‰æª”æ¡ˆè·¯å¾‘ï¼ˆé è¨­ gpt_responses_template.xlsxï¼‰: ").strip()
            if not response_file:
                response_file = "gpt_responses_template.xlsx"

            result_df = helper.integrate_gpt_responses(response_file)
            print(f"\nâœ… æ•´åˆå®Œæˆï¼å…±è™•ç† {len(result_df)} å€‹å•é¡Œ")

        else:
            print("ç„¡æ•ˆçš„é¸é …")

    except FileNotFoundError:
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°æª”æ¡ˆ {excel_file}")
    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {str(e)}")
