"""
RAG è©•ä¼°å„€è¡¨æ¿ v2.0 - æ•´åˆäººå·¥ GPT è©•å¯©
==========================================

ç‰¹è‰²åŠŸèƒ½ï¼š
1. ä¸‰å±¤è©•ä¼°æ¶æ§‹ï¼ˆé—œéµè©ã€èªç¾©ã€GPTï¼‰
2. GPT Prompt ç”Ÿæˆå™¨ï¼ˆå¯ç›´æ¥è¤‡è£½åˆ° ChatGPTï¼‰
3. GPT å›æ‡‰è²¼ä¸Šå€ï¼ˆäººå·¥è¼¸å…¥è©•åˆ†ï¼‰
4. æ‰€æœ‰æŒ‡æ¨™åŒæ™‚å‘ˆç¾ã€å³æ™‚æ›´æ–°
5. å®Œæ•´çš„è³‡æ–™è¼¸å…¥è¼¸å‡ºæ”¯æ´

ç‰ˆæœ¬ï¼š2.0 with Manual GPT
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from datetime import datetime
import json
import os
import re
import ast
from pathlib import Path
from rag_evaluation_two_models_v2 import RAGEvaluatorV2
from evaluation_history_manager import EvaluationHistoryManager

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="RAG è©•ä¼°å„€è¡¨æ¿ v2.0 - æ•´åˆäººå·¥ GPT è©•å¯©",
    #page_icon="ğŸ†š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ– session state
if 'comparison_results' not in st.session_state:
    st.session_state.comparison_results = None
if 'evaluator_instance' not in st.session_state:
    st.session_state.evaluator_instance = None
if 'current_question_idx' not in st.session_state:
    st.session_state.current_question_idx = 0
if 'gpt_responses_original' not in st.session_state:
    st.session_state.gpt_responses_original = {}
if 'gpt_responses_optimized' not in st.session_state:
    st.session_state.gpt_responses_optimized = {}
if 'history_manager' not in st.session_state:
    st.session_state.history_manager = EvaluationHistoryManager()
if 'current_excel_filename' not in st.session_state:
    st.session_state.current_excel_filename = None
if 'gpt_responses_loaded' not in st.session_state:
    st.session_state.gpt_responses_loaded = False
if 'display_semantic_metric' not in st.session_state:
    st.session_state.display_semantic_metric = True
if 'gpt_selected_dimensions' not in st.session_state:
    st.session_state.gpt_selected_dimensions = ['relevance', 'completeness', 'accuracy', 'faithfulness']
if 'gpt_dimension_weights' not in st.session_state:
    st.session_state.gpt_dimension_weights = {
        'relevance': 0.25,
        'completeness': 0.25,
        'accuracy': 0.25,
        'faithfulness': 0.25,
    }

# å·¥å…·å‡½æ•¸
def split_into_sentences(text: str):
    """å°‡æ–‡å­—åˆ‡æˆå¥å­åˆ—è¡¨"""
    if not isinstance(text, str) or not text.strip():
        return []

    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ!?\n\r]+', text)
    return [s.strip() for s in sentences if s.strip()]


def compute_sentence_similarity(evaluator: RAGEvaluatorV2, sentences, answer: str):
    """è¨ˆç®—æ¯å€‹å¥å­èˆ‡å›ç­”çš„èªç¾©ç›¸ä¼¼åº¦"""
    results = []
    if not evaluator or not evaluator.enable_semantic or not sentences:
        return results

    if answer is None or (isinstance(answer, float) and np.isnan(answer)) or str(answer).strip() == "":
        return [(sent, 0.0) for sent in sentences]

    for sent in sentences:
        try:
            score, _ = evaluator.calculate_semantic_similarity(sent, answer)
        except Exception:
            score = 0.0
        results.append((sent, score))

    return results


def format_reference_to_list(reference_text: str):
    """å°‡åƒè€ƒå…§å®¹æ‹†æˆä¾¿æ–¼å±•ç¤ºçš„æ¢åˆ—"""
    if not isinstance(reference_text, str):
        return []

    lines = [line.strip() for line in reference_text.splitlines() if line.strip()]
    if len(lines) <= 1:
        # è‹¥åªæœ‰å–®æ®µï¼Œç›¡é‡ä¾æ•¸å­—æˆ–é “è™Ÿå†æ‹†åˆ†
        segments = re.split(r'\d+\.|[ã€ï¼›;]', reference_text)
        lines = [seg.strip() for seg in segments if seg.strip()]
    return lines


# GPT Prompt ç”Ÿæˆå‡½æ•¸
def generate_gpt_prompt(question, reference_keywords, answer, version="optimized", question_id=1):
    """ç”Ÿæˆ GPT è©•å¯© prompt - ç¢ºä¿è©•åˆ†ä¸€è‡´æ€§"""
    prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„RAGç³»çµ±è©•ä¼°å°ˆå®¶ã€‚è«‹åš´æ ¼æŒ‰ç…§ä»¥ä¸‹æ¨™æº–è©•ä¼°ï¼Œç¢ºä¿è©•åˆ†ä¸€è‡´æ€§ã€‚

ã€å•é¡Œ {question_id}ã€‘
{question}

ã€å¿…é ˆåŒ…å«çš„é—œéµè³‡è¨Šã€‘
{reference_keywords}

ã€å¾…è©•ä¼°å›ç­”ï¼ˆ{version}ç‰ˆæœ¬ï¼‰ã€‘
{answer}

ã€è©•åˆ†æ¨™æº– â€‘ è«‹åš´æ ¼éµå®ˆã€‘

ğŸ¯ ç›¸é—œæ€§ (Relevance) â”€ å›ç­”å…§å®¹æ˜¯å¦é‡å°å•é¡Œæ ¸å¿ƒ  
åƒè€ƒï¼šDr3: Ask Large Language Models Not to Give Off-Topic Answers (arXiv 2024)ï¼› 
1. å°‡å›ç­”æ‹†æˆå¥å­æˆ–æ¢åˆ—ï¼Œæ¨™è¨˜ç‚º Strictly On-Topic / Off-Topicï¼Œä¸¦åˆ—å‡ºå…©è€…ã€‚  
2. è¨ˆç®—è²¼é¡Œæ¯”ä¾‹ p = è²¼é¡Œå¥æ•¸ Ã· ç¸½å¥æ•¸ã€‚  
3. ä¾ä¸‹è¡¨çµ¦åˆ†ï¼Œä¸¦åœ¨ reasoning ä¸­ç”¨äººé¡èªæ°£èªªæ˜ï¼šå“ªäº›å¥å­è²¼é¡Œã€å“ªäº›é›¢é¡Œã€ç‚ºä½•åŠ æ¸›åˆ†ã€‚  
   â€¢ 90â€‘100 åˆ†ï¼šp â‰¥ 0.90  
   â€¢ 80â€‘89 åˆ†ï¼š0.80 â‰¤ p < 0.90  
   â€¢ 70â€‘79 åˆ†ï¼š0.70 â‰¤ p < 0.80  
   â€¢ 60â€‘69 åˆ†ï¼š0.60 â‰¤ p < 0.70  
   â€¢ 50â€‘59 åˆ†ï¼š0.50 â‰¤ p < 0.60  
   â€¢ 40â€‘49 åˆ†ï¼š0.40 â‰¤ p < 0.50  
   â€¢ 30â€‘39 åˆ†ï¼š0.30 â‰¤ p < 0.40  
   â€¢ 20â€‘29 åˆ†ï¼š0.20 â‰¤ p < 0.30  
   â€¢ 10â€‘19 åˆ†ï¼š0.10 â‰¤ p < 0.20  
   â€¢ 0â€‘9 åˆ†ï¼šp < 0.10

ğŸ“‹ å®Œæ•´æ€§ (Completeness) â”€ æ˜¯å¦æ¶µè“‹æ‰€æœ‰å¿…è¦è³‡è¨Š  
åƒè€ƒï¼šAWS Bedrock â€œInformation Comprehensivenessâ€[Coverage+Depth]ï¼›QUEST â€œComprehensivenessâ€[80]ï¼›  
1. åˆ—å‡ºã€å¿…é ˆåŒ…å«çš„é—œéµè³‡è¨Šã€‘çš„æ¯å€‹è¦é»ï¼Œä¸¦æ¨™è¨˜ç‚º Covered / Partially / Missingã€‚  
2. å‘½ä¸­ç‡ q = (Covered + 0.5 Ã— Partially) Ã· ç¸½è¦é»ã€‚  
3. å°æ¯å€‹ Covered æˆ– Partially çš„è¦é»ï¼Œé¡å¤–è©•ä¼°æ˜¯å¦æä¾›äº†å……åˆ†ç´°ç¯€ã€ä¸Šä¸‹æ–‡æˆ–è³‡æ–™æ•´åˆï¼Œä¸¦åœ¨ reasoning ä¸­å…·é«”èªªæ˜æ·±åº¦è¡¨ç¾ã€‚  
4. è‹¥æ•´é«”å…§å®¹é›–è¦†è“‹å®Œæ•´ä½†èªªæ˜æ˜é¡¯æ·ºè–„ï¼ˆåƒ…åè©ç¾…åˆ—ã€ç¼ºä¹é‚è¼¯æˆ–è£œå……ï¼‰ï¼Œå‰‡æ•´é«”åˆ†æ•¸ä¸Šé™ç‚º 89 åˆ†ã€‚  
5. ä¾ä¸‹è¡¨çµ¦åˆ†ï¼›å€é–“å…§å¯ç·šæ€§å…§æ’ä¸¦å››æ¨äº”å…¥ç‚ºæ•´æ•¸ã€‚åœ¨ reasoning ä¸­åˆ—å‡ºå‘½ä¸­ã€éƒ¨åˆ†å‘½ä¸­ã€ç¼ºæ¼çš„è¦é»åŠæ·±åº¦åˆ†æï¼Œæœ€å¾Œç”¨äººé¡èªæ°£ç¸½çµæ•´é«”å½±éŸ¿ã€‚  

   â€¢ 90-100 åˆ†ï¼šq â‰¥ 0.90 ä¸”æ¯é …è¦é»è§£é‡‹å……åˆ†ï¼ˆè‹¥æ·±åº¦ä¸è¶³ï¼Œä¸Šé™ 89ï¼‰  
   â€¢ 80-89 åˆ†ï¼š0.80 â‰¤ q < 0.90  
   â€¢ 70-79 åˆ†ï¼š0.70 â‰¤ q < 0.80  
   â€¢ 60-69 åˆ†ï¼š0.60 â‰¤ q < 0.70  
   â€¢ 50-59 åˆ†ï¼š0.50 â‰¤ q < 0.60  
   â€¢ 40-49 åˆ†ï¼š0.40 â‰¤ q < 0.50  
   â€¢ 30-39 åˆ†ï¼š0.30 â‰¤ q < 0.40  
   â€¢ 20-29 åˆ†ï¼š0.20 â‰¤ q < 0.30  
   â€¢ 10-19 åˆ†ï¼š0.10 â‰¤ q < 0.20  
   â€¢ 0-9 åˆ†ï¼šq < 0.10

âœ… æº–ç¢ºæ€§ (Accuracy) â”€ è³‡è¨Šæ˜¯å¦æ­£ç¢º  
åƒè€ƒï¼šMin et al., 2023 â€œFactScoreâ€ï¼›Lee et al., 2023 â€œRLAIF vs. RLHFâ€ é™„éŒ„äº‹å¯¦æª¢æŸ¥ï¼› 
1. åˆ—å‡ºå›ç­”ä¸­å¯é©—è­‰çš„é™³è¿° S1â€¦Snï¼Œæ¨™è¨˜ç‚º Correct / Incorrect / Unverifiableã€‚  
2. æ­£ç¢ºç‡ r = Correct Ã· (Correct + Incorrect)ã€‚  
3. ä¾ä¸‹è¡¨çµ¦åˆ†ï¼Œåœ¨ reasoning ä¸­åˆ—å‡ºæ­£ç¢ºèˆ‡éŒ¯èª¤çš„é™³è¿°ã€æŒ‡å‡ºä¸»è¦éŒ¯èª¤ä¾†æºï¼Œä¸¦ç”¨äººé¡èªæ°£ç¸½çµã€‚  
   â€¢ 90â€‘100 åˆ†ï¼šr â‰¥ 0.95  
   â€¢ 80â€‘89 åˆ†ï¼š0.85 â‰¤ r < 0.95  
   â€¢ 70â€‘79 åˆ†ï¼š0.75 â‰¤ r < 0.85  
   â€¢ 60â€‘69 åˆ†ï¼š0.65 â‰¤ r < 0.75  
   â€¢ 50â€‘59 åˆ†ï¼š0.55 â‰¤ r < 0.65  
   â€¢ 40â€‘49 åˆ†ï¼š0.45 â‰¤ r < 0.55  
   â€¢ 30â€‘39 åˆ†ï¼š0.35 â‰¤ r < 0.45  
   â€¢ 20â€‘29 åˆ†ï¼š0.25 â‰¤ r < 0.35  
   â€¢ 10â€‘19 åˆ†ï¼š0.15 â‰¤ r < 0.25  
   â€¢ 0â€‘9 åˆ†ï¼šr < 0.15

ğŸ”’ å¿ èª åº¦ (Faithfulness) â”€ æ˜¯å¦åŸºæ–¼åŸå§‹è³‡æ–™  
åƒè€ƒï¼šMaynez et al., 2020 â€œOn Faithfulnessâ€¦â€ï¼›Lee et al., 2021 â€œEvaluation of RAG Metricsâ€¦â€ï¼›  
1. å°æ¯å¥æˆ–æ¯å€‹é™³è¿°æ¨™è¨˜ç‚º Supported / Partially Supported / Unsupportedï¼Œä¸¦åˆ—å‡ºå„é¡å¥å­ã€‚  
2. æ”¯æ’æ¯”ä¾‹ f = (Supported + 0.5 Ã— Partially) Ã· å…¨éƒ¨é™³è¿°ã€‚  
3. ä¾ä¸‹è¡¨çµ¦åˆ†ï¼Œåœ¨ reasoning ä¸­æ¸…æ¥šèªªæ˜ï¼šå“ªäº›å¥å­æœ‰ä¾†æºã€å“ªäº›ç¼ºä¹ä¾æ“šæˆ–å±¬åˆç†æ¨è«–ï¼Œæœ€å¾Œä»¥äººé¡èªæ°£ç¸½çµã€‚  
   â€¢ 90â€‘100 åˆ†ï¼šf â‰¥ 0.90  
   â€¢ 80â€‘89 åˆ†ï¼š0.80 â‰¤ f < 0.90  
   â€¢ 70â€‘79 åˆ†ï¼š0.70 â‰¤ f < 0.80  
   â€¢ 60â€‘69 åˆ†ï¼š0.60 â‰¤ f < 0.70  
   â€¢ 50â€‘59 åˆ†ï¼š0.50 â‰¤ f < 0.60  
   â€¢ 40â€‘49 åˆ†ï¼š0.40 â‰¤ f < 0.50  
   â€¢ 30â€‘39 åˆ†ï¼š0.30 â‰¤ f < 0.40  
   â€¢ 20â€‘29 åˆ†ï¼š0.20 â‰¤ f < 0.30  
   â€¢ 10â€‘19 åˆ†ï¼š0.10 â‰¤ f < 0.20  
   â€¢ 0â€‘9 åˆ†ï¼šf < 0.10


ã€è©•ä¼°æµç¨‹ - è«‹æŒ‰é †åºåŸ·è¡Œã€‘
1. å…ˆä»”ç´°é–±è®€å•é¡Œï¼Œç†è§£å•é¡Œè¦æ±‚ã€‚
2. æ•¸å‡ºã€å¿…é ˆåŒ…å«çš„é—œéµè³‡è¨Šã€‘ä¸­çš„é—œéµæ¦‚å¿µç¸½æ•¸ã€‚
3. é€å¥åˆ†æå›ç­”å…§å®¹ï¼Œç‚ºå››å€‹ç¶­åº¦æº–å‚™å°æ‡‰çš„å¥å­æ¸…å–®èˆ‡æ¯”ä¾‹ã€‚
4. ä¾æ“šä¸Šæ–¹å››å€‹è©•åˆ†è¡¨æ›ç®—å„ç¶­åº¦åˆ†æ•¸ï¼Œä¸¦ç¢ºèªæ˜¯å¦è½åœ¨æ­£ç¢ºçš„ç™¾åˆ†æ¯”å€é–“ã€‚
5. åœ¨ reasoning ä¸­ä»¥äººé¡èªæ°£æ•´ç†ï¼šåˆ—å‡ºè²¼é¡Œ/é›¢é¡Œã€å‘½ä¸­/ç¼ºæ¼ã€æ­£ç¢º/éŒ¯èª¤ã€Supported/Unsupported çš„å¥å­èˆ‡æ¯”ä¾‹ï¼Œæœ€å¾Œç”¨ä¸€å…©å¥è©±ç¸½çµåŠ æ¸›åˆ†åŸå› ã€‚

è«‹å‹™å¿…æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼å›å‚³ï¼š
{{
  "question_id": {question_id},
  "relevance": <åˆ†æ•¸>,
  "relevance_reasoning": "è²¼é¡Œå¥ï¼š[...]ï½œé›¢é¡Œå¥ï¼š[...]ï½œçµè«–ï¼šp=Y%ï¼Œå› æ­¤çµ¦Xåˆ†ï¼ŒåŸå› æ˜¯...",
  "completeness": <åˆ†æ•¸>,
  "completeness_reasoning": "å‘½ä¸­è¦é»ï¼š[...]ï½œç¼ºæ¼/éƒ¨åˆ†è¦é»ï¼š[...]ï½œçµè«–ï¼šå‘½ä¸­ç‡Z%(Y/X)ï¼Œå› æ­¤çµ¦Xåˆ†ï¼ŒåŸå› æ˜¯...",
  "accuracy": <åˆ†æ•¸>,
  "accuracy_reasoning": "æ­£ç¢ºé™³è¿°ï¼š[...]ï½œéŒ¯èª¤/ä¸å¯é©—è­‰ï¼š[...]ï½œçµè«–ï¼šæ­£ç¢ºç‡Z%(Y/X)ï¼Œå› æ­¤çµ¦Xåˆ†ï¼ŒæŒ‡å‡ºä¸»è¦éŒ¯èª¤...",
  "faithfulness": <åˆ†æ•¸>,
  "faithfulness_reasoning": "Supportedï¼š[...]ï½œUnsupported/æ¨è«–ï¼š[...]ï½œçµè«–ï¼šæ”¯æ’ç‡Z%(Y/X)ï¼Œå› æ­¤çµ¦Xåˆ†ï¼Œèªªæ˜ç¼ºä¹ä¾†æºçš„å¥å­...",
  "overall": <å››å€‹ç¶­åº¦å¹³å‡åˆ†>,
  "overall_reasoning": "å››å€‹ç¶­åº¦å¹³å‡ï¼š(X+Y+Z+W)/4=ç¸½åˆ†"
}}

é‡è¦æé†’ï¼šè«‹ç¢ºä¿æ¯æ¬¡è©•ä¼°éƒ½åš´æ ¼æŒ‰ç…§ç™¾åˆ†æ¯”è¨ˆç®—ï¼Œä¸è¦ä¾è³´ä¸»è§€æ„Ÿè¦ºã€‚æ¯å€‹reasoningå¿…é ˆåŒ…å«å…·é«”æ•¸æ“šã€‚"""

    return prompt

# è§£æ GPT å›æ‡‰
def normalize_json_like_text(text: str) -> str:
    """å°‡å¸¸è¦‹çš„å…¨å½¢/å½å¼•è™Ÿæ›¿æ›æˆæ¨™æº– ASCII å­—å…ƒï¼Œæ–¹ä¾¿ JSON è§£æ"""
    if not isinstance(text, str):
        return text

    normalized = text

    # å…ˆè™•ç†éµåï¼šå°‡ã€Œâ€œkeyâ€ :ã€è½‰æ›ç‚ºæ¨™æº– JSON æ ¼å¼
    normalized = re.sub(r'â€œ([^â€]+)â€\s*:', lambda m: f'"{m.group(1)}":', normalized)

    # è™•ç†ä»¥å…¨å½¢å¼•è™ŸåŒ…è£¹çš„å€¼ï¼Œç¢ºä¿èµ·è¨–ä½¿ç”¨æ¨™æº–é›™å¼•è™Ÿ
    normalized = re.sub(r':\s*â€œ', ': "', normalized)
    normalized = re.sub(r'â€(?=\s*[,\n}])', '"', normalized)

    replacements = {
        'â€œ': "'",
        'â€': "'",
        'ï¼‚': '"',
        'ã€Œ': "'",
        'ã€': "'",
        'ã€': "'",
        'ã€': "'",
        'â€˜': "'",
        'â€™': "'",
        'ï¼‡': "'",
    }

    for src, target in replacements.items():
        normalized = normalized.replace(src, target)

    return normalized


def parse_gpt_response(response_text):
    """è§£æ ChatGPT çš„ JSON å›æ‡‰ï¼Œä¸¦å®¹éŒ¯è™•ç†å¸¸è¦‹çš„æ ¼å¼å•é¡Œ"""

    if not response_text:
        return {"error": "å›æ‡‰ç‚ºç©ºç™½", "raw_response": response_text}

    candidates = []
    raw_text = response_text.strip()
    candidates.append(raw_text)

    normalized_text = normalize_json_like_text(raw_text)
    if normalized_text != raw_text:
        candidates.append(normalized_text)

    for candidate in candidates:
        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            try:
                literal_result = ast.literal_eval(candidate)
                if isinstance(literal_result, dict):
                    return literal_result
            except (ValueError, SyntaxError):
                pass
            json_match = re.search(r'\{.*\}', candidate, re.DOTALL)
            if json_match:
                json_snippet = json_match.group().strip()
                try:
                    return json.loads(json_snippet)
                except json.JSONDecodeError:
                    try:
                        literal_result = ast.literal_eval(json_snippet)
                        if isinstance(literal_result, dict):
                            return literal_result
                    except (ValueError, SyntaxError):
                        continue

    return {"error": "ç„¡æ³•è§£æ GPT å›æ‡‰", "raw_response": response_text}


GPT_DIMENSION_LABELS = {
    'relevance': 'ğŸ¯ ç›¸é—œæ€§',
    'completeness': 'ğŸ“‹ å®Œæ•´æ€§',
    'accuracy': 'âœ… æº–ç¢ºæ€§',
    'faithfulness': 'ğŸ”’ å¿ èª åº¦',
}

DEFAULT_GPT_DIMENSIONS = list(GPT_DIMENSION_LABELS.keys())


def get_selected_gpt_dimensions() -> list:
    """å–å¾—ç›®å‰é¸æ“‡çš„ GPT ç¶œåˆè©•åˆ†ç¶­åº¦ï¼ˆè‡³å°‘å›å‚³ä¸€å€‹ï¼‰ã€‚"""
    selected = st.session_state.get('gpt_selected_dimensions', DEFAULT_GPT_DIMENSIONS)
    if not selected:
        return DEFAULT_GPT_DIMENSIONS

    filtered = [dim for dim in selected if dim in GPT_DIMENSION_LABELS]
    return filtered or DEFAULT_GPT_DIMENSIONS


def get_gpt_dimension_weights(selected_dims: list) -> dict:
    """ä»¥ç›®å‰é¸æ“‡çš„ç¶­åº¦å›å‚³æ­¸ä¸€åŒ–æ¬Šé‡ï¼Œé è¨­å¹³å‡ã€‚"""
    weights_setting = st.session_state.get('gpt_dimension_weights', {})
    weights = {}
    total = 0.0
    for dim in selected_dims:
        value = weights_setting.get(dim)
        if isinstance(value, (int, float)) and value >= 0:
            weights[dim] = float(value)
            total += float(value)
        else:
            weights[dim] = 0.0

    if total <= 0:
        # è‹¥å…¨éƒ¨ç‚º 0 æˆ–ç„¡è¨­å®šï¼Œæ”¹æ¡å¹³å‡æ¬Šé‡
        equal_weight = 1.0 / len(selected_dims)
        return {dim: equal_weight for dim in selected_dims}

    return {dim: value / total for dim, value in weights.items()}


def compute_gpt_overall(gpt_data: dict, selected_dims: list | None = None, dim_weights: dict | None = None) -> float:
    """ä¾ç…§é¸å–çš„ç¶­åº¦é‡æ–°è¨ˆç®— GPT ç¶œåˆè©•åˆ†ã€‚"""
    if not isinstance(gpt_data, dict):
        return 0.0

    dimensions = selected_dims or get_selected_gpt_dimensions()
    weights = dim_weights or get_gpt_dimension_weights(dimensions)

    score_sum = 0.0
    applied_weight = 0.0
    for dim in dimensions:
        raw_value = gpt_data.get(dim)
        try:
            value = float(raw_value)
        except (TypeError, ValueError):
            continue
        weight = weights.get(dim, 0.0)
        score_sum += value * weight
        applied_weight += weight

    if applied_weight > 0:
        return score_sum / applied_weight

    fallback = gpt_data.get('overall')
    try:
        return float(fallback)
    except (TypeError, ValueError):
        return 0.0


def format_gpt_weight_summary(selected_dims: list, dim_weights: dict | None = None) -> str:
    weights = dim_weights or get_gpt_dimension_weights(selected_dims)
    parts = []
    for dim in selected_dims:
        label = GPT_DIMENSION_LABELS.get(dim, dim)
        parts.append(f"{label} {weights.get(dim, 0)*100:.0f}%")
    return 'ã€'.join(parts)

# é©—è­‰è©•åˆ†ä¸€è‡´æ€§å‡½æ•¸
def validate_scoring_consistency(parsed_response, question_text, answer_text):
    """é©—è­‰è©•åˆ†çš„é‚è¼¯ä¸€è‡´æ€§å’Œå®Œæ•´æ€§"""
    
    warnings = []
    errors = []
    
    # æª¢æŸ¥å¿…è¦æ¬„ä½
    required_fields = [
        'relevance', 'relevance_reasoning',
        'completeness', 'completeness_reasoning', 
        'accuracy', 'accuracy_reasoning',
        'faithfulness', 'faithfulness_reasoning',
        'overall', 'overall_reasoning'
    ]
    
    for field in required_fields:
        if field not in parsed_response:
            errors.append(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {field}")
            continue

        value = parsed_response.get(field)
        if value is None:
            errors.append(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {field}")
            continue

        if isinstance(value, str) and not value.strip():
            errors.append(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {field}")
    
    # å¦‚æœæœ‰éŒ¯èª¤ï¼Œç›´æ¥è¿”å›
    if errors:
        return warnings, errors
    
    # æª¢æŸ¥åˆ†æ•¸ç¯„åœ
    score_fields = ['relevance', 'completeness', 'accuracy', 'faithfulness', 'overall']
    for score_field in score_fields:
        score = parsed_response.get(score_field, 0)
        if not isinstance(score, (int, float)) or not (0 <= score <= 100):
            errors.append(f"{score_field} åˆ†æ•¸å¿…é ˆåœ¨ 0-100 ä¹‹é–“ï¼Œç›®å‰ç‚º: {score}")
    
    # æª¢æŸ¥overallæ˜¯å¦ç‚ºå››å€‹ç¶­åº¦çš„å¹³å‡å€¼
    if not errors:  # åªæœ‰åœ¨æ²’æœ‰éŒ¯èª¤æ™‚æ‰æª¢æŸ¥
        scores = {
            'relevance': parsed_response.get('relevance', 0),
            'completeness': parsed_response.get('completeness', 0), 
            'accuracy': parsed_response.get('accuracy', 0),
            'faithfulness': parsed_response.get('faithfulness', 0)
        }
        
        expected_overall = sum(scores.values()) / 4
        actual_overall = parsed_response.get('overall', 0)
        
        if abs(expected_overall - actual_overall) > 2:  # å®¹è¨±2åˆ†èª¤å·®
            warnings.append(f"ç¸½åˆ†å¯èƒ½ä¸ä¸€è‡´ï¼šæœŸæœ›{expected_overall:.1f}ï¼Œå¯¦éš›{actual_overall}")
    
    # æª¢æŸ¥reasoningæ˜¯å¦åŒ…å«å…·é«”æ•¸æ“š
    reasoning_fields = ['relevance_reasoning', 'completeness_reasoning', 'accuracy_reasoning', 'faithfulness_reasoning']
    for reasoning_field in reasoning_fields:
        reasoning = parsed_response.get(reasoning_field, '')
        if '%' not in reasoning and 'å€‹' not in reasoning and 'åˆ†æéç¨‹' not in reasoning:
            warnings.append(f"{reasoning_field}ç¼ºå°‘å…·é«”æ•¸æ“šæˆ–åˆ†æéç¨‹èªªæ˜")
    
    return warnings, errors

# è‡ªå‹•ä¿å­˜è©•ä¼°çµæœåˆ°æ­·å²ç´€éŒ„
def auto_save_evaluation(actual_question_id, results_df, weights, selected_dims=None, dim_weights=None):
    """
    è‡ªå‹•ä¿å­˜è©•ä¼°çµæœåˆ°æ­·å²ç´€éŒ„

    ç­–ç•¥ï¼š
    1. å¦‚æœå…©å€‹ç‰ˆæœ¬éƒ½æœ‰ GPT è©•åˆ† â†’ ä¿å­˜å®Œæ•´è©•ä¼°
    2. å¦‚æœåªæœ‰ä¸€å€‹ç‰ˆæœ¬æœ‰ GPT è©•åˆ† â†’ ä¿å­˜è©²ç‰ˆæœ¬ï¼ˆå¦ä¸€ç‰ˆæœ¬ç”¨ 0 å¡«å……ï¼‰

    Args:
        actual_question_id: å¯¦éš›çš„å•é¡Œåºè™Ÿï¼ˆä¾†è‡ª 'åºè™Ÿ' æ¬„ä½ï¼‰
        results_df: è©•ä¼°çµæœ DataFrame
        weights: æ¬Šé‡è¨­å®š
    """
    # æª¢æŸ¥æ˜¯å¦è‡³å°‘æœ‰ä¸€å€‹ç‰ˆæœ¬æœ‰ GPT è©•åˆ†ï¼ˆä½¿ç”¨å¯¦éš›åºè™Ÿï¼‰
    has_original = actual_question_id in st.session_state.gpt_responses_original
    has_optimized = actual_question_id in st.session_state.gpt_responses_optimized

    if not (has_original or has_optimized):
        return False  # å…©å€‹ç‰ˆæœ¬éƒ½æ²’æœ‰ GPT è©•åˆ†ï¼Œä¸ä¿å­˜

    try:
        # åœ¨ DataFrame ä¸­æŸ¥æ‰¾å°æ‡‰çš„è¡Œï¼ˆä½¿ç”¨ 'åºè™Ÿ' æ¬„ä½åŒ¹é…ï¼‰
        matching_rows = results_df[results_df['åºè™Ÿ'] == actual_question_id]
        if matching_rows.empty:
            print(f"âš ï¸ æ‰¾ä¸åˆ°åºè™Ÿ {actual_question_id} çš„å•é¡Œ")
            return False

        row = matching_rows.iloc[0]

        # æº–å‚™åŸå§‹ç‰ˆæœ¬è©•åˆ†
        selected_dims = selected_dims or get_selected_gpt_dimensions()
        dim_weights = dim_weights or get_gpt_dimension_weights(selected_dims)

        if has_original:
            gpt_orig = st.session_state.gpt_responses_original[actual_question_id]
            original_scores = {
                "keyword_score": row.get('KEYWORD_COVERAGE_ORIGINAL', 0),
                "semantic_score": row.get('SEMANTIC_SIMILARITY_ORIGINAL', 0),
                "gpt_relevance": gpt_orig.get('relevance', 0),
                "gpt_completeness": gpt_orig.get('completeness', 0),
                "gpt_accuracy": gpt_orig.get('accuracy', 0),
                "gpt_faithfulness": gpt_orig.get('faithfulness', 0),
                "gpt_overall": compute_gpt_overall(gpt_orig, selected_dims, dim_weights),
                "gpt_reasoning": gpt_orig.get('reasoning', ''),
                "final_score": row.get('FINAL_SCORE_ORIGINAL', 0)
            }
        else:
            # åŸå§‹ç‰ˆæœ¬æ²’æœ‰ GPT è©•åˆ†ï¼Œåªä¿å­˜é—œéµè©å’Œèªç¾©
            original_scores = {
                "keyword_score": row.get('KEYWORD_COVERAGE_ORIGINAL', 0),
                "semantic_score": row.get('SEMANTIC_SIMILARITY_ORIGINAL', 0),
                "gpt_relevance": 0,
                "gpt_completeness": 0,
                "gpt_accuracy": 0,
                "gpt_faithfulness": 0,
                "gpt_overall": 0,
                "gpt_reasoning": "",
                "final_score": row.get('FINAL_SCORE_ORIGINAL', 0)
            }

        # æº–å‚™å„ªåŒ–ç‰ˆæœ¬è©•åˆ†
        if has_optimized:
            gpt_opt = st.session_state.gpt_responses_optimized[actual_question_id]
            optimized_scores = {
                "keyword_score": row.get('KEYWORD_COVERAGE_OPTIMIZED', 0),
                "semantic_score": row.get('SEMANTIC_SIMILARITY_OPTIMIZED', 0),
                "gpt_relevance": gpt_opt.get('relevance', 0),
                "gpt_completeness": gpt_opt.get('completeness', 0),
                "gpt_accuracy": gpt_opt.get('accuracy', 0),
                "gpt_faithfulness": gpt_opt.get('faithfulness', 0),
                "gpt_overall": compute_gpt_overall(gpt_opt, selected_dims, dim_weights),
                "gpt_reasoning": gpt_opt.get('reasoning', ''),
                "final_score": row.get('FINAL_SCORE_OPTIMIZED', 0)
            }
        else:
            # å„ªåŒ–ç‰ˆæœ¬æ²’æœ‰ GPT è©•åˆ†ï¼Œåªä¿å­˜é—œéµè©å’Œèªç¾©
            optimized_scores = {
                "keyword_score": row.get('KEYWORD_COVERAGE_OPTIMIZED', 0),
                "semantic_score": row.get('SEMANTIC_SIMILARITY_OPTIMIZED', 0),
                "gpt_relevance": 0,
                "gpt_completeness": 0,
                "gpt_accuracy": 0,
                "gpt_faithfulness": 0,
                "gpt_overall": 0,
                "gpt_reasoning": "",
                "final_score": row.get('FINAL_SCORE_OPTIMIZED', 0)
            }

        # ä¿å­˜åˆ°æ­·å²ç´€éŒ„ï¼ˆä½¿ç”¨å¯¦éš›åºè™Ÿï¼‰
        success = st.session_state.history_manager.save_evaluation(
            excel_filename=st.session_state.current_excel_filename,
            question_id=actual_question_id,
            question_text=row.get('æ¸¬è©¦å•é¡Œ', ''),
            reference_keywords=row.get('æ‡‰å›ç­”ä¹‹è©å½™', ''),
            original_answer=row.get('ANSWER_ORIGINAL', ''),
            optimized_answer=row.get('ANSWER_OPTIMIZED', ''),
            original_scores=original_scores,
            optimized_scores=optimized_scores,
            weights=weights,
            metadata={
                "evaluation_date": datetime.now().isoformat(),
                "improvement": optimized_scores['final_score'] - original_scores['final_score'],
                "has_original_gpt": has_original,
                "has_optimized_gpt": has_optimized
            }
        )

        return success

    except Exception as e:
        print(f"âŒ è‡ªå‹•ä¿å­˜å¤±æ•—: {e}")
        return False

# å¾æ­·å²ç´€éŒ„è¼‰å…¥ GPT è©•åˆ†
def load_gpt_from_history(excel_filename):
    """å¾æ­·å²ç´€éŒ„è¼‰å…¥è©²æª”æ¡ˆçš„ GPT è©•åˆ†"""
    if not excel_filename:
        return

    try:
        evaluations = st.session_state.history_manager.get_evaluations_by_file(excel_filename)

        for eval_record in evaluations:
            # ä½¿ç”¨å¯¦éš› question_idï¼ˆä¸éœ€è¦è½‰æ›ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹åºè™Ÿï¼‰
            question_id = eval_record.get("question_id", 0)

            # è¼‰å…¥åŸå§‹ç‰ˆæœ¬ GPT è©•åˆ†
            original_scores = eval_record.get("scores", {}).get("original", {})
            if original_scores.get("gpt_overall", 0) > 0:
                st.session_state.gpt_responses_original[question_id] = {
                    "relevance": original_scores.get("gpt_relevance", 0),
                    "completeness": original_scores.get("gpt_completeness", 0),
                    "accuracy": original_scores.get("gpt_accuracy", 0),
                    "faithfulness": original_scores.get("gpt_faithfulness", 0),
                    "overall": original_scores.get("gpt_overall", 0),
                    "reasoning": original_scores.get("gpt_reasoning", "")
                }

            # è¼‰å…¥å„ªåŒ–ç‰ˆæœ¬ GPT è©•åˆ†
            optimized_scores = eval_record.get("scores", {}).get("optimized", {})
            if optimized_scores.get("gpt_overall", 0) > 0:
                st.session_state.gpt_responses_optimized[question_id] = {
                    "relevance": optimized_scores.get("gpt_relevance", 0),
                    "completeness": optimized_scores.get("gpt_completeness", 0),
                    "accuracy": optimized_scores.get("gpt_accuracy", 0),
                    "faithfulness": optimized_scores.get("gpt_faithfulness", 0),
                    "overall": optimized_scores.get("gpt_overall", 0),
                    "reasoning": optimized_scores.get("gpt_reasoning", "")
                }

        if evaluations:
            print(f"âœ… å¾æ­·å²ç´€éŒ„è¼‰å…¥äº† {len(evaluations)} ç­† GPT è©•åˆ†")
            return len(evaluations)

    except Exception as e:
        print(f"âš ï¸ è¼‰å…¥æ­·å² GPT è©•åˆ†å¤±æ•—: {e}")

    return 0

# æ¨™é¡Œå’Œèªªæ˜
st.title("ğŸ†š RAG è©•ä¼°å„€è¡¨æ¿ v2.0")
st.markdown("### RAGè©•ä¼°æ¶æ§‹ï¼šé—œéµè© + èªç¾©ç›¸ä¼¼åº¦ + GPT äººå·¥è©•å¯©")

# å´é‚Šæ¬„é…ç½®
with st.sidebar:
    st.header("ğŸ“ è¨­å®šèˆ‡æª”æ¡ˆé¸æ“‡")

    # æª”æ¡ˆé¸æ“‡æ–¹å¼
    file_source = st.radio(
        "é¸æ“‡æª”æ¡ˆä¾†æº",
        ["ğŸ“‚ æœ¬åœ°è³‡æ–™å¤¾", "ğŸ“¤ ä¸Šå‚³æª”æ¡ˆ"],
        help="é¸æ“‡è¦å¾æœ¬åœ°è³‡æ–™å¤¾è¼‰å…¥æˆ–ä¸Šå‚³æ–°æª”æ¡ˆ"
    )

    selected_file_path = None
    uploaded_file = None

    if file_source == "ğŸ“‚ æœ¬åœ°è³‡æ–™å¤¾":
        data_folder = "test_data"
        if not os.path.exists(data_folder):
            os.makedirs(data_folder)

        st.caption(f"è³‡æ–™å¤¾è·¯å¾‘ï¼š{data_folder}")

        try:
            all_files = os.listdir(data_folder)
            excel_files = [f for f in all_files
                          if f.endswith(('.xlsx', '.xls', '.csv')) and not f.startswith('~') and not f.startswith('.')]
        except Exception as e:
            st.error(f"è®€å–è³‡æ–™å¤¾æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
            excel_files = []

        if excel_files:
            selected_file = st.selectbox(
                "é¸æ“‡è¦è©•ä¼°çš„æª”æ¡ˆ",
                excel_files,
                help="å¾ test_data è³‡æ–™å¤¾ä¸­é¸æ“‡æª”æ¡ˆ"
            )
            selected_file_path = os.path.join(data_folder, selected_file)
            uploaded_file = selected_file_path

            file_info = os.stat(selected_file_path)
            st.info(f"æª”æ¡ˆå¤§å°ï¼š{file_info.st_size / 1024:.1f} KB")
            st.success(f"âœ… å·²è¼‰å…¥: {selected_file}")
        else:
            st.warning("âš ï¸ test_data è³‡æ–™å¤¾ä¸­æ²’æœ‰æ‰¾åˆ° Excel æˆ– CSV æª”æ¡ˆ")

    else:  # ä¸Šå‚³æª”æ¡ˆ
        uploaded_file = st.file_uploader(
            "ä¸Šå‚³æ¸¬è©¦çµæœExcel/CSVæª”æ¡ˆ",
            type=['xlsx', 'xls', 'csv'],
            help="è«‹ä¸Šå‚³åŒ…å«å‘é‡çŸ¥è­˜åº«(åŸå§‹ç‰ˆ)å’Œæ™ºæ…§æ–‡æª”çŸ¥è­˜åº«(å½™æ•´ç‰ˆ)å›ç­”çš„æ¸¬è©¦çµæœ"
        )

        if uploaded_file is not None:
            file_extension = uploaded_file.name.split('.')[-1].lower()
            selected_file_path = f"temp_uploaded.{file_extension}"
            with open(selected_file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            st.success(f"âœ… å·²è¼‰å…¥: {uploaded_file.name}")

    # çŸ¥è­˜åº«é¸æ“‡
    st.markdown("### ğŸ“š çŸ¥è­˜åº«è¨­å®š")
    col1, col2 = st.columns(2)

    with col1:
        original_kb = st.selectbox(
            "åŸå§‹ç‰ˆæœ¬",
            ["å‘é‡çŸ¥è­˜åº«", "æ™ºæ…§æ–‡æª”çŸ¥è­˜åº«"],
            index=0,
            help="é¸æ“‡åŸå§‹ç‰ˆæœ¬ä½¿ç”¨çš„çŸ¥è­˜åº«æŠ€è¡“"
        )

    with col2:
        optimized_kb = st.selectbox(
            "å„ªåŒ–ç‰ˆæœ¬",
            ["æ™ºæ…§æ–‡æª”çŸ¥è­˜åº«", "å‘é‡çŸ¥è­˜åº«+å„ªåŒ–"],
            index=0,
            help="é¸æ“‡å„ªåŒ–ç‰ˆæœ¬ä½¿ç”¨çš„çŸ¥è­˜åº«æŠ€è¡“"
        )

    # è©•ä¼°å±¤ç´šè¨­å®š
    st.markdown("### ğŸ¯ è©•ä¼°å±¤ç´šè¨­å®š")
    st.info("ğŸ” é¸æ“‡è¦å•Ÿç”¨çš„è©•ä¼°å±¤ç´š")

    enable_semantic = st.checkbox(
        "å•Ÿç”¨èªç¾©ç›¸ä¼¼åº¦è©•ä¼°",
        value=True,
        help="ä½¿ç”¨ Sentence Transformers è¨ˆç®—èªç¾©ç›¸ä¼¼åº¦ï¼ˆæ¨è–¦ï¼‰"
    )

    enable_manual_gpt = st.checkbox(
        "å•Ÿç”¨ GPT äººå·¥è©•å¯©",
        value=True,
        help="ç”Ÿæˆ GPT promptsï¼Œæ‚¨å¯è¤‡è£½åˆ° ChatGPT ä¸¦è²¼å›è©•åˆ†ï¼ˆå®Œå…¨å…è²»ï¼Œç„¡éœ€ APIï¼‰"
    )

    if enable_manual_gpt:
        st.success("âœ… GPT äººå·¥è©•å¯©æ¨¡å¼")
        st.info("ğŸ’¡ ç³»çµ±æœƒç”Ÿæˆ Promptï¼Œè«‹ç›´æ¥è¤‡è£½åˆ° ChatGPT é€²è¡Œåˆ†æ")

    show_semantic_overview = st.checkbox(
        "æ¦‚è¦½é¡¯ç¤ºèªç¾©ç›¸ä¼¼åº¦",
        value=st.session_state.display_semantic_metric,
        help="åƒ…å½±éŸ¿è©•ä¼°ç¸½è¦½æŒ‡æ¨™å¡ç‰‡ï¼›å³ä½¿ä¸é¡¯ç¤ºï¼Œèªç¾©åˆ†æ•¸ä»æœƒè¨ˆç®—ä¸¦èƒ½åœ¨å…¶ä»–åˆ†é ä½¿ç”¨ã€‚"
    )
    st.session_state.display_semantic_metric = show_semantic_overview

    # è©•åˆ†æ¬Šé‡è¨­å®š
    st.markdown("### âš–ï¸ è©•åˆ†æ¬Šé‡è¨­å®š")

    if enable_semantic and enable_manual_gpt:
        st.info("ä¸‰ç¨®è©•ä¼°æ¨¡å¼")
        weight_keyword = st.slider("é—œéµè©æ¬Šé‡", 0.0, 1.0, 0.3, 0.1)
        weight_semantic = st.slider("èªç¾©æ¬Šé‡", 0.0, 1.0, 0.3, 0.1)
        weight_gpt = 1.0 - weight_keyword - weight_semantic
        st.metric("GPT æ¬Šé‡", f"{weight_gpt:.1f}")
    elif enable_semantic:
        st.info("é›™å±¤è©•ä¼°æ¨¡å¼ï¼ˆé—œéµè© + èªç¾©ï¼‰")
        weight_keyword = st.slider("é—œéµè©æ¬Šé‡", 0.0, 1.0, 0.5, 0.1)
        weight_semantic = 1.0 - weight_keyword
        weight_gpt = 0.0
        st.metric("èªç¾©æ¬Šé‡", f"{weight_semantic:.1f}")
    elif enable_manual_gpt:
        st.info("é›™å±¤è©•ä¼°æ¨¡å¼ï¼ˆé—œéµè© + GPTï¼‰")
        weight_keyword = st.slider("é—œéµè©æ¬Šé‡", 0.0, 1.0, 0.4, 0.1)
        weight_gpt = 1.0 - weight_keyword
        weight_semantic = 0.0
        st.metric("GPT æ¬Šé‡", f"{weight_gpt:.1f}")
    else:
        st.info("ï¿½ï¿½å±¤è©•ä¼°æ¨¡å¼ï¼ˆåƒ…é—œéµè©ï¼‰")
        weight_keyword = 1.0
        weight_semantic = 0.0
        weight_gpt = 0.0

    weights = {
        "keyword": weight_keyword,
        "semantic": weight_semantic,
        "gpt": weight_gpt
    }

    # é¡¯è‘—æ”¹å–„é–¾å€¼
    st.markdown("### ğŸ¯ åˆ†æè¨­å®š")
    improvement_threshold = st.slider(
        "é¡¯è‘—æ”¹å–„é–¾å€¼ (%)",
        min_value=5,
        max_value=50,
        value=10,
        help="ç•¶æ”¹å–„å¹…åº¦è¶…éæ­¤é–¾å€¼æ™‚ï¼Œæ¨™è¨˜ç‚ºé¡¯è‘—æ”¹å–„"
    )

    # æ­·å²ç´€éŒ„ç®¡ç†
    st.markdown("### ğŸ“š æ­·å²ç´€éŒ„")
    all_evaluations = st.session_state.history_manager.get_all_evaluations()
    stats = st.session_state.history_manager.get_statistics()

    st.metric("ç´¯è¨ˆè©•ä¼°é¡Œæ•¸", stats["total_evaluations"])
    st.metric("å·²è©•ä¼°æª”æ¡ˆæ•¸", stats["files_evaluated"])

    if stats["total_evaluations"] > 0:
        st.metric(
            "å¹³å‡æ”¹å–„å¹…åº¦",
            f"{stats['avg_improvement']:.1f}",
            delta=f"{stats['avg_improvement']:.1f}%"
        )

    # åŒ¯å‡ºæ­·å²ç´€éŒ„æŒ‰éˆ•
    if st.button("ğŸ“¥ åŒ¯å‡ºå®Œæ•´æ­·å²ç´€éŒ„", use_container_width=True):
        output_path = f"evaluation_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        if st.session_state.history_manager.export_to_excel(output_path):
            st.success(f"âœ… å·²åŒ¯å‡ºåˆ° {output_path}")
        else:
            st.error("âŒ åŒ¯å‡ºå¤±æ•—")

    # æ¸…é™¤æ­·å²ç´€éŒ„æŒ‰éˆ•
    if st.button("ğŸ—‘ï¸ æ¸…é™¤æ­·å²ç´€éŒ„", type="secondary", use_container_width=True):
        if st.session_state.history_manager.clear_history():
            st.success("âœ… æ­·å²ç´€éŒ„å·²æ¸…é™¤")
            st.rerun()
        else:
            st.error("âŒ æ¸…é™¤å¤±æ•—")

# ä¸»è¦å…§å®¹å€
if uploaded_file is not None:
    # è™•ç†æª”æ¡ˆ
    if isinstance(uploaded_file, str):
        temp_file_path = uploaded_file
        # è¨­å®šç•¶å‰æª”æ¡ˆåç¨±ï¼ˆç”¨æ–¼æ­·å²ç´€éŒ„ï¼‰
        st.session_state.current_excel_filename = os.path.basename(uploaded_file)
    else:
        temp_file_path = "temp_comparison_file.xlsx"
        with open(temp_file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        # è¨­å®šç•¶å‰æª”æ¡ˆåç¨±ï¼ˆç”¨æ–¼æ­·å²ç´€éŒ„ï¼‰
        st.session_state.current_excel_filename = uploaded_file.name

    # æ ¹æ“šé¸æ“‡çš„çŸ¥è­˜åº«é¡å‹å»ºç«‹è©•ä¼°å™¨
    try:
        if original_kb == "å‘é‡çŸ¥è­˜åº«" and optimized_kb == "æ™ºæ…§æ–‡æª”çŸ¥è­˜åº«":
            model_type = "cross"
        elif original_kb == "å‘é‡çŸ¥è­˜åº«":
            model_type = "vector"
        else:
            model_type = "smart_doc"

        evaluator = RAGEvaluatorV2(
            temp_file_path,
            model_type=model_type,
            enable_semantic=enable_semantic,
            enable_gpt=False,  # æˆ‘å€‘ä½¿ç”¨äººå·¥è©•å¯©ï¼Œä¸ä½¿ç”¨ API
            weights=weights
        )

        # å¦‚æœèªç¾©ç›¸ä¼¼åº¦åœ¨è¼‰å…¥éšæ®µè¢«åœç”¨ï¼Œæé†’ä½¿ç”¨è€…ä¸¦åŒæ­¥ç‹€æ…‹
        if enable_semantic and not evaluator.enable_semantic:
            st.warning("âš ï¸ èªç¾©ç›¸ä¼¼åº¦æ¨¡å‹æœªå•Ÿå‹•ï¼Œè«‹ç¢ºèªå·²å®‰è£ sentence-transformers èˆ‡ torch å¥—ä»¶ã€‚")

        enable_semantic = evaluator.enable_semantic
        weights = evaluator.weights

        st.session_state.evaluator_instance = evaluator

        # åŸ·è¡Œè©•ä¼°ï¼ˆä¸åŒ…å« GPTï¼ŒGPT ç”±äººå·¥æä¾›ï¼‰
        # æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰è©•ä¼°çµæœï¼ˆé¿å…é‡è¤‡è©•ä¼°å°è‡´èªç¾©ç›¸ä¼¼åº¦ä¸Ÿå¤±ï¼‰
        if st.session_state.comparison_results is None:
            with st.spinner("ğŸ”„ æ­£åœ¨é€²è¡Œè©•ä¼°åˆ†æ..."):
                results_df = evaluator.evaluate_all()
                st.session_state.comparison_results = results_df
        else:
            # å·²ç¶“æœ‰è©•ä¼°çµæœï¼Œç›´æ¥ä½¿ç”¨
            results_df = st.session_state.comparison_results

        # å¾æ­·å²ç´€éŒ„è¼‰å…¥ GPT è©•åˆ†ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        if not st.session_state.gpt_responses_loaded and st.session_state.current_excel_filename:
            loaded_count = load_gpt_from_history(st.session_state.current_excel_filename)
            if loaded_count > 0:
                st.success(f"âœ… å¾æ­·å²ç´€éŒ„æ¢å¾©äº† {loaded_count} ç­† GPT è©•åˆ†")
            st.session_state.gpt_responses_loaded = True

        # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
        if os.path.exists(temp_file_path) and not isinstance(uploaded_file, str):
            os.remove(temp_file_path)

    except Exception as e:
        st.error(f"âŒ è©•ä¼°éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        if os.path.exists(temp_file_path) and not isinstance(uploaded_file, str):
            os.remove(temp_file_path)
        st.stop()

    # å»ºç«‹é ç±¤
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs(
        [
            "ğŸ“Š è©•ä¼°ç¸½è¦½",
            "ğŸ¤– GPT äººå·¥è©•å¯©",
            "ğŸ“ˆ ç¶œåˆæ¯”è¼ƒåœ–è¡¨",
            "ğŸ”¤ èªç¾©åˆ†æ",
            "ğŸ’¬ GPTåˆ†æ",
            "ğŸ¯ é—œéµè©åˆ†æ",
            "ğŸ“¥ ä¸‹è¼‰çµæœ",
            "ğŸ“ GPT è£œå……èªªæ˜"
        ]
    )

    with tab1:
        st.markdown("### ğŸ“Š è©•ä¼°ç¸½è¦½")

        # è¨ˆç®—åŒ…å« GPT çš„ç¶œåˆè©•åˆ†
        results_df = st.session_state.comparison_results.copy()

        selected_gpt_dims = get_selected_gpt_dimensions()
        selected_gpt_weights = get_gpt_dimension_weights(selected_gpt_dims)
        selected_weight_summary = format_gpt_weight_summary(selected_gpt_dims, selected_gpt_weights)

        # åŠ å…¥ GPT è©•åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰- ä½¿ç”¨å¯¦éš›åºè™Ÿè€Œé DataFrame index
        for idx in range(len(results_df)):
            # å–å¾—è©²è¡Œçš„å¯¦éš›åºè™Ÿ
            actual_q_id = int(results_df.iloc[idx]['åºè™Ÿ'])

            if actual_q_id in st.session_state.gpt_responses_original:
                gpt_data = st.session_state.gpt_responses_original[actual_q_id]
                results_df.at[idx, 'GPT_OVERALL_ORIGINAL'] = compute_gpt_overall(
                    gpt_data, selected_gpt_dims, selected_gpt_weights
                )
                results_df.at[idx, 'GPT_OVERALL_ORIGINAL_RAW'] = gpt_data.get('overall', 0)
            else:
                results_df.at[idx, 'GPT_OVERALL_ORIGINAL'] = 0
                results_df.at[idx, 'GPT_OVERALL_ORIGINAL_RAW'] = 0

            if actual_q_id in st.session_state.gpt_responses_optimized:
                gpt_data = st.session_state.gpt_responses_optimized[actual_q_id]
                results_df.at[idx, 'GPT_OVERALL_OPTIMIZED'] = compute_gpt_overall(
                    gpt_data, selected_gpt_dims, selected_gpt_weights
                )
                results_df.at[idx, 'GPT_OVERALL_OPTIMIZED_RAW'] = gpt_data.get('overall', 0)
            else:
                results_df.at[idx, 'GPT_OVERALL_OPTIMIZED'] = 0
                results_df.at[idx, 'GPT_OVERALL_OPTIMIZED_RAW'] = 0

        # é‡æ–°è¨ˆç®—ç¶œåˆè©•åˆ†ï¼ˆåŒ…å« GPTï¼‰
        # æ³¨æ„ï¼šä¸è¦†è“‹åŸå§‹ results_dfï¼Œä¿ç•™åŸå§‹çš„èªç¾©ç›¸ä¼¼åº¦åˆ†æ•¸
        results_df['FINAL_SCORE_ORIGINAL'] = (
            results_df['KEYWORD_COVERAGE_ORIGINAL'] * weights['keyword'] +
            results_df['SEMANTIC_SIMILARITY_ORIGINAL'] * weights['semantic'] +
            results_df['GPT_OVERALL_ORIGINAL'] * weights['gpt']
        )

        results_df['FINAL_SCORE_OPTIMIZED'] = (
            results_df['KEYWORD_COVERAGE_OPTIMIZED'] * weights['keyword'] +
            results_df['SEMANTIC_SIMILARITY_OPTIMIZED'] * weights['semantic'] +
            results_df['GPT_OVERALL_OPTIMIZED'] * weights['gpt']
        )

        results_df['FINAL_IMPROVEMENT'] = (
            results_df['FINAL_SCORE_OPTIMIZED'] - results_df['FINAL_SCORE_ORIGINAL']
        )

        # âš ï¸ ä¸è¦è¦†è“‹ session_stateï¼ä¿ç•™åŸå§‹è©•ä¼°æ•¸æ“š
        # st.session_state.comparison_results = results_df  # <-- ç§»é™¤é€™è¡Œ

        # é—œéµæŒ‡æ¨™å¡ç‰‡
        overview_blocks = []

        def render_overall():
            st.markdown("**ğŸ“ˆ ç¶œåˆè©•åˆ†**")
            avg_orig = results_df['FINAL_SCORE_ORIGINAL'].mean()
            avg_opt = results_df['FINAL_SCORE_OPTIMIZED'].mean()
            improvement = avg_opt - avg_orig
            color = '#28a745' if improvement > 0 else '#dc3545'
            st.markdown(f"<h1 style='color: {color}; margin: 0;'>{avg_opt:.1f}åˆ†</h1>", unsafe_allow_html=True)
            st.markdown(f"<p style='color: {color}; font-size: 18px;'>{'â†‘' if improvement > 0 else 'â†“'} {abs(improvement):.1f}åˆ†</p>", unsafe_allow_html=True)
            st.caption(
                "ä¾ç…§ç›®å‰æ¬Šé‡ (é—œéµè© {keyword:.0%} / èªç¾© {semantic:.0%} / GPT {gpt:.0%})"
                " å°æ¯é¡Œçš„ä¸‰å±¤åˆ†æ•¸åšåŠ æ¬Šå¹³å‡å¾Œï¼Œå†å–æ‰€æœ‰é¡Œç›®çš„å¹³å‡åˆ†ã€‚".format(
                    keyword=weights['keyword'],
                    semantic=weights['semantic'],
                    gpt=weights['gpt']
                )
            )

        def render_keyword():
            st.markdown("**ğŸ¯ é—œéµè©è¦†è“‹ç‡**")
            keyword_improvement = results_df['KEYWORD_COVERAGE_OPTIMIZED'].mean() - results_df['KEYWORD_COVERAGE_ORIGINAL'].mean()
            color = '#28a745' if keyword_improvement > 0 else '#dc3545'
            st.markdown(f"<h1 style='color: {color}; margin: 0;'>{results_df['KEYWORD_COVERAGE_OPTIMIZED'].mean():.1f}%</h1>", unsafe_allow_html=True)
            st.markdown(f"<p style='color: {color}; font-size: 18px;'>{'â†‘' if keyword_improvement > 0 else 'â†“'} {abs(keyword_improvement):.1f}%</p>", unsafe_allow_html=True)
            st.caption("è‡ªå‹•æ¯”å°å›ç­”èˆ‡ã€æ‡‰å›ç­”ä¹‹è©å½™ã€çš„å‘½ä¸­æ¯”ä¾‹ï¼Œå¹³å‡æ‰€æœ‰é¡Œç›®å¾Œå–å¾—æ­¤æ•¸å€¼ã€‚")

        def render_semantic():
            if enable_semantic:
                st.markdown("**ğŸ”¤ èªç¾©ç›¸ä¼¼åº¦**")
                semantic_improvement = results_df['SEMANTIC_SIMILARITY_OPTIMIZED'].mean() - results_df['SEMANTIC_SIMILARITY_ORIGINAL'].mean()
                color = '#28a745' if semantic_improvement > 0 else '#dc3545'
                st.markdown(f"<h1 style='color: {color}; margin: 0;'>{results_df['SEMANTIC_SIMILARITY_OPTIMIZED'].mean():.1f}%</h1>", unsafe_allow_html=True)
                st.markdown(f"<p style='color: {color}; font-size: 18px;'>{'â†‘' if semantic_improvement > 0 else 'â†“'} {abs(semantic_improvement):.1f}%</p>", unsafe_allow_html=True)
                st.caption("ä½¿ç”¨ Sentence-Transformers é‡æ¸¬ã€æ‡‰å›ç­”å…§å®¹ã€èˆ‡å¯¦éš›å›ç­”çš„å‘é‡é¤˜å¼¦ç›¸ä¼¼åº¦ï¼Œå–æ‰€æœ‰é¡Œç›®å¹³å‡å€¼ã€‚")
            else:
                st.info("èªç¾©ç›¸ä¼¼åº¦æœªå•Ÿç”¨")

        def render_gpt():
            if enable_manual_gpt:
                st.markdown("**ğŸ¤– GPT è©•åˆ†**")

                gpt_original_ids = set(st.session_state.gpt_responses_original.keys())
                gpt_optimized_ids = set(st.session_state.gpt_responses_optimized.keys())
                evaluated_question_ids = gpt_original_ids | gpt_optimized_ids
                total_count = len(results_df)
                selected_dims = selected_gpt_dims
                selected_summary_local = selected_weight_summary

                if evaluated_question_ids:
                    seq_series = results_df['åºè™Ÿ'].astype(int)

                    mask_opt = seq_series.isin(gpt_optimized_ids)
                    mask_orig = seq_series.isin(gpt_original_ids)
                    mask_both = seq_series.isin(gpt_original_ids & gpt_optimized_ids)

                    avg_opt = results_df.loc[mask_opt, 'GPT_OVERALL_OPTIMIZED'].mean() if mask_opt.any() else None
                    avg_orig = results_df.loc[mask_orig, 'GPT_OVERALL_ORIGINAL'].mean() if mask_orig.any() else None

                    display_score = avg_opt if avg_opt is not None else avg_orig
                    if display_score is not None:
                        color = '#2196F3'
                        delta_html = ""

                        if mask_both.any():
                            improvement = (
                                results_df.loc[mask_both, 'GPT_OVERALL_OPTIMIZED'].mean() -
                                results_df.loc[mask_both, 'GPT_OVERALL_ORIGINAL'].mean()
                            )
                            if improvement > 0:
                                color = '#28a745'
                                delta_html = f"<p style='color: {color}; font-size: 18px;'>â†‘ {abs(improvement):.1f}åˆ†</p>"
                            elif improvement < 0:
                                color = '#dc3545'
                                delta_html = f"<p style='color: {color}; font-size: 18px;'>â†“ {abs(improvement):.1f}åˆ†</p>"
                            else:
                                delta_html = f"<p style='color: {color}; font-size: 18px;'>â†’ 0.0åˆ†</p>"

                        st.markdown(
                            f"<h1 style='color: {color}; margin: 0;'>{display_score:.1f}åˆ†</h1>",
                            unsafe_allow_html=True
                        )
                        if delta_html:
                            st.markdown(delta_html, unsafe_allow_html=True)
                        st.caption(
                            "äººå·¥ GPT è©•å¯©ä¾ç…§{summary}çš„åŠ æ¬Šå¹³å‡ï¼›è‹¥å…©ç‰ˆæœ¬çš†å®Œæˆè©•å¯©æœƒé¡¯ç¤ºæ”¹é€²å¹…åº¦ã€‚".format(
                                summary=selected_summary_local
                            )
                        )
                    else:
                        st.info("å°šæœªå¡«å…¥ GPT è©•åˆ†")

                    st.markdown(
                        f"<p style='font-size: 16px;'>å·²è©•å¯©é¡Œæ•¸ï¼š{len(evaluated_question_ids)}/{total_count}</p>",
                        unsafe_allow_html=True
                    )
                else:
                    st.info("å°šæœªå¡«å…¥ GPT è©•åˆ†")
            else:
                st.info("GPT è©•å¯©æœªå•Ÿç”¨")

        overview_blocks.append(render_overall)
        overview_blocks.append(render_keyword)

        show_semantic_metric = st.session_state.display_semantic_metric
        if enable_semantic and show_semantic_metric:
            overview_blocks.append(render_semantic)

        overview_blocks.append(render_gpt)

        cols = st.columns(len(overview_blocks))
        for col, renderer in zip(cols, overview_blocks):
            with col:
                renderer()

        # è©•ä¼°å±¤ç´šé…ç½®é¡¯ç¤º
        st.markdown("### âš™ï¸ è©•ä¼°é…ç½®")
        config_col1, config_col2, config_col3 = st.columns(3)

        with config_col1:
            st.metric("é—œéµè©åŒ¹é…", "âœ… å•Ÿç”¨", f"æ¬Šé‡: {weights['keyword']:.0%}")

        with config_col2:
            status = "âœ… å•Ÿç”¨" if enable_semantic else "âŒ åœç”¨"
            st.metric("èªç¾©ç›¸ä¼¼åº¦", status, f"æ¬Šé‡: {weights['semantic']:.0%}")

        with config_col3:
            status = "âœ… å•Ÿç”¨" if enable_manual_gpt else "âŒ åœç”¨"
            st.metric("GPT äººå·¥è©•å¯©", status, f"æ¬Šé‡: {weights['gpt']:.0%}")

    with tab2:
        st.markdown("### ğŸ¤– GPT äººå·¥è©•å¯©åŠ©æ‰‹")
        st.info("ğŸ’¡ åœ¨é€™è£¡ç”Ÿæˆ prompt â†’ è¤‡è£½åˆ° ChatGPT â†’ è²¼å›è©•åˆ†çµæœ â†’ æ‰€æœ‰æŒ‡æ¨™å³æ™‚æ›´æ–°")

        st.markdown("#### ğŸ§® GPT ç¶œåˆè©•åˆ†ç¶­åº¦")
        available_gpt_dims = list(GPT_DIMENSION_LABELS.keys())
        selected_from_widget = st.multiselect(
            "é¸æ“‡è¦ç´å…¥ç¶œåˆè©•åˆ†çš„ç¶­åº¦",
            options=available_gpt_dims,
            default=st.session_state.gpt_selected_dimensions,
            format_func=lambda x: GPT_DIMENSION_LABELS[x],
            key="gpt_dimension_selector"
        )

        if selected_from_widget:
            st.session_state.gpt_selected_dimensions = selected_from_widget
        else:
            st.warning("è‡³å°‘éœ€è¦ä¿ç•™ä¸€å€‹ç¶­åº¦æ‰èƒ½è¨ˆç®—ç¶œåˆè©•åˆ†ï¼Œå·²æ²¿ç”¨å‰æ¬¡è¨­å®šã€‚")
            if not st.session_state.gpt_selected_dimensions:
                st.session_state.gpt_selected_dimensions = available_gpt_dims
            selected_from_widget = st.session_state.gpt_selected_dimensions
        weight_cols = st.columns(len(selected_from_widget)) if selected_from_widget else []
        new_weights = {}
        for col, dim in zip(weight_cols, selected_from_widget):
            with col:
                default_weight = st.session_state.gpt_dimension_weights.get(dim, 0.25)
                new_weights[dim] = st.number_input(
                    GPT_DIMENSION_LABELS[dim],
                    min_value=0.0,
                    value=float(default_weight),
                    step=0.05,
                    key=f"weight_input_{dim}"
                )

        if new_weights:
            st.session_state.gpt_dimension_weights.update(new_weights)

        selected_gpt_dims_tab2 = st.session_state.gpt_selected_dimensions
        selected_gpt_weights_tab2 = get_gpt_dimension_weights(selected_gpt_dims_tab2)
        selected_weight_summary_tab2 = format_gpt_weight_summary(selected_gpt_dims_tab2, selected_gpt_weights_tab2)

        st.caption(
            "ç³»çµ±æœƒè‡ªå‹•æ ¹æ“šå‹¾é¸çš„ç¶­åº¦èˆ‡æŒ‡å®šæ¬Šé‡é‡æ–°è¨ˆç®—æ¯é¡Œèˆ‡æ•´é«”çš„ GPT ç¶œåˆè©•åˆ†ã€‚"
        )
        st.caption(f"ç›®å‰åŠ æ¬Šè¨­å®šï¼š{selected_weight_summary_tab2}")

        # è©•åˆ†ä¸€è‡´æ€§æŒ‡å°
        with st.expander("ğŸ“ è©•åˆ†æŒ‡æ¨™èªªæ˜", expanded=False):
            st.markdown("""
            #### ğŸ¯ ç¢ºä¿è©•åˆ†ä¸€è‡´æ€§çš„ä½¿ç”¨æ–¹æ³•
            
            **1. *åš´è¬¹ä¸”å›ºå®šçš„è©•åˆ†æ©Ÿåˆ¶**  
            æˆ‘å€‘é‡å°å››å€‹æ ¸å¿ƒç¶­åº¦ï¼ˆğŸ¯ ç›¸é—œæ€§ã€ğŸ“‹ å®Œæ•´æ€§ã€âœ… æº–ç¢ºæ€§ã€ğŸ”’ å¿ èª åº¦ï¼‰å»ºç«‹äº†æ˜ç¢ºä¸”å¯é‡åŒ–çš„è©•ä¼°æµç¨‹ï¼Œç¢ºä¿æ¯ä¸€æ¬¡è©•åˆ†éƒ½åœ¨ç›¸åŒæ¨™æº–ä¸‹åŸ·è¡Œï¼š
            - (1)å›ºå®šåˆ†ç´šæ¨™æº–ï¼šåˆ†æ•¸å€é–“èˆ‡æ¯”ä¾‹ï¼ˆå¦‚ â‰¥90% ç‚ºæ»¿åˆ†ï¼‰äº‹å…ˆå®šç¾©ï¼Œæ¨¡å‹ä¸å¾—è‡ªè¡Œèª¿æ•´ã€‚
            - (2)æ˜ç¢ºè¨ˆç®—æ–¹å¼ï¼šæ¯å€‹ç¶­åº¦å‡ä»¥æ¯”ä¾‹å…¬å¼è¨ˆç®—ï¼ˆå¦‚è²¼é¡Œå¥ï¼ç¸½å¥ã€æ­£ç¢ºå¥ï¼(æ­£ç¢ºï¼‹éŒ¯èª¤) ç­‰ï¼‰ï¼Œå†å°ç…§æ¨™æº–åˆ†æ•¸è¡¨ã€‚
            - (3)çµ±ä¸€æ¨™è¨˜æµç¨‹ï¼šæ‰€æœ‰è©•åˆ†çš†ä¾ã€Œæ‹†å¥ â†’ æ¨™è¨˜ â†’ è¨ˆç®— â†’ å°ç…§åˆ†æ•¸æ®µ â†’ è¼¸å‡ºçµæœã€äº”æ­¥é©Ÿé€²è¡Œã€‚
            - (4)è¦æ±‚å…·é«”æ•¸æ“šï¼šæ¨¡å‹å¿…é ˆåœ¨ reasoning ä¸­åˆ—å‡ºå…·é«”æ¸…å–®èˆ‡è¨ˆç®—çµæœï¼ˆå¦‚å‘½ä¸­è¦é»æ•¸ã€Supported å¥ç­‰ï¼‰ï¼Œæ¯ä¸€åˆ†çš†æœ‰ä¾æ“šã€‚
            - (5)çµ±ä¸€è¼¸å‡ºæ ¼å¼ï¼šä»¥å›ºå®š JSON æ¬„ä½å‘ˆç¾è©•åˆ†èˆ‡ reasoningï¼Œç¦æ­¢æ–°å¢æˆ–åˆªæ”¹çµæ§‹ã€‚
            - (6)äººé¡èªæ°£èˆ‡é©—è­‰æç¤ºï¼šåœ¨è§£é‡‹ä¸­ä»¥è‡ªç„¶èªæ°£èªªæ˜æ‰“åˆ†åŸå› ï¼Œä¸¦æé†’ã€Œè«‹åˆ—å‡ºæ‰€æœ‰ä¸­é–“è¨ˆç®—æ•¸æ“šã€ï¼Œå¼·åŒ–é€æ˜åº¦ã€‚
            - (7)ä¸€è‡´æ€§æé†’ï¼šPrompt é–‹é ­è¨»æ˜åƒè€ƒæµç¨‹ï¼Œçµå°¾é‡ç”³ã€Œè«‹åš´æ ¼ä¾ä¸Šè¿°æ­¥é©Ÿèˆ‡å…¬å¼åŸ·è¡Œã€ï¼Œæœçµ•ä»»æ„è®Šå‹•ã€‚    
            
            **2. è©•åˆ†æŒ‡æ¨™èªªæ˜**
            - ğŸ¯ ç›¸é—œæ€§ï¼šå›ç­”æœ‰æ²’æœ‰é‡å°å•é¡Œä¾†å›ç­”
            - ğŸ“‹ å®Œæ•´æ€§ï¼šå›ç­”æœ‰æ²’æœ‰åŒ…å«æ‡‰è©²è¦æœ‰çš„é‡è¦è³‡è¨Šï¼ˆèˆ‡è¦†è“‹ç‡çš„å·®ç•°ç‚ºæ˜¯å¦æœ‰é‡å°å…§å®¹åšæ·±åº¦è£œå……ï¼‰
            - âœ… æº–ç¢ºæ€§ï¼šå›ç­”çš„å…§å®¹æ˜¯ä¸æ˜¯æ­£ç¢ºçš„ï¼Œæœ‰æ²’æœ‰éŒ¯èª¤è³‡è¨Šï¼ˆèˆ‡å®Œæ•´æ€§çš„å·®ç•°ç‚ºä¸ç®¡æœ‰æ²’æœ‰éºæ¼ï¼Œåªçœ‹èªªçš„å…§å®¹å°ä¸å°ï¼‰
            - ğŸ”’ å¿ èª åº¦ï¼šå›æ‡‰å…§å®¹åš´æ ¼æºè‡ªåŸå§‹è³‡æ–™ï¼Œæ‰€æœ‰é™³è¿°çš†æœ‰è³‡æ–™æ”¯æ’ï¼Œæœªæ·»åŠ ä»»ä½•æœªæª¢ç´¢å¾Œæˆ–æ˜¯å…¶ä»–è£œå……çš„è³‡è¨Šã€‚ 
            
            **3. è©•åˆ†æŒ‡æ¨™ç°¡å–®èªªæ˜**
            - **ğŸ¯ ç›¸é—œæ€§**ï¼šæŠŠå›ç­”æ‹†æˆå¥å­ï¼Œæ¨™è¨˜è²¼é¡Œï¼é›¢é¡Œä¸¦è¨ˆç®—è²¼é¡Œæ¯”ä¾‹ã€‚
            - **ğŸ“‹ å®Œæ•´æ€§**ï¼šé€é …æª¢æŸ¥ã€å¿…é ˆåŒ…å«çš„é—œéµè³‡è¨Šã€‘ï¼Œæ¨™è¨˜å‘½ä¸­ï¼éƒ¨åˆ†å‘½ä¸­ï¼ç¼ºæ¼ã€‚
            - **âœ… æº–ç¢ºæ€§**ï¼šåˆ—å‡ºå¯é©—è­‰é™³è¿°ï¼Œæ¨™è¨˜æ­£ç¢ºï¼éŒ¯èª¤ï¼ä¸å¯é©—è­‰ï¼Œè¨ˆç®—æ­£ç¢ºç‡ã€‚
            - **ğŸ”’ å¿ èª åº¦**ï¼šæª¢æŸ¥æ¯å¥æ˜¯å¦æœ‰è³‡æ–™ä½è­‰ï¼Œæ¨™è¨˜ Supportedï¼Partiallyï¼Unsupportedã€‚
            
            **4. è©•åˆ†æŒ‡æ¨™è©•åˆ†è¦å‰‡**
            - **ğŸ¯ ç›¸é—œæ€§**ï¼šå°‡æ¯ä¸€å¥è©±éƒ½åˆ†æˆã€Œæœ‰å›ç­”åˆ°é¡Œç›®ã€æˆ–ã€Œåé›¢é¡Œæ„ã€ï¼Œç®—å‡ºæœ‰å¹¾å¥æ˜¯å°é¡Œç›®çš„ï¼Œç„¶å¾Œçœ‹æ¯”ä¾‹æœ‰å¤šé«˜ï¼Œé«˜æ–¼ä¹æˆå°±æ‹¿æœ€é«˜åˆ†ã€‚
            - **ğŸ“‹ å®Œæ•´æ€§**ï¼šåˆ—å‡ºä¸€å®šè¦æåˆ°çš„é‡é»ï¼Œä¾‹å¦‚ã€ŒåŸå› ã€ã€Œæ­¥é©Ÿã€ã€Œçµæœã€ç­‰ï¼Œæª¢æŸ¥å“ªäº›å®Œå…¨å¯«åˆ°äº†ï¼ˆCoveredï¼‰ã€å“ªäº›åªå¯«åˆ°ä¸€åŠï¼ˆPartiallyï¼‰ã€å“ªäº›æ²’å¯«ï¼ˆMissingï¼‰ã€‚ç”¨ã€Œå…¨éƒ¨é‡é»å‘½ä¸­çš„æ•¸é‡ï¼‹ä¸€åŠç®—éƒ¨åˆ†å‘½ä¸­ã€é™¤ä»¥é‡é»ç¸½æ•¸ï¼Œå°±èƒ½å¾—å‡ºä¸€å€‹æ¯”ä¾‹ï¼Œæ¯”ä¾‹è¶Šé«˜åˆ†æ•¸è¶Šé«˜ã€‚
            - **âœ… æº–ç¢ºæ€§**ï¼šæŠŠå›ç­”è£¡èƒ½æŸ¥è­‰çš„æ¯ä»¶äº‹éƒ½æ‹†å‡ºä¾†ï¼Œçœ‹å“ªäº›æ˜¯çœŸçš„ï¼ˆCorrectï¼‰ã€å“ªäº›æ˜é¡¯éŒ¯äº†ï¼ˆIncorrectï¼‰ã€å“ªäº›æŸ¥ä¸åˆ°ï¼ˆUnverifiableï¼‰ã€‚è¨ˆç®—ã€Œæ­£ç¢º Ã· (æ­£ç¢ºï¼‹éŒ¯èª¤)ã€ï¼Œå¦‚æœæ­£ç¢ºç‡é”åˆ° 95% å°±æ‹¿æ»¿åˆ†ã€‚
            - **ğŸ”’ å¿ èª åº¦**ï¼šæŠŠæ¯ä¸€å¥è©±éƒ½å°ç…§åŸå§‹è³‡æ–™ï¼Œçœ‹æœ‰å¤šå°‘å¥å­æ˜¯ã€Œæœ‰ä¾†æºè­‰æ˜ã€ï¼ˆSupportedï¼‰ã€å¤šå°‘å¥å­åªæ˜¯ã€Œéƒ¨åˆ†ç¬¦åˆã€ï¼ˆPartially Supportedï¼‰ã€å¤šå°‘æ˜¯ã€Œæœæ’°æˆ–æ²’ä¾æ“šã€ï¼ˆUnsupportedï¼‰ã€‚åŒæ¨£ç”¨ã€Œæœ‰ä¾†æºï¼‹ä¸€åŠç®—éƒ¨åˆ†ã€é™¤ä»¥ç¸½å¥æ•¸çš„æ–¹å¼ç®—æ¯”ä¾‹ï¼Œæ¯”ä¾‹è¶Šé«˜ä»£è¡¨è¶Šå¿ å¯¦ã€‚
            """)
            
            st.success("âœ… éµå¾ªä»¥ä¸ŠæŒ‡å°ï¼Œå¯ç¢ºä¿è©•åˆ†çš„ä¸€è‡´æ€§å’Œæº–ç¢ºæ€§ï¼")

        # é¸æ“‡è¦è©•å¯©çš„å•é¡Œ
        question_selector = st.selectbox(
            "é¸æ“‡è¦è©•å¯©çš„å•é¡Œ",
            range(len(results_df)),
            format_func=lambda x: f"å•é¡Œ {results_df.iloc[x]['åºè™Ÿ']}: {results_df.iloc[x]['æ¸¬è©¦å•é¡Œ'][:40]}..."
        )

        selected_row = results_df.iloc[question_selector]
        # ä½¿ç”¨å¯¦éš›åºè™Ÿä½œç‚º GPT è©•åˆ†çš„ keyï¼ˆè€Œä¸æ˜¯ DataFrame indexï¼‰
        actual_question_id = int(selected_row['åºè™Ÿ'])

        # é¡¯ç¤ºå•é¡Œè³‡è¨Š
        st.markdown("#### ğŸ“ å•é¡Œè³‡è¨Š")
        st.info(f"**å•é¡Œ**: {selected_row['æ¸¬è©¦å•é¡Œ']}")
        st.success(f"**æ‡‰å›ç­”è©å½™**: {selected_row['æ‡‰å›ç­”ä¹‹è©å½™']}")

        # ç”Ÿï¿½ï¿½ prompt å€åŸŸ
        version_col1, version_col2 = st.columns(2)

        with version_col1:
            st.markdown("#### ğŸ”´ åŸå§‹ç‰ˆæœ¬")

            # é¡¯ç¤ºåŸå§‹å›ç­”
            with st.expander("æŸ¥çœ‹åŸå§‹å›ç­”"):
                st.text_area("", value=selected_row['ANSWER_ORIGINAL'], height=150, key="orig_answer_view", disabled=True)

            # ç”Ÿæˆ Prompt
            prompt_original = generate_gpt_prompt(
                selected_row['æ¸¬è©¦å•é¡Œ'],
                selected_row['æ‡‰å›ç­”ä¹‹è©å½™'],
                selected_row['ANSWER_ORIGINAL'],
                version="åŸå§‹",
                question_id=selected_row['åºè™Ÿ']
            )

            st.markdown("**ğŸ“‹ GPT Promptï¼ˆè¤‡è£½åˆ° ChatGPTï¼‰**")
            st.text_area("", value=prompt_original, height=200, key=f"prompt_orig_{question_selector}")

            if st.button("ğŸ“‹ è¤‡è£½ Prompt (åŸå§‹ç‰ˆæœ¬)", key=f"copy_orig_{question_selector}"):
                st.success("âœ… Prompt å·²è¤‡è£½ï¼è«‹è²¼åˆ° ChatGPT")

            # è²¼ä¸Š GPT å›æ‡‰
            st.markdown("**ğŸ“¥ è²¼ä¸Š ChatGPT çš„ JSON å›æ‡‰**")
            gpt_response_original = st.text_area(
                "",
                height=150,
                key=f"gpt_response_orig_{question_selector}",
                placeholder='è²¼ä¸Š ChatGPT å›æ‡‰çš„ JSONï¼Œä¾‹å¦‚ï¼š\n{\n  "relevance": 85,\n  "completeness": 90,\n  ...\n}'
            )

            if st.button("âœ… ç¢ºèªä¸¦å„²å­˜è©•åˆ† (åŸå§‹ç‰ˆæœ¬)", key=f"save_orig_{question_selector}"):
                if gpt_response_original.strip():
                    parsed = parse_gpt_response(gpt_response_original)
                    if 'error' not in parsed:
                        # æ–°å¢ï¼šä¸€è‡´æ€§é©—è­‰
                        warnings, errors = validate_scoring_consistency(
                            parsed, 
                            selected_row['æ¸¬è©¦å•é¡Œ'], 
                            selected_row['ANSWER_ORIGINAL']
                        )
                        
                        if errors:
                            st.error("âŒ ç™¼ç¾åš´é‡å•é¡Œï¼Œç„¡æ³•å„²å­˜ï¼š")
                            for error in errors:
                                st.text(f"â€¢ {error}")
                            st.info("ğŸ’¡ è«‹é‡æ–°è«‹ChatGPTè©•åˆ†ï¼Œç¢ºä¿åŒ…å«æ‰€æœ‰å¿…è¦æ¬„ä½")
                        elif warnings:
                            st.warning("âš ï¸ ç™¼ç¾è©•åˆ†ä¸€è‡´æ€§å•é¡Œï¼š")
                            for warning in warnings:
                                st.text(f"â€¢ {warning}")
                            
                            col_a, col_b = st.columns(2)
                            with col_a:
                                if st.button("ğŸ”„ é‡æ–°è©•åˆ†", key=f"recheck_orig_{question_selector}"):
                                    st.info("å»ºè­°é‡æ–°è«‹ChatGPTè©•åˆ†ä»¥ç¢ºä¿ä¸€è‡´æ€§")
                            with col_b:
                                if st.button("ğŸ“¥ ä»è¦å„²å­˜", key=f"force_save_orig_{question_selector}"):
                                    st.session_state.gpt_responses_original[actual_question_id] = parsed
                                    st.success("âœ… åŸå§‹ç‰ˆæœ¬è©•åˆ†å·²å„²å­˜ï¼")
                                    
                                    # è‡ªå‹•ä¿å­˜åˆ°æ­·å²ç´€éŒ„
                                    if auto_save_evaluation(
                                        actual_question_id,
                                        results_df,
                                        weights,
                                        selected_gpt_dims_tab2,
                                        selected_gpt_weights_tab2
                                    ):
                                        st.info("ğŸ’¾ å·²è‡ªå‹•ä¿å­˜åˆ°æ­·å²ç´€éŒ„")
                                    
                                    st.rerun()
                        else:
                            st.session_state.gpt_responses_original[actual_question_id] = parsed
                            st.success("âœ… åŸå§‹ç‰ˆæœ¬è©•åˆ†å·²å„²å­˜ï¼è©•åˆ†æ ¼å¼å®Œå…¨æ­£ç¢º")
                            
                            # è‡ªå‹•ä¿å­˜åˆ°æ­·å²ç´€éŒ„
                            if auto_save_evaluation(
                                actual_question_id,
                                results_df,
                                weights,
                                selected_gpt_dims_tab2,
                                selected_gpt_weights_tab2
                            ):
                                st.info("ğŸ’¾ å·²è‡ªå‹•ä¿å­˜åˆ°æ­·å²ç´€éŒ„")
                            
                            st.rerun()
                    else:
                        st.error("âŒ ç„¡æ³•è§£æ JSONï¼Œè«‹æª¢æŸ¥æ ¼å¼")
                        st.text(f"éŒ¯èª¤è©³æƒ…ï¼š{parsed.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
                else:
                    st.warning("âš ï¸ è«‹å…ˆè²¼ä¸Š ChatGPT çš„å›æ‡‰")

            # é¡¯ç¤ºå·²å„²å­˜çš„è©•åˆ†
            if actual_question_id in st.session_state.gpt_responses_original:
                gpt_data = st.session_state.gpt_responses_original[actual_question_id]
                st.markdown("**ğŸ“Š å·²å„²å­˜çš„ GPT è©•åˆ†**")
                col_a, col_b = st.columns(2)
                with col_a:
                    st.metric("ç›¸é—œæ€§", f"{gpt_data.get('relevance', 0)}")
                    st.metric("æº–ç¢ºæ€§", f"{gpt_data.get('accuracy', 0)}")
                with col_b:
                    st.metric("å®Œæ•´æ€§", f"{gpt_data.get('completeness', 0)}")
                    st.metric("å¿ èª åº¦", f"{gpt_data.get('faithfulness', 0)}")
                computed_overall = compute_gpt_overall(
                    gpt_data,
                    selected_gpt_dims_tab2,
                    selected_gpt_weights_tab2
                )
                raw_overall = gpt_data.get('overall')
                try:
                    raw_overall_value = float(raw_overall)
                except (TypeError, ValueError):
                    raw_overall_value = None

                delta_text = None
                if raw_overall_value is not None and abs(computed_overall - raw_overall_value) > 0.01:
                    delta_text = f"{computed_overall - raw_overall_value:+.1f}"

                st.metric("ç¶œåˆè©•åˆ†", f"{computed_overall:.1f}", delta=delta_text)
                if raw_overall_value is not None and delta_text:
                    st.caption(f"åŸå§‹ ChatGPT overallï¼š{raw_overall_value:.1f} (æœªä¾é¸æ“‡ç¶­åº¦èª¿æ•´)")
                st.caption(f"ç›®å‰å– {selected_weight_summary_tab2} çš„åŠ æ¬Šå¹³å‡ã€‚")

        with version_col2:
            st.markdown("#### ğŸŸ¢ å„ªåŒ–ç‰ˆæœ¬")

            # é¡¯ç¤ºå„ªåŒ–å›ç­”
            with st.expander("æŸ¥çœ‹å„ªåŒ–å›ç­”"):
                st.text_area("", value=selected_row['ANSWER_OPTIMIZED'], height=150, key="opt_answer_view", disabled=True)

            # ç”Ÿæˆ Prompt
            prompt_optimized = generate_gpt_prompt(
                selected_row['æ¸¬è©¦å•é¡Œ'],
                selected_row['æ‡‰å›ç­”ä¹‹è©å½™'],
                selected_row['ANSWER_OPTIMIZED'],
                version="å„ªåŒ–",
                question_id=selected_row['åºè™Ÿ']
            )

            st.markdown("**ğŸ“‹ GPT Promptï¼ˆè¤‡è£½åˆ° ChatGPTï¼‰**")
            st.text_area("", value=prompt_optimized, height=200, key=f"prompt_opt_{question_selector}")

            if st.button("ğŸ“‹ è¤‡è£½ Prompt (å„ªåŒ–ç‰ˆæœ¬)", key=f"copy_opt_{question_selector}"):
                st.success("âœ… Prompt å·²è¤‡è£½ï¼è«‹è²¼åˆ° ChatGPT")

            # è²¼ä¸Š GPT å›æ‡‰
            st.markdown("**ğŸ“¥ è²¼ä¸Š ChatGPT çš„ JSON å›æ‡‰**")
            gpt_response_optimized = st.text_area(
                "",
                height=150,
                key=f"gpt_response_opt_{question_selector}",
                placeholder='è²¼ä¸Š ChatGPT å›æ‡‰çš„ JSONï¼Œä¾‹å¦‚ï¼š\n{\n  "relevance": 85,\n  "completeness": 90,\n  ...\n}'
            )

            if st.button("âœ… ç¢ºèªä¸¦å„²å­˜è©•åˆ† (å„ªåŒ–ç‰ˆæœ¬)", key=f"save_opt_{question_selector}"):
                if gpt_response_optimized.strip():
                    parsed = parse_gpt_response(gpt_response_optimized)
                    if 'error' not in parsed:
                        # æ–°å¢ï¼šä¸€è‡´æ€§é©—è­‰
                        warnings, errors = validate_scoring_consistency(
                            parsed, 
                            selected_row['æ¸¬è©¦å•é¡Œ'], 
                            selected_row['ANSWER_OPTIMIZED']
                        )
                        
                        if errors:
                            st.error("âŒ ç™¼ç¾åš´é‡å•é¡Œï¼Œç„¡æ³•å„²å­˜ï¼š")
                            for error in errors:
                                st.text(f"â€¢ {error}")
                            st.info("ğŸ’¡ è«‹é‡æ–°è«‹ChatGPTè©•åˆ†ï¼Œç¢ºä¿åŒ…å«æ‰€æœ‰å¿…è¦æ¬„ä½")
                        elif warnings:
                            st.warning("âš ï¸ ç™¼ç¾è©•åˆ†ä¸€è‡´æ€§å•é¡Œï¼š")
                            for warning in warnings:
                                st.text(f"â€¢ {warning}")
                            
                            col_a, col_b = st.columns(2)
                            with col_a:
                                if st.button("ğŸ”„ é‡æ–°è©•åˆ†", key=f"recheck_opt_{question_selector}"):
                                    st.info("å»ºè­°é‡æ–°è«‹ChatGPTè©•åˆ†ä»¥ç¢ºä¿ä¸€è‡´æ€§")
                            with col_b:
                                if st.button("ğŸ“¥ ä»è¦å„²å­˜", key=f"force_save_opt_{question_selector}"):
                                    st.session_state.gpt_responses_optimized[actual_question_id] = parsed
                                    st.success("âœ… å„ªåŒ–ç‰ˆæœ¬è©•åˆ†å·²å„²å­˜ï¼")
                                    
                                    # è‡ªå‹•ä¿å­˜åˆ°æ­·å²ç´€éŒ„
                                    if auto_save_evaluation(
                                        actual_question_id,
                                        results_df,
                                        weights,
                                        selected_gpt_dims_tab2,
                                        selected_gpt_weights_tab2
                                    ):
                                        st.info("ğŸ’¾ å·²è‡ªå‹•ä¿å­˜åˆ°æ­·å²ç´€éŒ„")
                                    
                                    st.rerun()
                        else:
                            st.session_state.gpt_responses_optimized[actual_question_id] = parsed
                            st.success("âœ… å„ªåŒ–ç‰ˆæœ¬è©•åˆ†å·²å„²å­˜ï¼è©•åˆ†æ ¼å¼å®Œå…¨æ­£ç¢º")
                            
                            # è‡ªå‹•ä¿å­˜åˆ°æ­·å²ç´€éŒ„
                            if auto_save_evaluation(
                                actual_question_id,
                                results_df,
                                weights,
                                selected_gpt_dims_tab2,
                                selected_gpt_weights_tab2
                            ):
                                st.info("ğŸ’¾ å·²è‡ªå‹•ä¿å­˜åˆ°æ­·å²ç´€éŒ„")
                            
                            st.rerun()
                    else:
                        st.error("âŒ ç„¡æ³•è§£æ JSONï¼Œè«‹æª¢æŸ¥æ ¼å¼")
                        st.text(f"éŒ¯èª¤è©³æƒ…ï¼š{parsed.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
                else:
                    st.warning("âš ï¸ è«‹å…ˆè²¼ä¸Š ChatGPT çš„å›æ‡‰")

            # é¡¯ç¤ºå·²å„²å­˜çš„è©•åˆ†
            if actual_question_id in st.session_state.gpt_responses_optimized:
                gpt_data = st.session_state.gpt_responses_optimized[actual_question_id]
                st.markdown("**ğŸ“Š å·²å„²å­˜çš„ GPT è©•åˆ†**")
                col_a, col_b = st.columns(2)
                with col_a:
                    st.metric("ç›¸é—œæ€§", f"{gpt_data.get('relevance', 0)}")
                    st.metric("æº–ç¢ºæ€§", f"{gpt_data.get('accuracy', 0)}")
                with col_b:
                    st.metric("å®Œæ•´æ€§", f"{gpt_data.get('completeness', 0)}")
                    st.metric("å¿ èª åº¦", f"{gpt_data.get('faithfulness', 0)}")
                computed_overall = compute_gpt_overall(
                    gpt_data,
                    selected_gpt_dims_tab2,
                    selected_gpt_weights_tab2
                )
                raw_overall = gpt_data.get('overall')
                try:
                    raw_overall_value = float(raw_overall)
                except (TypeError, ValueError):
                    raw_overall_value = None

                delta_text = None
                if raw_overall_value is not None and abs(computed_overall - raw_overall_value) > 0.01:
                    delta_text = f"{computed_overall - raw_overall_value:+.1f}"

                st.metric("ç¶œåˆè©•åˆ†", f"{computed_overall:.1f}", delta=delta_text)
                if raw_overall_value is not None and delta_text:
                    st.caption(f"åŸå§‹ ChatGPT overallï¼š{raw_overall_value:.1f} (æœªä¾é¸æ“‡ç¶­åº¦èª¿æ•´)")
                st.caption(f"ç›®å‰å– {selected_weight_summary_tab2} çš„åŠ æ¬Šå¹³å‡ã€‚")

        # æ‰¹æ¬¡æ“ä½œæç¤º
        st.markdown("---")
        st.markdown("### ğŸ“Š æ‰¹æ¬¡è©•å¯©é€²åº¦")

        total_questions = len(results_df)
        evaluated_original = len(st.session_state.gpt_responses_original)
        evaluated_optimized = len(st.session_state.gpt_responses_optimized)

        progress_col1, progress_col2 = st.columns(2)

        with progress_col1:
            st.metric("åŸå§‹ç‰ˆæœ¬å·²è©•å¯©", f"{evaluated_original}/{total_questions}",
                     f"{evaluated_original/total_questions*100:.1f}%")
            st.progress(evaluated_original / total_questions)

        with progress_col2:
            st.metric("å„ªåŒ–ç‰ˆæœ¬å·²è©•å¯©", f"{evaluated_optimized}/{total_questions}",
                     f"{evaluated_optimized/total_questions*100:.1f}%")
            st.progress(evaluated_optimized / total_questions)

        col_btn1, col_btn2 = st.columns(2)

        with col_btn1:
            if st.button("ğŸ’¾ æ‰‹å‹•ä¿å­˜å…¨éƒ¨åˆ°æ­·å²ç´€éŒ„", key="manual_save_all", type="primary", use_container_width=True):
                saved_count = 0
                for idx in range(len(results_df)):
                    if auto_save_evaluation(
                        idx,
                        results_df,
                        weights,
                        selected_gpt_dims_tab2,
                        selected_gpt_weights_tab2
                    ):
                        saved_count += 1
                st.success(f"âœ… æˆåŠŸä¿å­˜ {saved_count} ç­†è©•ä¼°åˆ°æ­·å²ç´€éŒ„")
                st.rerun()

        with col_btn2:
            if st.button("ğŸ”„ æ¸…é™¤æ‰€æœ‰ GPT è©•åˆ†", key="clear_all_gpt", use_container_width=True):
                st.session_state.gpt_responses_original = {}
                st.session_state.gpt_responses_optimized = {}
                st.success("âœ… å·²æ¸…é™¤æ‰€æœ‰ GPT è©•åˆ†")
                st.rerun()

    with tab3:
        st.markdown("### ğŸ“ˆ è©³ç´°å°æ¯”åˆ†æ")
        st.info("æ•´åˆä¸‰å±¤è©•ä¼°çµæœçš„å®Œæ•´å°æ¯”ï¼ˆåŒ…å«æ‚¨æä¾›çš„ GPT è©•åˆ†ï¼‰")

        # å»ºç«‹å¤šå±¤ç´šå°æ¯”è¡¨æ ¼
        comparison_data = []

        metrics = [
            ('é—œéµè©è¦†è“‹ç‡', 'KEYWORD_COVERAGE'),
        ]

        if enable_semantic:
            metrics.append(('èªç¾©ç›¸ä¼¼åº¦', 'SEMANTIC_SIMILARITY'))

        if enable_manual_gpt:
            metrics.append(('GPT è©•åˆ†', 'GPT_OVERALL'))

        metrics.append(('ç¶œåˆè©•åˆ†', 'FINAL_SCORE'))

        for metric_name, metric_key in metrics:
            comparison_data.append({
                'è©•ä¼°æŒ‡æ¨™': f'ğŸ”´ åŸå§‹ç‰ˆæœ¬ - {metric_name}',
                'å¹³å‡åˆ†æ•¸': f"{results_df[f'{metric_key}_ORIGINAL'].mean():.1f}",
                'æœ€é«˜åˆ†': f"{results_df[f'{metric_key}_ORIGINAL'].max():.1f}",
                'æœ€ä½åˆ†': f"{results_df[f'{metric_key}_ORIGINAL'].min():.1f}",
                'æ¨™æº–å·®': f"{results_df[f'{metric_key}_ORIGINAL'].std():.1f}"
            })

            comparison_data.append({
                'è©•ä¼°æŒ‡æ¨™': f'ğŸŸ¢ å„ªåŒ–ç‰ˆæœ¬ - {metric_name}',
                'å¹³å‡åˆ†æ•¸': f"{results_df[f'{metric_key}_OPTIMIZED'].mean():.1f}",
                'æœ€é«˜åˆ†': f"{results_df[f'{metric_key}_OPTIMIZED'].max():.1f}",
                'æœ€ä½åˆ†': f"{results_df[f'{metric_key}_OPTIMIZED'].min():.1f}",
                'æ¨™æº–å·®': f"{results_df[f'{metric_key}_OPTIMIZED'].std():.1f}"
            })

            improvement = results_df[f'{metric_key}_OPTIMIZED'].mean() - results_df[f'{metric_key}_ORIGINAL'].mean()
            comparison_data.append({
                'è©•ä¼°æŒ‡æ¨™': f'ğŸ“Š æ”¹å–„å¹…åº¦ - {metric_name}',
                'å¹³å‡åˆ†æ•¸': f"{improvement:+.1f}",
                'æœ€é«˜åˆ†': "-",
                'æœ€ä½åˆ†': "-",
                'æ¨™æº–å·®': "-"
            })

        comparison_df = pd.DataFrame(comparison_data)
        st.dataframe(comparison_df, use_container_width=True, hide_index=True)

        # é›·é”åœ–å°æ¯”
        st.markdown("### ğŸ¯ å¤šç¶­åº¦é›·é”åœ–å°æ¯”")

        categories = ['é—œéµè©è¦†è“‹ç‡']
        original_scores = [results_df['KEYWORD_COVERAGE_ORIGINAL'].mean()]
        optimized_scores = [results_df['KEYWORD_COVERAGE_OPTIMIZED'].mean()]

        if enable_semantic:
            categories.append('èªç¾©ç›¸ä¼¼åº¦')
            original_scores.append(results_df['SEMANTIC_SIMILARITY_ORIGINAL'].mean())
            optimized_scores.append(results_df['SEMANTIC_SIMILARITY_OPTIMIZED'].mean())

        if enable_manual_gpt:
            categories.append('GPT è©•åˆ†')
            original_scores.append(results_df['GPT_OVERALL_ORIGINAL'].mean())
            optimized_scores.append(results_df['GPT_OVERALL_OPTIMIZED'].mean())

        fig_radar = go.Figure()

        fig_radar.add_trace(go.Scatterpolar(
            r=original_scores + [original_scores[0]],
            theta=categories + [categories[0]],
            fill='toself',
            name='åŸå§‹ç‰ˆæœ¬',
            line_color='#e57373'
        ))

        fig_radar.add_trace(go.Scatterpolar(
            r=optimized_scores + [optimized_scores[0]],
            theta=categories + [categories[0]],
            fill='toself',
            name='å„ªåŒ–ç‰ˆæœ¬',
            line_color='#81c784'
        ))

        fig_radar.update_layout(
            polar=dict(radialaxis=dict(visible=True, range=[0, 100])),
            showlegend=True,
            height=500
        )

        st.plotly_chart(fig_radar, use_container_width=True)

    with tab4:
        st.markdown("### ğŸ”¤ èªç¾©å·®ç•°åˆ†æ")

        if not enable_semantic:
            st.warning("èªç¾©ç›¸ä¼¼åº¦åŠŸèƒ½æœªå•Ÿç”¨ï¼Œè«‹åœ¨å·¦å´å‹¾é¸ä¸¦ç¢ºèªç’°å¢ƒå·²å®‰è£ sentence-transformersã€‚")
        elif not st.session_state.evaluator_instance or not st.session_state.evaluator_instance.enable_semantic:
            st.warning("èªç¾©æ¨¡å‹å°šæœªè¼‰å…¥æˆåŠŸï¼Œè«‹é‡æ–°åŸ·è¡Œè©•ä¼°æˆ–æª¢æŸ¥ç’°å¢ƒè¨­å®šã€‚")
        else:
            evaluator = st.session_state.evaluator_instance

            semantic_selector = st.selectbox(
                "é¸æ“‡è¦åˆ†æçš„å•é¡Œ",
                range(len(results_df)),
                format_func=lambda x: f"å•é¡Œ {results_df.iloc[x]['åºè™Ÿ']}: {results_df.iloc[x]['æ¸¬è©¦å•é¡Œ'][:40]}...",
                key="semantic_selector"
            )

            row = results_df.iloc[semantic_selector]
            question_id = int(row['åºè™Ÿ'])
            reference_text = row['æ‡‰å›ç­”ä¹‹è©å½™']
            answer_original = row['ANSWER_ORIGINAL']
            answer_optimized = row['ANSWER_OPTIMIZED']

            st.markdown(f"#### ğŸ§¾ å•é¡Œ {question_id}: {row['æ¸¬è©¦å•é¡Œ']}")
            with st.expander("æ‡‰å›ç­”ä¹‹è©å½™ / åƒè€ƒå…§å®¹", expanded=False):
                st.write(reference_text)

            with st.expander("æŸ¥çœ‹åŸå§‹ç‰ˆæœ¬å›ç­”", expanded=False):
                st.write(answer_original)

            with st.expander("æŸ¥çœ‹å„ªåŒ–ç‰ˆæœ¬å›ç­”", expanded=False):
                st.write(answer_optimized)

            st.info(
                "èªç¾©ç›¸ä¼¼åº¦æ˜¯å°‡ã€æ‡‰å›ç­”ä¹‹è©å½™ã€èˆ‡å¯¦éš›å›ç­”åšå‘é‡æ¯”å°ï¼Œå› æ­¤å³ä½¿é—œéµè©çš†å‘½ä¸­ï¼Œ"
                "è‹¥å¥å‹ã€ç”¨è©æˆ–è£œå……å…§å®¹èˆ‡åƒè€ƒè³‡æ–™å·®ç•°å¤§ï¼Œåˆ†æ•¸ä»æœƒé™ä½ã€‚"
            )

            ideal_lines = format_reference_to_list(reference_text)
            if ideal_lines:
                st.markdown("**ç†æƒ³èªç¾©ç¤ºä¾‹ï¼ˆèˆ‡åƒè€ƒå…§å®¹å°é½Šçš„å¯«æ³•ï¼‰**")
                ideal_text = "\n".join([f"{idx + 1}. {line}" for idx, line in enumerate(ideal_lines)])
                st.code(ideal_text, language="text")

            score_col1, score_col2 = st.columns(2)

            keywords = evaluator.extract_keywords(reference_text)
            orig_kw_score, orig_matched, orig_details = evaluator.calculate_keyword_coverage(answer_original, keywords)
            opt_kw_score, opt_matched, opt_details = evaluator.calculate_keyword_coverage(answer_optimized, keywords)

            orig_sem_score, orig_sem_details = evaluator.calculate_semantic_similarity(reference_text, answer_original)
            opt_sem_score, opt_sem_details = evaluator.calculate_semantic_similarity(reference_text, answer_optimized)

            ref_sentences = split_into_sentences(reference_text)
            orig_sentence_scores = compute_sentence_similarity(evaluator, ref_sentences, answer_original)
            opt_sentence_scores = compute_sentence_similarity(evaluator, ref_sentences, answer_optimized)

            def build_sentence_table(data):
                if not data:
                    return pd.DataFrame(columns=["å¥å­", "èˆ‡å›ç­”ç›¸ä¼¼åº¦"])
                sorted_data = sorted(data, key=lambda x: x[1])
                top_items = sorted_data[:3]
                return pd.DataFrame([
                    {"å¥å­": sent, "èˆ‡å›ç­”ç›¸ä¼¼åº¦": f"{score:.1f}%"} for sent, score in top_items
                ])

            with score_col1:
                st.markdown("##### ğŸ”´ åŸå§‹ç‰ˆæœ¬")
                st.metric("èªç¾©ç›¸ä¼¼åº¦", f"{row['SEMANTIC_SIMILARITY_ORIGINAL']:.1f}%")
                st.caption(
                    f"é¤˜å¼¦ç›¸ä¼¼åº¦ï¼š{orig_sem_details.get('raw_similarity', 0):.3f}ï½œåƒè€ƒé•·åº¦ï¼š{orig_sem_details.get('reference_length', len(reference_text))}ï½œå›ç­”é•·åº¦ï¼š{orig_sem_details.get('answer_length', len(str(answer_original)))}"
                )

                st.markdown("**ç¼ºæ¼é—œéµè©**")
                missing_keywords = orig_details.get('missing_list', [])
                if missing_keywords:
                    st.write('ã€'.join(missing_keywords))
                else:
                    st.success("é—œéµè©çš†å·²è¦†è“‹")

                st.markdown("**ä½ç›¸ä¼¼åº¦åƒè€ƒå¥**")
                sentence_table = build_sentence_table(orig_sentence_scores)
                if sentence_table.empty:
                    st.info("åƒè€ƒè³‡æ–™ç„¡å¯æ¯”è¼ƒå¥å­æˆ–å›ç­”ç‚ºç©ºã€‚")
                else:
                    st.table(sentence_table)

                if missing_keywords:
                    st.markdown(
                        "**å»ºè­°**ï¼šè£œå……ä¸Šè¿°ç¼ºæ¼é—œéµè©ï¼Œæˆ–å°‡å›ç­”ä¸­çš„æ•˜è¿°èª¿æ•´æˆè²¼è¿‘åƒè€ƒè³‡æ–™çš„èªå¥ï¼Œä»¥æå‡èªç¾©è¦†è“‹ç‡ã€‚"
                    )

            with score_col2:
                st.markdown("##### ğŸŸ¢ å„ªåŒ–ç‰ˆæœ¬")
                st.metric("èªç¾©ç›¸ä¼¼åº¦", f"{row['SEMANTIC_SIMILARITY_OPTIMIZED']:.1f}%")
                st.caption(
                    f"é¤˜å¼¦ç›¸ä¼¼åº¦ï¼š{opt_sem_details.get('raw_similarity', 0):.3f}ï½œåƒè€ƒé•·åº¦ï¼š{opt_sem_details.get('reference_length', len(reference_text))}ï½œå›ç­”é•·åº¦ï¼š{opt_sem_details.get('answer_length', len(str(answer_optimized)))}"
                )

                st.markdown("**ç¼ºæ¼é—œéµè©**")
                missing_keywords_opt = opt_details.get('missing_list', [])
                if missing_keywords_opt:
                    st.write('ã€'.join(missing_keywords_opt))
                else:
                    st.success("é—œéµè©çš†å·²è¦†è“‹")

                st.markdown("**ä½ç›¸ä¼¼åº¦åƒè€ƒå¥**")
                sentence_table_opt = build_sentence_table(opt_sentence_scores)
                if sentence_table_opt.empty:
                    st.info("åƒè€ƒè³‡æ–™ç„¡å¯æ¯”è¼ƒå¥å­æˆ–å›ç­”ç‚ºç©ºã€‚")
                else:
                    st.table(sentence_table_opt)

                if missing_keywords_opt:
                    st.markdown(
                        "**å»ºè­°**ï¼šè£œè¶³ç¼ºæ¼è©å½™ï¼Œä¸¦æ¯”å°ä½ç›¸ä¼¼å¥å­çš„è³‡è¨Šé‡é»ï¼Œè®“å›ç­”æ›´è²¼è¿‘åƒè€ƒå…§å®¹ã€‚"
                    )

            st.markdown("---")
            st.markdown("#### ğŸ§­ åƒè€ƒå¦‚ä½•æ’°å¯«æ›´ç†æƒ³çš„å›ç­”ï¼Ÿ")
            improvement_points = []

            if missing_keywords:
                improvement_points.append("åŸå§‹ç‰ˆæœ¬æ¼æ‰çš„é—œéµè©ï¼š" + 'ã€'.join(missing_keywords))
            if missing_keywords_opt:
                improvement_points.append("å„ªåŒ–ç‰ˆæœ¬ä»éœ€è£œå……çš„é—œéµè©ï¼š" + 'ã€'.join(missing_keywords_opt))

            if orig_sentence_scores:
                lowest_orig = sorted(orig_sentence_scores, key=lambda x: x[1])[:1]
                for sent, score in lowest_orig:
                    improvement_points.append(f"åŸå§‹ç‰ˆèˆ‡åƒè€ƒå¥ã€Œ{sent}ã€åƒ… {score:.1f}% ç›¸ä¼¼ï¼Œå¯åŠ å…¥ç›¸å°æ‡‰ç´°ç¯€ã€‚")

            if opt_sentence_scores:
                lowest_opt = sorted(opt_sentence_scores, key=lambda x: x[1])[:1]
                for sent, score in lowest_opt:
                    improvement_points.append(f"å„ªåŒ–ç‰ˆèˆ‡åƒè€ƒå¥ã€Œ{sent}ã€åƒ… {score:.1f}% ç›¸ä¼¼ï¼Œå¯å†è²¼è¿‘åŸå§‹æè¿°ã€‚")

            if improvement_points:
                for item in improvement_points:
                    st.markdown(f"- {item}")
            else:
                st.success("å…©å€‹ç‰ˆæœ¬èˆ‡åƒè€ƒå…§å®¹é«˜åº¦ä¸€è‡´ï¼Œç„¡æ˜é¡¯ç¼ºæ¼ã€‚")

    with tab5:
        st.markdown("### ğŸ’¬ GPTè©•åˆ†å°è¦½")
        st.info("ç€è¦½æ‰€æœ‰æ¸¬è©¦å•é¡Œçš„è©³ç´°è©•ä¼°çµæœ")

        # ç¯©é¸é¸é …
        filter_option = st.selectbox(
            "ç¯©é¸é¡¯ç¤º",
            ["æ‰€æœ‰å•é¡Œ", "é¡¯è‘—æ”¹å–„", "ç•¥æœ‰æ”¹å–„", "ç„¡è®ŠåŒ–", "æ•ˆæœé€€æ­¥", "å·²æœ‰ GPT è©•åˆ†", "æœªæœ‰ GPT è©•åˆ†"]
        )

        evaluated_question_ids = set(st.session_state.gpt_responses_original.keys()) | set(
            st.session_state.gpt_responses_optimized.keys()
        )

        # æ ¹æ“šæ¢ä»¶ç¯©é¸
        if filter_option == "é¡¯è‘—æ”¹å–„":
            filtered_df = results_df[results_df['FINAL_IMPROVEMENT'] >= improvement_threshold]
        elif filter_option == "ç•¥æœ‰æ”¹å–„":
            filtered_df = results_df[(results_df['FINAL_IMPROVEMENT'] > 0) & (results_df['FINAL_IMPROVEMENT'] < improvement_threshold)]
        elif filter_option == "ç„¡è®ŠåŒ–":
            filtered_df = results_df[results_df['FINAL_IMPROVEMENT'] == 0]
        elif filter_option == "æ•ˆæœé€€æ­¥":
            filtered_df = results_df[results_df['FINAL_IMPROVEMENT'] < 0]
        elif filter_option == "å·²æœ‰ GPT è©•åˆ†":
            filtered_df = results_df[results_df['åºè™Ÿ'].astype(int).isin(evaluated_question_ids)]
        elif filter_option == "æœªæœ‰ GPT è©•åˆ†":
            filtered_df = results_df[~results_df['åºè™Ÿ'].astype(int).isin(evaluated_question_ids)]
        else:
            filtered_df = results_df

        st.info(f"é¡¯ç¤º {len(filtered_df)} / {len(results_df)} å€‹å•é¡Œ")

        # é¡¯ç¤ºå•é¡Œåˆ—è¡¨
        for idx, row in filtered_df.iterrows():
            question_id = int(row['åºè™Ÿ'])
            improvement = row['FINAL_IMPROVEMENT']
            improvement_icon = "ğŸ“ˆ" if improvement > 0 else "ğŸ“‰" if improvement < 0 else "â¡ï¸"
            
            with st.expander(f"{improvement_icon} å•é¡Œ {row['åºè™Ÿ']}: {row['æ¸¬è©¦å•é¡Œ'][:50]}... (æ”¹å–„:{improvement:+.1f})"):
                st.markdown(f"**æ¸¬è©¦å•é¡Œ**: {row['æ¸¬è©¦å•é¡Œ']}")
                st.markdown(f"**æ‡‰å›ç­”è©å½™**: {row['æ‡‰å›ç­”ä¹‹è©å½™']}")

                # åŸºç¤è©•åˆ†å°æ¯”
                score_col1, score_col2, score_col3, score_col4 = st.columns(4)

                with score_col1:
                    st.metric(
                        "é—œéµè©è¦†è“‹ç‡",
                        f"{row['KEYWORD_COVERAGE_OPTIMIZED']:.1f}%",
                        f"{row['KEYWORD_COVERAGE_OPTIMIZED'] - row['KEYWORD_COVERAGE_ORIGINAL']:.1f}%"
                    )

                with score_col2:
                    if enable_semantic:
                        st.metric(
                            "èªç¾©ç›¸ä¼¼åº¦",
                            f"{row['SEMANTIC_SIMILARITY_OPTIMIZED']:.1f}%",
                            f"{row['SEMANTIC_SIMILARITY_OPTIMIZED'] - row['SEMANTIC_SIMILARITY_ORIGINAL']:.1f}%"
                        )

                with score_col3:
                    if enable_manual_gpt and question_id in st.session_state.gpt_responses_optimized:
                        st.metric(
                            "GPT è©•åˆ†",
                            f"{row['GPT_OVERALL_OPTIMIZED']:.1f}",
                            f"{row['GPT_OVERALL_OPTIMIZED'] - row['GPT_OVERALL_ORIGINAL']:.1f}"
                        )
                    elif enable_manual_gpt and question_id in st.session_state.gpt_responses_original:
                        st.info("åƒ…åŸå§‹ç‰ˆå·²è©•å¯©")
                    elif enable_manual_gpt:
                        st.warning("æœªè©•å¯©")

                with score_col4:
                    st.metric(
                        "ğŸ“Š ç¶œåˆè©•åˆ†",
                        f"{row['FINAL_SCORE_OPTIMIZED']:.1f}",
                        f"{row['FINAL_IMPROVEMENT']:.1f}"
                    )
                
                # å„æŒ‡æ¨™è®ŠåŒ–åŸå› åˆ†æ
                st.markdown("---")
                st.markdown("#### ğŸ” å„æŒ‡æ¨™è®ŠåŒ–åŸå› åˆ†æ")
                
                # é—œéµè©è¦†è“‹ç‡åˆ†æ
                keyword_change = row['KEYWORD_COVERAGE_OPTIMIZED'] - row['KEYWORD_COVERAGE_ORIGINAL']
                if abs(keyword_change) > 0.1:  # åªé¡¯ç¤ºæœ‰è®ŠåŒ–çš„æŒ‡æ¨™
                    st.markdown("**ğŸ¯ é—œéµè©è¦†è“‹ç‡è®ŠåŒ–åˆ†æ**")
                    
                    kw_col1, kw_col2 = st.columns(2)
                    with kw_col1:
                        st.info(f"ğŸ”´ **åŸå§‹ç‰ˆæœ¬**: {row['KEYWORD_COVERAGE_ORIGINAL']:.1f}%")
                    with kw_col2:
                        if keyword_change > 0:
                            st.success(f"ğŸŸ¢ **å„ªåŒ–ç‰ˆæœ¬**: {row['KEYWORD_COVERAGE_OPTIMIZED']:.1f}% (æå‡ {keyword_change:.1f}%)")
                        else:
                            st.error(f"ğŸ”´ **å„ªåŒ–ç‰ˆæœ¬**: {row['KEYWORD_COVERAGE_OPTIMIZED']:.1f}% (ä¸‹é™ {abs(keyword_change):.1f}%)")
                    
                    # é—œéµè©è®ŠåŒ–åŸå› åˆ†æ
                    if st.session_state.evaluator_instance:
                        evaluator = st.session_state.evaluator_instance
                        keywords = evaluator.extract_keywords(row['æ‡‰å›ç­”ä¹‹è©å½™'])
                        
                        # åŸå§‹ç‰ˆæœ¬é—œéµè©åˆ†æ
                        orig_score, orig_matched, orig_details = evaluator.calculate_keyword_coverage(
                            row['ANSWER_ORIGINAL'], keywords
                        )
                        
                        # å„ªåŒ–ç‰ˆæœ¬é—œéµè©åˆ†æ  
                        opt_score, opt_matched, opt_details = evaluator.calculate_keyword_coverage(
                            row['ANSWER_OPTIMIZED'], keywords
                        )
                        
                        # è©³ç´°é—œéµè©è¦†è“‹åˆ†æ
                        detail_col1, detail_col2 = st.columns(2)
                        
                        with detail_col1:
                            st.write("**åŸå§‹ç‰ˆæœ¬ - é—œéµè©è©³æƒ…:**")
                            orig_found = orig_matched or orig_details.get('found_list', [])
                            if orig_found:
                                st.write("âœ… **å·²è¦†è“‹é—œéµè©:**")
                                for kw in orig_found:
                                    st.write(f"  â€¢ {kw}")

                            orig_missing = [kw for kw in keywords if kw not in orig_found]
                            if orig_missing:
                                st.write("âŒ **æœªè¦†è“‹é—œéµè©:**")
                                for kw in orig_missing:
                                    st.write(f"  â€¢ {kw}")

                        with detail_col2:
                            st.write("**å„ªåŒ–ç‰ˆæœ¬ - é—œéµè©è©³æƒ…:**")
                            opt_found = opt_matched or opt_details.get('found_list', [])
                            if opt_found:
                                st.write("âœ… **å·²è¦†è“‹é—œéµè©:**")
                                for kw in opt_found:
                                    st.write(f"  â€¢ {kw}")
                            
                            opt_missing = [kw for kw in keywords if kw not in opt_found]
                            if opt_missing:
                                st.write("âŒ **æœªè¦†è“‹é—œéµè©:**")
                                for kw in opt_missing:
                                    st.write(f"  â€¢ {kw}")
                        
                        # è®ŠåŒ–æ‘˜è¦
                        if keyword_change > 0:
                            # æå‡åŸå› 
                            newly_found = set(opt_found) - set(orig_found)
                            if newly_found:
                                st.success(f"ğŸ†• **æ–°å¢å‘½ä¸­é—œéµè©**: {', '.join(newly_found)}")
                            else:
                                st.success("âœ… **æ”¹å–„åŸå› **: å„ªåŒ–ç‰ˆæœ¬æ›´å®Œæ•´åœ°åŒ…å«äº†æ—¢æœ‰é—œéµè©")
                        elif keyword_change < 0:
                            # ä¸‹é™åŸå› 
                            lost_keywords = set(orig_found) - set(opt_found)
                            if lost_keywords:
                                st.error(f"ğŸ“‰ **éºå¤±é—œéµè©**: {', '.join(lost_keywords)}")
                            else:
                                st.error("âŒ **ä¸‹é™åŸå› **: å„ªåŒ–ç‰ˆæœ¬å¯èƒ½éåº¦ç°¡åŒ–äº†é—œéµè³‡è¨Š")
                        else:
                            st.info("â¡ï¸ **é—œéµè©è¦†è“‹ç‡ç„¡è®ŠåŒ–**")
                
                # èªç¾©ç›¸ä¼¼åº¦åˆ†æ
                if enable_semantic:
                    semantic_change = row['SEMANTIC_SIMILARITY_OPTIMIZED'] - row['SEMANTIC_SIMILARITY_ORIGINAL']
                    if abs(semantic_change) > 0.1:  # åªé¡¯ç¤ºæœ‰è®ŠåŒ–çš„æŒ‡æ¨™
                        st.markdown("**ğŸ”¤ èªç¾©ç›¸ä¼¼åº¦è®ŠåŒ–åˆ†æ**")
                        
                        sem_col1, sem_col2 = st.columns(2)
                        with sem_col1:
                            st.info(f"ğŸ”´ **åŸå§‹ç‰ˆæœ¬**: {row['SEMANTIC_SIMILARITY_ORIGINAL']:.1f}%")
                        with sem_col2:
                            if semantic_change > 0:
                                st.success(f"ğŸŸ¢ **å„ªåŒ–ç‰ˆæœ¬**: {row['SEMANTIC_SIMILARITY_OPTIMIZED']:.1f}% (æå‡ {semantic_change:.1f}%)")
                            else:
                                st.error(f"ğŸŸ¢ **å„ªåŒ–ç‰ˆæœ¬**: {row['SEMANTIC_SIMILARITY_OPTIMIZED']:.1f}% (ä¸‹é™ {abs(semantic_change):.1f}%)")
                        
                        # èªç¾©ç›¸ä¼¼åº¦è®ŠåŒ–åŸå› åˆ†æ
                        if st.session_state.evaluator_instance and st.session_state.evaluator_instance.enable_semantic:
                            evaluator = st.session_state.evaluator_instance
                            
                            # è¨ˆç®—è©³ç´°èªç¾©ç›¸ä¼¼åº¦
                            orig_sem_score, orig_sem_details = evaluator.calculate_semantic_similarity(
                                row['æ‡‰å›ç­”ä¹‹è©å½™'], row['ANSWER_ORIGINAL']
                            )
                            opt_sem_score, opt_sem_details = evaluator.calculate_semantic_similarity(
                                row['æ‡‰å›ç­”ä¹‹è©å½™'], row['ANSWER_OPTIMIZED']
                            )
                            
                            if semantic_change > 0:
                                st.success(
                                    "âœ… **èªç¾©æ”¹å–„åŸå› **: å„ªåŒ–ç‰ˆæœ¬æ›´è²¼è¿‘åƒè€ƒå…§å®¹çš„è¡¨é”æ–¹å¼å’Œè©å½™é¸æ“‡"
                                )
                                st.caption(f"åŸå§‹é¤˜å¼¦ç›¸ä¼¼åº¦: {orig_sem_details.get('raw_similarity', 0):.3f} â†’ å„ªåŒ–å¾Œ: {opt_sem_details.get('raw_similarity', 0):.3f}")
                            else:
                                st.error(
                                    "âŒ **èªç¾©ä¸‹é™åŸå› **: å„ªåŒ–ç‰ˆæœ¬å¯èƒ½ä½¿ç”¨äº†è¼ƒä¸å¸¸è¦‹çš„è©å½™æˆ–è¡¨é”æ–¹å¼"
                                )
                                st.caption(f"åŸå§‹é¤˜å¼¦ç›¸ä¼¼åº¦: {orig_sem_details.get('raw_similarity', 0):.3f} â†’ å„ªåŒ–å¾Œ: {opt_sem_details.get('raw_similarity', 0):.3f}")

                # è©³ç´°GPTè©•åˆ†åˆ†æ
                if enable_manual_gpt and (question_id in st.session_state.gpt_responses_original or question_id in st.session_state.gpt_responses_optimized):
                    st.markdown("---")
                    st.markdown("#### ğŸ¤– GPT è©³ç´°è©•åˆ†åˆ†æ")
                    
                    # GPTå››ç¶­åº¦å°æ¯”
                    gpt_orig = st.session_state.gpt_responses_original.get(question_id, {})
                    gpt_opt = st.session_state.gpt_responses_optimized.get(question_id, {})
                    
                    gpt_col1, gpt_col2, gpt_col3, gpt_col4 = st.columns(4)
                    
                    with gpt_col1:
                        orig_rel = gpt_orig.get('relevance', 0)
                        opt_rel = gpt_opt.get('relevance', 0)
                        if orig_rel > 0 and opt_rel > 0:
                            st.metric("ğŸ¯ ç›¸é—œæ€§", f"{opt_rel}", f"{opt_rel - orig_rel:+.0f}")
                        elif opt_rel > 0:
                            st.metric("ğŸ¯ ç›¸é—œæ€§", f"{opt_rel}", "å„ªåŒ–ç‰ˆ")
                        elif orig_rel > 0:
                            st.metric("ğŸ¯ ç›¸é—œæ€§", f"{orig_rel}", "åŸå§‹ç‰ˆ")
                    
                    with gpt_col2:
                        orig_comp = gpt_orig.get('completeness', 0)
                        opt_comp = gpt_opt.get('completeness', 0)
                        if orig_comp > 0 and opt_comp > 0:
                            st.metric("ğŸ“‹ å®Œæ•´æ€§", f"{opt_comp}", f"{opt_comp - orig_comp:+.0f}")
                        elif opt_comp > 0:
                            st.metric("ğŸ“‹ å®Œæ•´æ€§", f"{opt_comp}", "å„ªåŒ–ç‰ˆ")
                        elif orig_comp > 0:
                            st.metric("ğŸ“‹ å®Œæ•´æ€§", f"{orig_comp}", "åŸå§‹ç‰ˆ")
                    
                    with gpt_col3:
                        orig_acc = gpt_orig.get('accuracy', 0)
                        opt_acc = gpt_opt.get('accuracy', 0)
                        if orig_acc > 0 and opt_acc > 0:
                            st.metric("âœ… æº–ç¢ºæ€§", f"{opt_acc}", f"{opt_acc - orig_acc:+.0f}")
                        elif opt_acc > 0:
                            st.metric("âœ… æº–ç¢ºæ€§", f"{opt_acc}", "å„ªåŒ–ç‰ˆ")
                        elif orig_acc > 0:
                            st.metric("âœ… æº–ç¢ºæ€§", f"{orig_acc}", "åŸå§‹ç‰ˆ")
                    
                    with gpt_col4:
                        orig_faith = gpt_orig.get('faithfulness', 0)
                        opt_faith = gpt_opt.get('faithfulness', 0)
                        if orig_faith > 0 and opt_faith > 0:
                            st.metric("ğŸ”’ å¿ èª åº¦", f"{opt_faith}", f"{opt_faith - orig_faith:+.0f}")
                        elif opt_faith > 0:
                            st.metric("ğŸ”’ å¿ èª åº¦", f"{opt_faith}", "å„ªåŒ–ç‰ˆ")
                        elif orig_faith > 0:
                            st.metric("ğŸ”’ å¿ èª åº¦", f"{orig_faith}", "åŸå§‹ç‰ˆ")
                    
                    # GPTè©•åˆ†åŸå› åˆ†æ
                    if gpt_orig or gpt_opt:
                        st.markdown("#### ğŸ’­ è©•åˆ†åŸå› è©³ç´°åˆ†æ")
                        
                        reasoning_col1, reasoning_col2 = st.columns(2)
                        
                        with reasoning_col1:
                            if gpt_orig:
                                st.markdown("##### ğŸ”´ åŸå§‹ç‰ˆæœ¬è©•åˆ†åŸå› ")
                                
                                if gpt_orig.get('relevance_reasoning'):
                                    st.markdown(f"**ğŸ¯ ç›¸é—œæ€§ ({gpt_orig.get('relevance', 0)}åˆ†)**")
                                    st.info(gpt_orig.get('relevance_reasoning', 'ç„¡è©³ç´°èªªæ˜'))
                                
                                if gpt_orig.get('completeness_reasoning'):
                                    st.markdown(f"**ğŸ“‹ å®Œæ•´æ€§ ({gpt_orig.get('completeness', 0)}åˆ†)**")
                                    st.info(gpt_orig.get('completeness_reasoning', 'ç„¡è©³ç´°èªªæ˜'))
                                
                                if gpt_orig.get('accuracy_reasoning'):
                                    st.markdown(f"**âœ… æº–ç¢ºæ€§ ({gpt_orig.get('accuracy', 0)}åˆ†)**")
                                    st.info(gpt_orig.get('accuracy_reasoning', 'ç„¡è©³ç´°èªªæ˜'))
                                
                                if gpt_orig.get('faithfulness_reasoning'):
                                    st.markdown(f"**ğŸ”’ å¿ èª åº¦ ({gpt_orig.get('faithfulness', 0)}åˆ†)**")
                                    st.info(gpt_orig.get('faithfulness_reasoning', 'ç„¡è©³ç´°èªªæ˜'))
                            else:
                                st.info("åŸå§‹ç‰ˆæœ¬å°šæœªé€²è¡ŒGPTè©•åˆ†")
                        
                        with reasoning_col2:
                            if gpt_opt:
                                st.markdown("##### ğŸŸ¢ å„ªåŒ–ç‰ˆæœ¬è©•åˆ†åŸå› ")
                                
                                if gpt_opt.get('relevance_reasoning'):
                                    st.markdown(f"**ğŸ¯ ç›¸é—œæ€§ ({gpt_opt.get('relevance', 0)}åˆ†)**")
                                    st.success(gpt_opt.get('relevance_reasoning', 'ç„¡è©³ç´°èªªæ˜'))
                                
                                if gpt_opt.get('completeness_reasoning'):
                                    st.markdown(f"**ğŸ“‹ å®Œæ•´æ€§ ({gpt_opt.get('completeness', 0)}åˆ†)**")
                                    st.success(gpt_opt.get('completeness_reasoning', 'ç„¡è©³ç´°èªªæ˜'))
                                
                                if gpt_opt.get('accuracy_reasoning'):
                                    st.markdown(f"**âœ… æº–ç¢ºæ€§ ({gpt_opt.get('accuracy', 0)}åˆ†)**")
                                    st.success(gpt_opt.get('accuracy_reasoning', 'ç„¡è©³ç´°èªªæ˜'))
                                
                                if gpt_opt.get('faithfulness_reasoning'):
                                    st.markdown(f"**ğŸ”’ å¿ èª åº¦ ({gpt_opt.get('faithfulness', 0)}åˆ†)**")
                                    st.success(gpt_opt.get('faithfulness_reasoning', 'ç„¡è©³ç´°èªªæ˜'))
                            else:
                                st.info("å„ªåŒ–ç‰ˆæœ¬å°šæœªé€²è¡ŒGPTè©•åˆ†")

                    # æ”¹é€²å»ºè­°
                    if gpt_orig and gpt_opt:
                        st.markdown("---")
                        st.markdown("#### ğŸ“ˆ æ”¹é€²åˆ†æèˆ‡å»ºè­°")
                        
                        improvements = []
                        concerns = []
                        
                        # åˆ†æå„ç¶­åº¦è®ŠåŒ–
                        dimensions = [
                            ('ç›¸é—œæ€§', 'relevance', 'ğŸ¯'),
                            ('å®Œæ•´æ€§', 'completeness', 'ğŸ“‹'), 
                            ('æº–ç¢ºæ€§', 'accuracy', 'âœ…'),
                            ('å¿ èª åº¦', 'faithfulness', 'ğŸ”’')
                        ]

                        for dim_name, dim_key, dim_icon in dimensions:
                            orig_score = gpt_orig.get(dim_key, 0)
                            opt_score = gpt_opt.get(dim_key, 0)
                            diff = opt_score - orig_score

                            orig_reason = (gpt_orig.get(f"{dim_key}_reasoning") or "").strip()
                            opt_reason = (gpt_opt.get(f"{dim_key}_reasoning") or "").strip()
                            reason_text = opt_reason if diff >= 0 else orig_reason
                            if reason_text:
                                reason_text = reason_text.replace("\n", "  \n")
                            else:
                                reason_text = "ï¼ˆGPT æœªæä¾›è©³ç´°èªªæ˜ï¼‰"

                            if diff > 5:
                                improvements.append(
                                    f"{dim_icon} **{dim_name}é¡¯è‘—æå‡** (+{diff:.0f}åˆ†)  \n"
                                    f"> {reason_text}"
                                )
                            elif diff < -5:
                                concerns.append(
                                    f"{dim_icon} **{dim_name}æœ‰æ‰€ä¸‹é™** ({diff:+.0f}åˆ†)  \n"
                                    f"> {reason_text}"
                                )
                        
                        if improvements:
                            st.markdown("**âœ… ä¸»è¦æ”¹é€²**")
                            for improvement in improvements:
                                st.markdown(f"- {improvement}")
                        
                        if concerns:
                            st.markdown("**âš ï¸ éœ€è¦æ³¨æ„**")
                            for concern in concerns:
                                st.markdown(f"- {concern}")
                        
                        if not improvements and not concerns:
                            st.info("ğŸ’¡ å…©å€‹ç‰ˆæœ¬åœ¨å„ç¶­åº¦è¡¨ç¾ç›¸ç•¶ï¼Œå·®ç•°ä¸å¤§")

                    # åŸå§‹ JSON åƒè€ƒ
                    json_col1, json_col2 = st.columns(2)
                    with json_col1:
                        if gpt_orig:
                            st.markdown("**ğŸ—’ï¸ åŸå§‹ç‰ˆæœ¬ GPT JSON**")
                            st.code(json.dumps(gpt_orig, ensure_ascii=False, indent=2), language="json")
                        else:
                            st.info("åŸå§‹ç‰ˆæœ¬å°šæœªè²¼ä¸Š GPT JSON")
                    with json_col2:
                        if gpt_opt:
                            st.markdown("**ğŸ—’ï¸ å„ªåŒ–ç‰ˆæœ¬ GPT JSON**")
                            st.code(json.dumps(gpt_opt, ensure_ascii=False, indent=2), language="json")
                        else:
                            st.info("å„ªåŒ–ç‰ˆæœ¬å°šæœªè²¼ä¸Š GPT JSON")
                    
                    # é¡¯ç¤ºåŸå§‹å›ç­”å°æ¯”
                    st.markdown("---")
                    st.markdown("#### ğŸ“ å›ç­”å…§å®¹å°æ¯”")
                    
                    answer_col1, answer_col2 = st.columns(2)
                    
                    with answer_col1:
                        st.markdown("##### ğŸ”´ åŸå§‹ç‰ˆæœ¬å›ç­”")
                        # ä½¿ç”¨å¯æ”¶åˆçš„å®¹å™¨ä¾†å–ä»£ expander
                        show_orig = st.checkbox("é¡¯ç¤ºåŸå§‹å›ç­”", key=f"show_orig_{question_id}")
                        if show_orig:
                            st.text_area("", value=row['ANSWER_ORIGINAL'], height=150, key=f"orig_answer_{question_id}", disabled=True)
                    
                    with answer_col2:
                        st.markdown("##### ğŸŸ¢ å„ªåŒ–ç‰ˆæœ¬å›ç­”")
                        # ä½¿ç”¨å¯æ”¶åˆçš„å®¹å™¨ä¾†å–ä»£ expander
                        show_opt = st.checkbox("é¡¯ç¤ºå„ªåŒ–å›ç­”", key=f"show_opt_{question_id}")
                        if show_opt:
                            st.text_area("", value=row['ANSWER_OPTIMIZED'], height=150, key=f"opt_answer_{question_id}", disabled=True)

    with tab6:
        st.markdown("### ğŸ¯ é—œéµè©åˆ†æ")
        st.info("ğŸ” é€é¡Œæª¢è¦–é—œéµè©è¦†è“‹ç‡çš„è©³ç´°è¡¨ç¾ï¼ŒåŒ…å«å·²è¦†è“‹å’Œæœªè¦†è“‹çš„é—œéµè©åˆ—è¡¨")
        
        if 'comparison_results' in st.session_state and st.session_state.evaluator_instance:
            results_df = st.session_state.comparison_results
            evaluator = st.session_state.evaluator_instance
            
            # é¡Œç›®é¸æ“‡å™¨
            keyword_selector = st.selectbox(
                "é¸æ“‡è¦åˆ†æçš„å•é¡Œ",
                range(len(results_df)),
                format_func=lambda x: f"å•é¡Œ {results_df.iloc[x]['åºè™Ÿ']}: {results_df.iloc[x]['æ¸¬è©¦å•é¡Œ'][:40]}...",
                key="keyword_selector"
            )
            
            row = results_df.iloc[keyword_selector]
            question_id = int(row['åºè™Ÿ'])
            reference_text = row['æ‡‰å›ç­”ä¹‹è©å½™']
            answer_original = row['ANSWER_ORIGINAL']
            answer_optimized = row['ANSWER_OPTIMIZED']
            
            st.markdown(f"#### ğŸ“ å•é¡Œ {question_id}: {row['æ¸¬è©¦å•é¡Œ']}")
            
            with st.expander("æ‡‰å›ç­”ä¹‹è©å½™ / åƒè€ƒå…§å®¹", expanded=False):
                st.write(reference_text)
            
            with st.expander("æŸ¥çœ‹åŸå§‹ç‰ˆæœ¬å›ç­”", expanded=False):
                st.write(answer_original)
            
            with st.expander("æŸ¥çœ‹å„ªåŒ–ç‰ˆæœ¬å›ç­”", expanded=False):
                st.write(answer_optimized)
            
            st.info(
                "ğŸ“ˆ é—œéµè©è¦†è“‹ç‡æ˜¯æª¢æŸ¥å›ç­”ä¸­æ˜¯å¦åŒ…å«ã€æ‡‰å›ç­”ä¹‹è©å½™ã€ä¸­çš„é—œéµè©å½™ã€‚"
                "æœ¬åˆ†æå°‡æ¸…æ¥šé¡¯ç¤ºå“ªäº›è©å½™å·²è¦†è“‹ã€å“ªäº›å°šæœªè¦†è“‹ã€‚"
            )
            
            # æå–é—œéµè©å’Œè¨ˆç®—è¦†è“‹ç‡
            keywords = evaluator.extract_keywords(reference_text)
            orig_kw_score, orig_matched, orig_details = evaluator.calculate_keyword_coverage(answer_original, keywords)
            opt_kw_score, opt_matched, opt_details = evaluator.calculate_keyword_coverage(answer_optimized, keywords)
            
            # é¡¯ç¤ºæ‰€æœ‰é—œéµè©åˆ—è¡¨
            if keywords:
                st.markdown("**ğŸ—’ï¸ æ‰€æœ‰é—œéµè©åˆ—è¡¨**")
                keyword_list = "ã€".join(keywords)
                st.code(keyword_list, language="text")
            else:
                st.warning("âš ï¸ ç„¡æ³•æå–é—œéµè©")
                st.stop()
            
            # å°æ¯”åˆ†æèˆ‡è¦†è“‹ç‡èªªæ˜
            total_keywords = len(keywords)
            orig_found = orig_matched or []
            opt_found = opt_matched or []
            orig_missing = (orig_details or {}).get('missing_list', [])
            opt_missing = (opt_details or {}).get('missing_list', [])
            found_count = len(orig_found)
            opt_found_count = len(opt_found)
            orig_hit_pct = (found_count / total_keywords * 100) if total_keywords else 0.0
            opt_hit_pct = (opt_found_count / total_keywords * 100) if total_keywords else 0.0
            change = row['KEYWORD_COVERAGE_OPTIMIZED'] - row['KEYWORD_COVERAGE_ORIGINAL']

            score_col1, score_col2 = st.columns(2)

            with score_col1:
                st.markdown("##### ğŸ”´ åŸå§‹ç‰ˆæœ¬")
                st.metric("é—œéµè©è¦†è“‹ç‡", f"{row['KEYWORD_COVERAGE_ORIGINAL']:.1f}%")

                st.caption(f"å‘½ä¸­é—œéµè©æ•¸é‡ï¼š{found_count}/{total_keywords}ï¼ˆå‘½ä¸­ç‡ {orig_hit_pct:.1f}%ï¼‰")

                st.markdown("**ğŸ“Š è¦†è“‹ç‡è¨ˆç®—èªªæ˜**")
                if total_keywords:
                    st.write(
                        f"æ‡‰è¦†è“‹é—œéµè©å…± {total_keywords} å€‹ï¼Œå¯¦éš›å‘½ä¸­ {found_count} å€‹ï¼Œ"
                        f"è¦†è“‹ç‡ = {found_count}/{total_keywords} Ã— 100 = {row['KEYWORD_COVERAGE_ORIGINAL']:.1f}%ã€‚"
                    )
                else:
                    st.warning("æœ¬é¡Œæœªèƒ½æ“·å–åˆ°å¯ç”¨çš„é—œéµè©ï¼Œå› æ­¤ç„¡æ³•è¨ˆç®—è¦†è“‹ç‡ã€‚")

                st.markdown("**âœ… å·²è¦†è“‹é—œéµè©**")
                if orig_found:
                    for kw in orig_found:
                        st.success(f"â€¢ {kw}")
                else:
                    st.info("ç„¡å‘½ä¸­é—œéµè©")

                st.markdown("**âŒ æœªè¦†è“‹é—œéµè©**")
                if orig_missing:
                    for kw in orig_missing:
                        st.error(f"â€¢ {kw}")
                    st.markdown(
                        "**å»ºè­°**ï¼šåœ¨å›ç­”ä¸­åŠ å…¥ä¸Šè¿°ç¼ºæ¼çš„é—œéµè©ï¼Œæé«˜è¦†è“‹ç‡ã€‚"
                    )
                else:
                    st.success("å…¨éƒ¨é—œéµè©å·²è¦†è“‹ï¼")

            with score_col2:
                st.markdown("##### ğŸŸ¢ å„ªåŒ–ç‰ˆæœ¬")
                st.metric("é—œéµè©è¦†è“‹ç‡", f"{row['KEYWORD_COVERAGE_OPTIMIZED']:.1f}%", f"{change:+.1f}%")

                st.caption(f"å‘½ä¸­é—œéµè©æ•¸é‡ï¼š{opt_found_count}/{total_keywords}ï¼ˆå‘½ä¸­ç‡ {opt_hit_pct:.1f}%ï¼‰")

                st.markdown("**ğŸ“Š è¦†è“‹ç‡è¨ˆç®—èªªæ˜**")
                if total_keywords:
                    st.write(
                        f"æ‡‰è¦†è“‹é—œéµè©å…± {total_keywords} å€‹ï¼Œå„ªåŒ–ç‰ˆæœ¬å‘½ä¸­ {opt_found_count} å€‹ï¼Œ"
                        f"è¦†è“‹ç‡ = {opt_found_count}/{total_keywords} Ã— 100 = {row['KEYWORD_COVERAGE_OPTIMIZED']:.1f}%ã€‚"
                    )
                else:
                    st.warning("æœ¬é¡Œæœªèƒ½æ“·å–åˆ°å¯ç”¨çš„é—œéµè©ï¼Œå› æ­¤ç„¡æ³•è¨ˆç®—è¦†è“‹ç‡ã€‚")

                st.markdown("**âœ… å·²è¦†è“‹é—œéµè©**")
                if opt_found:
                    for kw in opt_found:
                        st.success(f"â€¢ {kw}")
                else:
                    st.info("ç„¡å‘½ä¸­é—œéµè©")

                st.markdown("**âŒ æœªè¦†è“‹é—œéµè©**")
                if opt_missing:
                    for kw in opt_missing:
                        st.error(f"â€¢ {kw}")
                    st.markdown(
                        "**å»ºè­°**ï¼šé€™äº›è©å½™ä»éœ€è¦è¢«æåŠä»¥é€²ä¸€æ­¥æå‡è¦†è“‹ç‡ã€‚"
                    )
                else:
                    st.success("å…¨éƒ¨é—œéµè©å·²è¦†è“‹ï¼")

            st.markdown("---")

            st.markdown("#### ğŸ“‹ é—œéµè©å‘½ä¸­å°ç…§è¡¨")
            if keywords:
                comparison_rows = []
                for kw in keywords:
                    orig_status = "âœ… å‘½ä¸­" if kw in orig_found else "âŒ ç¼ºæ¼"
                    opt_status = "âœ… å‘½ä¸­" if kw in opt_found else "âŒ ç¼ºæ¼"
                    if kw in orig_found and kw not in opt_found:
                        reason = "å„ªåŒ–ç‰ˆæœ¬éºå¤±"
                    elif kw not in orig_found and kw in opt_found:
                        reason = "å„ªåŒ–ç‰ˆæœ¬è£œä¸Š"
                    elif kw not in orig_found and kw not in opt_found:
                        reason = "å…©ç‰ˆæœ¬çš†ç¼ºæ¼"
                    else:
                        reason = "å…©ç‰ˆæœ¬çš†å‘½ä¸­"
                    comparison_rows.append({
                        "é—œéµè©": kw,
                        "åŸå§‹ç‰ˆæœ¬": orig_status,
                        "å„ªåŒ–ç‰ˆæœ¬": opt_status,
                        "å·®ç•°èªªæ˜": reason
                    })

                st.table(pd.DataFrame(comparison_rows))

            st.markdown("---")

            # è®ŠåŒ–åˆ†æ
            st.markdown("#### ğŸ”„ é—œéµè©è¦†è“‹è®ŠåŒ–åˆ†æ")

            newly_covered = sorted(set(opt_found) - set(orig_found))
            newly_lost = sorted(set(orig_found) - set(opt_found))
            remained_covered = sorted(set(orig_found) & set(opt_found))
            remained_missing = sorted(set(orig_missing) & set(opt_missing))

            change_col1, change_col2 = st.columns(2)

            with change_col1:
                st.markdown("**ğŸ†• æ–°å¢è¦†è“‹**")
                if newly_covered:
                    for kw in newly_covered:
                        st.success(f"â€¢ {kw}")
                    st.success(f"ğŸ‰ æ–°å¢è¦†è“‹ {len(newly_covered)} å€‹é—œéµè©ï¼")
                else:
                    st.info("ç„¡æ–°å¢è¦†è“‹é—œéµè©")

                st.markdown("**â¡ï¸ æŒçºŒè¦†è“‹**")
                if remained_covered:
                    st.write(f"æŒçºŒä¿æŒè¦†è“‹ {len(remained_covered)} å€‹é—œéµè©")
                    for kw in remained_covered:
                        st.write(f"  â€¢ {kw}")
                else:
                    st.info("ç„¡æŒçºŒè¦†è“‹çš„é—œéµè©")

            with change_col2:
                st.markdown("**ğŸ“‰ å¤±å»è¦†è“‹**")
                if newly_lost:
                    for kw in newly_lost:
                        st.error(f"â€¢ {kw}")
                    st.error(f"âš ï¸ å¤±å»äº† {len(newly_lost)} å€‹é—œéµè©è¦†è“‹ï¼")
                else:
                    st.info("ç„¡å¤±å»è¦†è“‹é—œéµè©")

                st.markdown("**âŒ æŒçºŒç¼ºæ¼**")
                if remained_missing:
                    st.write(f"ä»æœªè¦†è“‹ {len(remained_missing)} å€‹é—œéµè©")
                    for kw in remained_missing:
                        st.write(f"  â€¢ {kw}")
                else:
                    st.success("ç„¡æŒçºŒç¼ºæ¼çš„é—œéµè©")
            
            # çµè«–å’Œå»ºè­°
            st.markdown("---")
            st.markdown("#### ğŸ’¡ çµè«–å’Œå»ºè­°")
            
            improvement_points = []
            
            if change > 5:
                st.success(f"ğŸ‰ **å„ªç§€è¡¨ç¾**: æœ¬é¡Œé—œéµè©è¦†è“‹ç‡å¤§å¹…æ”¹å–„ {change:.1f}%ï¼")
            elif change > 0:
                st.success(f"âœ… **æ­£å‘æ”¹å–„**: æœ¬é¡Œé—œéµè©è¦†è“‹ç‡æå‡ {change:.1f}%")
            elif change == 0:
                st.info("â¡ï¸ **ç¶­æŒç¾ç‹€**: æœ¬é¡Œé—œéµè©è¦†è“‹ç‡ç„¡è®ŠåŒ–")
            else:
                st.warning(f"âš ï¸ **éœ€è¦æ”¹é€²**: æœ¬é¡Œé—œéµè©è¦†è“‹ç‡ä¸‹é™ {abs(change):.1f}%")
            
            # å…·é«”å»ºè­°
            if opt_missing:
                improvement_points.append(f"éœ€è¦åœ¨å›ç­”ä¸­åŠ å…¥ï¼š{'ã€'.join(opt_missing)}")
            
            if newly_lost:
                improvement_points.append(f"é¿å…éºå¤±é€™äº›é‡è¦è©å½™ï¼š{'ã€'.join(newly_lost)}")
            
            if newly_covered:
                improvement_points.append(f"ç¹¼çºŒä¿æŒé€™äº›æ–°å¢çš„å„ªé»ï¼š{'ã€'.join(newly_covered)}")
            
            if improvement_points:
                st.markdown("**ğŸ“ å…·é«”å»ºè­°**")
                for point in improvement_points:
                    st.markdown(f"- {point}")
            else:
                st.success("ğŸ† æœ¬é¡Œé—œéµè©è¦†è“‹ç‡å·²é”åˆ°ç†æƒ³ç‹€æ…‹ï¼")
        
        else:
            st.warning("ğŸ˜” ç„¡æ³•è¼‰å…¥è³‡æ–™ï¼Œè«‹å…ˆåœ¨ã€Œè©•ä¼°ç¸½è¦½ã€åˆ†é ä¸­å®Œæˆè©•ä¼°")

    with tab7:
        st.markdown("### ğŸ“¥ ä¸‹è¼‰çµæœ")
        st.info("åŒ¯å‡ºå®Œæ•´è©•ä¼°å ±å‘Šï¼ˆåŒ…å« GPT äººå·¥è©•å¯©çµæœï¼‰")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### ğŸ“Š å®Œæ•´è©•ä¼°å ±å‘Šï¼ˆExcelï¼‰")

            if st.button("ç”Ÿæˆå®Œæ•´å ±å‘Š", type="primary"):
                # æº–å‚™åŒ…å« GPT è©•åˆ†çš„å®Œæ•´è³‡æ–™
                export_df = results_df.copy()

                # åŠ å…¥ GPT è©³ç´°è©•åˆ†
                gpt_columns = ['GPT_RELEVANCE', 'GPT_COMPLETENESS', 'GPT_ACCURACY', 'GPT_FAITHFULNESS']
                for col in gpt_columns:
                    export_df[f'{col}_ORIGINAL'] = 0
                    export_df[f'{col}_OPTIMIZED'] = 0

                for idx, row in export_df.iterrows():
                    question_id = int(row['åºè™Ÿ'])

                    if question_id in st.session_state.gpt_responses_original:
                        gpt_data = st.session_state.gpt_responses_original[question_id]
                        export_df.at[idx, 'GPT_RELEVANCE_ORIGINAL'] = gpt_data.get('relevance', 0)
                        export_df.at[idx, 'GPT_COMPLETENESS_ORIGINAL'] = gpt_data.get('completeness', 0)
                        export_df.at[idx, 'GPT_ACCURACY_ORIGINAL'] = gpt_data.get('accuracy', 0)
                        export_df.at[idx, 'GPT_FAITHFULNESS_ORIGINAL'] = gpt_data.get('faithfulness', 0)

                    if question_id in st.session_state.gpt_responses_optimized:
                        gpt_data = st.session_state.gpt_responses_optimized[question_id]
                        export_df.at[idx, 'GPT_RELEVANCE_OPTIMIZED'] = gpt_data.get('relevance', 0)
                        export_df.at[idx, 'GPT_COMPLETENESS_OPTIMIZED'] = gpt_data.get('completeness', 0)
                        export_df.at[idx, 'GPT_ACCURACY_OPTIMIZED'] = gpt_data.get('accuracy', 0)
                        export_df.at[idx, 'GPT_FAITHFULNESS_OPTIMIZED'] = gpt_data.get('faithfulness', 0)

                filename = f'RAGå®Œæ•´è©•ä¼°_v2_{datetime.now().strftime("%Y%m%d_%H%M%S")}.xlsx'

                with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:
                    export_df.to_excel(writer, sheet_name='è©•ä¼°çµæœ', index=False)

                with open(filename, 'rb') as f:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰å®Œæ•´å ±å‘Š",
                        data=f,
                        file_name=filename,
                        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                    )

                if os.path.exists(filename):
                    os.remove(filename)

                st.success("âœ… å®Œæ•´å ±å‘Šå·²ç”Ÿæˆ")

        with col2:
            st.markdown("#### ğŸ“ˆ GPT è©•åˆ†æ‘˜è¦ï¼ˆJSONï¼‰")

            if st.button("åŒ¯å‡º GPT è©•åˆ†", type="secondary"):
                gpt_export = {
                    "original": st.session_state.gpt_responses_original,
                    "optimized": st.session_state.gpt_responses_optimized,
                    "metadata": {
                        "total_questions": len(results_df),
                        "evaluated_original": len(st.session_state.gpt_responses_original),
                        "evaluated_optimized": len(st.session_state.gpt_responses_optimized),
                        "export_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    }
                }

                json_filename = f'GPTè©•åˆ†æ‘˜è¦_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'

                with open(json_filename, 'w', encoding='utf-8') as f:
                    json.dump(gpt_export, f, ensure_ascii=False, indent=2)

                with open(json_filename, 'rb') as f:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰ GPT è©•åˆ†",
                        data=f,
                        file_name=json_filename,
                        mime='application/json'
                    )

                if os.path.exists(json_filename):
                    os.remove(json_filename)

                st.success("âœ… GPT è©•åˆ†å·²åŒ¯å‡º")

    with tab8:
        st.markdown("### ğŸ“ GPT è©•åˆ†è£œå……èªªæ˜")

        supplement_path = Path(__file__).resolve().parent / "GPTè£œå……èªªæ˜.md"

        if supplement_path.exists():
            try:
                supplement_content = supplement_path.read_text(encoding="utf-8")
                st.markdown(supplement_content)
            except Exception as exc:
                st.error(f"ç„¡æ³•è®€å– GPTè£œå……èªªæ˜.mdï¼š{exc}")
        else:
            st.warning("æ‰¾ä¸åˆ° GPTè£œå……èªªæ˜.mdï¼Œè«‹ç¢ºèªæª”æ¡ˆä½æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„ã€‚")

else:
    # æœªä¸Šå‚³æª”æ¡ˆæ™‚çš„æç¤º
    st.info("ğŸ‘ˆ è«‹å¾å´é‚Šæ¬„ä¸Šå‚³æ¸¬è©¦çµæœæª”æ¡ˆé–‹å§‹è©•ä¼°")

    # ä½¿ç”¨èªªæ˜
    with st.expander("ğŸ“– ä½¿ç”¨èªªæ˜ v2.0 - æ•´åˆäººå·¥ GPT è©•å¯©", expanded=True):
        st.markdown("""
        ### ğŸ¯ ç³»çµ±ç‰¹æ€§

        æœ¬ç³»çµ±æ¡ç”¨**ä¸‰ç¨®è©•ä¼°æ¶æ§‹ + äººå·¥ GPT è©•å¯©**ï¼Œå®Œç¾å¹³è¡¡è‡ªå‹•åŒ–èˆ‡æº–ç¢ºåº¦ï¼š

        #### ğŸ“Š è©•ä¼°æµç¨‹

        1. **ç¬¬ä¸€ç¨®ï¼šé—œéµè©åŒ¹é…**
           - ç³»çµ±è‡ªå‹•è¨ˆç®—é—œéµè©è¦†è“‹ç‡

        2. **ç¬¬äºŒç¨®ï¼šèªç¾©ç›¸ä¼¼åº¦**
           - ç³»çµ±è‡ªå‹•è¨ˆç®—èªç¾©ç›¸ä¼¼åº¦

        3. **ç¬¬ä¸‰ç¨®ï¼šGPT as a Judge**
           - ï¼ˆä¸€ï¼‰ç³»çµ±ç”Ÿæˆæ¨™æº–åŒ– prompt
           - ï¼ˆäºŒï¼‰æ‚¨è¤‡è£½ prompt åˆ° ChatGPT
           - ï¼ˆä¸‰ï¼‰è²¼å› ChatGPT çš„ JSON å›æ‡‰
           - ï¼ˆå››ï¼‰ç³»çµ±è‡ªå‹•æ•´åˆä¸¦å³æ™‚æ›´æ–°æ‰€æœ‰æŒ‡æ¨™

        #### ğŸš€ ä½¿ç”¨æ­¥é©Ÿ

        1. ä¸Šå‚³æ¸¬è©¦çµæœæª”æ¡ˆ
        2. ç³»çµ±è‡ªå‹•å®Œæˆé—œéµè©å’Œèªç¾©è©•ä¼°
        3. é€²å…¥ã€ŒGPT äººå·¥è©•å¯©ã€é ç±¤
        4. è¤‡è£½ prompt â†’ è²¼åˆ° ChatGPT â†’ è²¼å›çµæœ
        5. åœ¨ã€Œè©•ä¼°ç¸½è¦½ã€æŸ¥çœ‹æ•´åˆå¾Œçš„å®Œæ•´çµæœ
        """)

# é å°¾
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>RAG è©•ä¼°å„€è¡¨æ¿ v2.0 - æ•´åˆäººå·¥ GPT è©•å¯©</p>
    <p>Â© 2025 | é—œéµè© + èªç¾©ç›¸ä¼¼åº¦ + GPT äººå·¥è©•å¯© | </p>
</div>
""", unsafe_allow_html=True)
