"""
RAG æ¯”è¼ƒå„€è¡¨æ¿ v2.0 - ä¸‰å±¤è©•ä¼°æ¶æ§‹
====================================

å‡ç´šç‰¹æ€§ï¼š
1. æ”¯æ´ä¸‰å±¤è©•ä¼°çµæœé¡¯ç¤ºï¼ˆé—œéµè©ã€èªç¾©ã€GPTï¼‰
2. å¯é…ç½®è©•ä¼°å±¤ç´šå’Œæ¬Šé‡
3. å¤šç¶­åº¦æ•¸æ“šè¦–è¦ºåŒ–
4. æˆæœ¬é ä¼°å’Œæ•ˆèƒ½åˆ†æ
5. å®Œæ•´çš„è³‡æ–™è¼¸å…¥è¼¸å‡ºæ”¯æ´

ç‰ˆæœ¬ï¼š2.0
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from datetime import datetime
import json
import os
from rag_evaluation_two_models_v2 import RAGEvaluatorV2

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="RAG è©•ä¼°å„€è¡¨æ¿ v2.0 - ä¸‰å±¤è©•ä¼°æ¶æ§‹",
    page_icon="ğŸ†š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ– session state
if 'comparison_results' not in st.session_state:
    st.session_state.comparison_results = None
if 'evaluator_instance' not in st.session_state:
    st.session_state.evaluator_instance = None
if 'current_question_idx' not in st.session_state:
    st.session_state.current_question_idx = 0

# æ¨™é¡Œå’Œèªªæ˜
st.title("ğŸ†š RAG è©•ä¼°å„€è¡¨æ¿ v2.0")
st.markdown("### ä¸‰å±¤è©•ä¼°æ¶æ§‹ï¼šé—œéµè© + èªç¾©ç›¸ä¼¼åº¦ + GPT è©•å¯©")

# å´é‚Šæ¬„é…ç½®
with st.sidebar:
    st.header("ğŸ“ è¨­å®šèˆ‡æª”æ¡ˆé¸æ“‡")

    # æª”æ¡ˆé¸æ“‡æ–¹å¼
    file_source = st.radio(
        "é¸æ“‡æª”æ¡ˆä¾†æº",
        ["ğŸ“‚ æœ¬åœ°è³‡æ–™å¤¾", "ğŸ“¤ ä¸Šå‚³æª”æ¡ˆ"],
        help="é¸æ“‡è¦å¾æœ¬åœ°è³‡æ–™å¤¾è¼‰å…¥æˆ–ä¸Šå‚³æ–°æª”æ¡ˆ"
    )

    selected_file_path = None
    uploaded_file = None

    if file_source == "ğŸ“‚ æœ¬åœ°è³‡æ–™å¤¾":
        data_folder = "test_data"
        if not os.path.exists(data_folder):
            os.makedirs(data_folder)

        st.caption(f"è³‡æ–™å¤¾è·¯å¾‘ï¼š{data_folder}")

        try:
            all_files = os.listdir(data_folder)
            excel_files = [f for f in all_files
                          if f.endswith(('.xlsx', '.xls', '.csv')) and not f.startswith('~') and not f.startswith('.')]
        except Exception as e:
            st.error(f"è®€å–è³‡æ–™å¤¾æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
            excel_files = []

        if excel_files:
            selected_file = st.selectbox(
                "é¸æ“‡è¦è©•ä¼°çš„æª”æ¡ˆ",
                excel_files,
                help="å¾ test_data è³‡æ–™å¤¾ä¸­é¸æ“‡æª”æ¡ˆ"
            )
            selected_file_path = os.path.join(data_folder, selected_file)
            uploaded_file = selected_file_path

            file_info = os.stat(selected_file_path)
            st.info(f"æª”æ¡ˆå¤§å°ï¼š{file_info.st_size / 1024:.1f} KB")
            st.success(f"âœ… å·²è¼‰å…¥: {selected_file}")
        else:
            st.warning("âš ï¸ test_data è³‡æ–™å¤¾ä¸­æ²’æœ‰æ‰¾åˆ° Excel æˆ– CSV æª”æ¡ˆ")

    else:  # ä¸Šå‚³æª”æ¡ˆ
        uploaded_file = st.file_uploader(
            "ä¸Šå‚³æ¸¬è©¦çµæœExcel/CSVæª”æ¡ˆ",
            type=['xlsx', 'xls', 'csv'],
            help="è«‹ä¸Šå‚³åŒ…å«å‘é‡çŸ¥è­˜åº«(åŸå§‹ç‰ˆ)å’Œæ™ºæ…§æ–‡æª”çŸ¥è­˜åº«(å½™æ•´ç‰ˆ)å›ç­”çš„æ¸¬è©¦çµæœ"
        )

        if uploaded_file is not None:
            file_extension = uploaded_file.name.split('.')[-1].lower()
            selected_file_path = f"temp_uploaded.{file_extension}"
            with open(selected_file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            st.success(f"âœ… å·²è¼‰å…¥: {uploaded_file.name}")

    # çŸ¥è­˜åº«é¸æ“‡
    st.markdown("### ğŸ“š çŸ¥è­˜åº«è¨­å®š")
    col1, col2 = st.columns(2)

    with col1:
        original_kb = st.selectbox(
            "åŸå§‹ç‰ˆæœ¬",
            ["å‘é‡çŸ¥è­˜åº«", "æ™ºæ…§æ–‡æª”çŸ¥è­˜åº«"],
            index=0,
            help="é¸æ“‡åŸå§‹ç‰ˆæœ¬ä½¿ç”¨çš„çŸ¥è­˜åº«æŠ€è¡“"
        )

    with col2:
        optimized_kb = st.selectbox(
            "å„ªåŒ–ç‰ˆæœ¬",
            ["æ™ºæ…§æ–‡æª”çŸ¥è­˜åº«", "å‘é‡çŸ¥è­˜åº«+å„ªåŒ–"],
            index=0,
            help="é¸æ“‡å„ªåŒ–ç‰ˆæœ¬ä½¿ç”¨çš„çŸ¥è­˜åº«æŠ€è¡“"
        )

    # è©•ä¼°å±¤ç´šè¨­å®š
    st.markdown("### ğŸ¯ è©•ä¼°å±¤ç´šè¨­å®š")
    st.info("ğŸ” é¸æ“‡è¦å•Ÿç”¨çš„è©•ä¼°å±¤ç´š")

    enable_semantic = st.checkbox(
        "å•Ÿç”¨èªç¾©ç›¸ä¼¼åº¦è©•ä¼°",
        value=True,
        help="ä½¿ç”¨ Sentence Transformers è¨ˆç®—èªç¾©ç›¸ä¼¼åº¦ï¼ˆæ¨è–¦ï¼‰"
    )

    enable_gpt = st.checkbox(
        "å•Ÿç”¨ GPT è©•å¯©",
        value=False,
        help="ä½¿ç”¨ GPT é€²è¡Œå¤šç¶­åº¦æ·±åº¦è©•ä¼°ï¼ˆéœ€è¦ API é‡‘é‘°ï¼Œæœƒç”¢ç”Ÿè²»ç”¨ï¼‰"
    )

    openai_api_key = None
    if enable_gpt:
        openai_api_key = st.text_input(
            "OpenAI API é‡‘é‘°",
            type="password",
            help="è«‹è¼¸å…¥æ‚¨çš„ OpenAI API é‡‘é‘°"
        )

        if not openai_api_key:
            st.warning("âš ï¸ è«‹è¼¸å…¥ API é‡‘é‘°ä»¥å•Ÿç”¨ GPT è©•å¯©")
            enable_gpt = False

    # è©•åˆ†æ¬Šé‡è¨­å®š
    st.markdown("### âš–ï¸ è©•åˆ†æ¬Šé‡è¨­å®š")

    if enable_semantic and enable_gpt:
        st.info("ä¸‰å±¤è©•ä¼°æ¨¡å¼")
        weight_keyword = st.slider("é—œéµè©æ¬Šé‡", 0.0, 1.0, 0.3, 0.1)
        weight_semantic = st.slider("èªç¾©æ¬Šé‡", 0.0, 1.0, 0.3, 0.1)
        weight_gpt = 1.0 - weight_keyword - weight_semantic
        st.metric("GPT æ¬Šé‡", f"{weight_gpt:.1f}")
    elif enable_semantic:
        st.info("é›™å±¤è©•ä¼°æ¨¡å¼ï¼ˆé—œéµè© + èªç¾©ï¼‰")
        weight_keyword = st.slider("é—œéµè©æ¬Šé‡", 0.0, 1.0, 0.5, 0.1)
        weight_semantic = 1.0 - weight_keyword
        weight_gpt = 0.0
        st.metric("èªç¾©æ¬Šé‡", f"{weight_semantic:.1f}")
    elif enable_gpt:
        st.info("é›™å±¤è©•ä¼°æ¨¡å¼ï¼ˆé—œéµè© + GPTï¼‰")
        weight_keyword = st.slider("é—œéµè©æ¬Šé‡", 0.0, 1.0, 0.4, 0.1)
        weight_gpt = 1.0 - weight_keyword
        weight_semantic = 0.0
        st.metric("GPT æ¬Šé‡", f"{weight_gpt:.1f}")
    else:
        st.info("å–®å±¤è©•ä¼°æ¨¡å¼ï¼ˆåƒ…é—œéµè©ï¼‰")
        weight_keyword = 1.0
        weight_semantic = 0.0
        weight_gpt = 0.0

    weights = {
        "keyword": weight_keyword,
        "semantic": weight_semantic,
        "gpt": weight_gpt
    }

    # é¡¯è‘—æ”¹å–„é–¾å€¼
    st.markdown("### ğŸ¯ åˆ†æè¨­å®š")
    improvement_threshold = st.slider(
        "é¡¯è‘—æ”¹å–„é–¾å€¼ (%)",
        min_value=5,
        max_value=50,
        value=10,
        help="ç•¶æ”¹å–„å¹…åº¦è¶…éæ­¤é–¾å€¼æ™‚ï¼Œæ¨™è¨˜ç‚ºé¡¯è‘—æ”¹å–„"
    )

# ä¸»è¦å…§å®¹å€
if uploaded_file is not None:
    # è™•ç†æª”æ¡ˆ
    if isinstance(uploaded_file, str):
        temp_file_path = uploaded_file
    else:
        temp_file_path = "temp_comparison_file.xlsx"
        with open(temp_file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

    # æ ¹æ“šé¸æ“‡çš„çŸ¥è­˜åº«é¡å‹å»ºç«‹è©•ä¼°å™¨
    try:
        if original_kb == "å‘é‡çŸ¥è­˜åº«" and optimized_kb == "æ™ºæ…§æ–‡æª”çŸ¥è­˜åº«":
            model_type = "cross"
        elif original_kb == "å‘é‡çŸ¥è­˜åº«":
            model_type = "vector"
        else:
            model_type = "smart_doc"

        evaluator = RAGEvaluatorV2(
            temp_file_path,
            model_type=model_type,
            enable_semantic=enable_semantic,
            enable_gpt=enable_gpt,
            openai_api_key=openai_api_key,
            weights=weights
        )

        st.session_state.evaluator_instance = evaluator

        # åŸ·è¡Œè©•ä¼°
        with st.spinner("ğŸ”„ æ­£åœ¨é€²è¡Œä¸‰å±¤è©•ä¼°åˆ†æ..."):
            results_df = evaluator.evaluate_all()
            st.session_state.comparison_results = results_df

        # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
        if os.path.exists(temp_file_path) and not isinstance(uploaded_file, str):
            os.remove(temp_file_path)

    except Exception as e:
        st.error(f"âŒ è©•ä¼°éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        if os.path.exists(temp_file_path) and not isinstance(uploaded_file, str):
            os.remove(temp_file_path)
        st.stop()

    # å»ºç«‹é ç±¤
    tab1, tab2, tab3, tab4, tab5 = st.tabs(
        ["ğŸ“Š è©•ä¼°ç¸½è¦½", "ğŸ“ˆ è©³ç´°å°æ¯”", "ğŸ” å±¤ç´šåˆ†æ", "ğŸ’¬ å•é¡Œå°è¦½", "ğŸ“¥ ä¸‹è¼‰çµæœ"]
    )

    with tab1:
        st.markdown("### ğŸ“Š è©•ä¼°ç¸½è¦½")

        # ç²å–çµ±è¨ˆæ•¸æ“š
        stats = evaluator.generate_summary_stats()

        # é—œéµæŒ‡æ¨™å¡ç‰‡
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.markdown("**ğŸ“ˆ ç¶œåˆè©•åˆ†æå‡**")
            improvement = stats['æ”¹å–„æ•ˆæœ']['å¹³å‡ç¶œåˆè©•åˆ†æå‡']
            color = '#28a745' if improvement > 0 else '#dc3545'
            st.markdown(f"<h1 style='color: {color}; margin: 0;'>{stats['å½™æ•´å„ªåŒ–ç‰ˆæœ¬']['å¹³å‡ç¶œåˆè©•åˆ†']:.1f}åˆ†</h1>", unsafe_allow_html=True)
            st.markdown(f"<p style='color: {color}; font-size: 18px;'>{'â†‘' if improvement > 0 else 'â†“'} {abs(improvement):.1f}åˆ†</p>", unsafe_allow_html=True)

        with col2:
            st.markdown("**ğŸ¯ é—œéµè©è¦†è“‹ç‡**")
            keyword_improvement = stats['æ”¹å–„æ•ˆæœ']['å¹³å‡é—œéµè©è¦†è“‹ç‡æå‡']
            color = '#28a745' if keyword_improvement > 0 else '#dc3545'
            st.markdown(f"<h1 style='color: {color}; margin: 0;'>{stats['å½™æ•´å„ªåŒ–ç‰ˆæœ¬']['å¹³å‡é—œéµè©è¦†è“‹ç‡']:.1f}%</h1>", unsafe_allow_html=True)
            st.markdown(f"<p style='color: {color}; font-size: 18px;'>{'â†‘' if keyword_improvement > 0 else 'â†“'} {abs(keyword_improvement):.1f}%</p>", unsafe_allow_html=True)

        with col3:
            if enable_semantic:
                st.markdown("**ğŸ”¤ èªç¾©ç›¸ä¼¼åº¦**")
                semantic_improvement = stats['æ”¹å–„æ•ˆæœ']['å¹³å‡èªç¾©ç›¸ä¼¼åº¦æå‡']
                color = '#28a745' if semantic_improvement > 0 else '#dc3545'
                st.markdown(f"<h1 style='color: {color}; margin: 0;'>{stats['å½™æ•´å„ªåŒ–ç‰ˆæœ¬']['å¹³å‡èªç¾©ç›¸ä¼¼åº¦']:.1f}%</h1>", unsafe_allow_html=True)
                st.markdown(f"<p style='color: {color}; font-size: 18px;'>{'â†‘' if semantic_improvement > 0 else 'â†“'} {abs(semantic_improvement):.1f}%</p>", unsafe_allow_html=True)
            else:
                st.info("èªç¾©ç›¸ä¼¼åº¦æœªå•Ÿç”¨")

        with col4:
            if enable_gpt:
                st.markdown("**ğŸ¤– GPT è©•åˆ†**")
                gpt_improvement = stats['æ”¹å–„æ•ˆæœ']['å¹³å‡GPTè©•åˆ†æå‡']
                color = '#28a745' if gpt_improvement > 0 else '#dc3545'
                st.markdown(f"<h1 style='color: {color}; margin: 0;'>{stats['å½™æ•´å„ªåŒ–ç‰ˆæœ¬']['å¹³å‡GPTè©•åˆ†']:.1f}åˆ†</h1>", unsafe_allow_html=True)
                st.markdown(f"<p style='color: {color}; font-size: 18px;'>{'â†‘' if gpt_improvement > 0 else 'â†“'} {abs(gpt_improvement):.1f}åˆ†</p>", unsafe_allow_html=True)
            else:
                st.info("GPT è©•å¯©æœªå•Ÿç”¨")

        # è©•ä¼°å±¤ç´šé…ç½®é¡¯ç¤º
        st.markdown("### âš™ï¸ è©•ä¼°é…ç½®")
        config_col1, config_col2, config_col3 = st.columns(3)

        with config_col1:
            st.metric("é—œéµè©åŒ¹é…", "âœ… å•Ÿç”¨", f"æ¬Šé‡: {weights['keyword']:.0%}")

        with config_col2:
            status = "âœ… å•Ÿç”¨" if enable_semantic else "âŒ åœç”¨"
            st.metric("èªç¾©ç›¸ä¼¼åº¦", status, f"æ¬Šé‡: {weights['semantic']:.0%}")

        with config_col3:
            status = "âœ… å•Ÿç”¨" if enable_gpt else "âŒ åœç”¨"
            st.metric("GPT è©•å¯©", status, f"æ¬Šé‡: {weights['gpt']:.0%}")

        # æ”¹å–„çµ±è¨ˆ
        st.markdown("### ğŸ“ˆ æ”¹å–„çµ±è¨ˆ")

        stat_col1, stat_col2, stat_col3 = st.columns(3)

        with stat_col1:
            significant_improvements = (results_df['FINAL_IMPROVEMENT'] >= improvement_threshold).sum()
            improvement_rate = significant_improvements / len(results_df) * 100
            st.metric(
                "é¡¯è‘—æ”¹å–„å•é¡Œæ•¸",
                f"{significant_improvements} é¡Œ",
                f"{improvement_rate:.1f}%"
            )

        with stat_col2:
            no_change = (results_df['FINAL_IMPROVEMENT'] == 0).sum()
            st.metric("ç„¡è®ŠåŒ–å•é¡Œæ•¸", f"{no_change} é¡Œ")

        with stat_col3:
            declined = (results_df['FINAL_IMPROVEMENT'] < 0).sum()
            declined_rate = declined / len(results_df) * 100
            st.metric(
                "é€€æ­¥å•é¡Œæ•¸",
                f"{declined} é¡Œ",
                f"{declined_rate:.1f}%",
                delta_color="inverse"
            )

        # åˆ†æ•¸åˆ†å¸ƒåœ–è¡¨
        st.markdown("### ğŸ“Š ç¶œåˆè©•åˆ†åˆ†å¸ƒ")

        fig = go.Figure()

        fig.add_trace(go.Histogram(
            x=results_df['FINAL_SCORE_ORIGINAL'],
            name='åŸå§‹ç‰ˆæœ¬',
            opacity=0.7,
            marker_color='#e57373',
            nbinsx=20
        ))

        fig.add_trace(go.Histogram(
            x=results_df['FINAL_SCORE_OPTIMIZED'],
            name='å„ªåŒ–ç‰ˆæœ¬',
            opacity=0.7,
            marker_color='#81c784',
            nbinsx=20
        ))

        fig.update_layout(
            barmode='overlay',
            title='ç¶œåˆè©•åˆ†åˆ†å¸ƒå°æ¯”',
            xaxis_title='ç¶œåˆè©•åˆ†',
            yaxis_title='å•é¡Œæ•¸é‡',
            height=400
        )

        st.plotly_chart(fig, use_container_width=True)

    with tab2:
        st.markdown("### ğŸ“ˆ è©³ç´°å°æ¯”åˆ†æ")

        # å»ºç«‹å¤šå±¤ç´šå°æ¯”è¡¨æ ¼
        comparison_data = []

        metrics = []
        if True:  # é—œéµè©ç¸½æ˜¯å•Ÿç”¨
            metrics.append(('é—œéµè©è¦†è“‹ç‡', 'KEYWORD_COVERAGE'))
        if enable_semantic:
            metrics.append(('èªç¾©ç›¸ä¼¼åº¦', 'SEMANTIC_SIMILARITY'))
        if enable_gpt:
            metrics.append(('GPT è©•åˆ†', 'GPT_OVERALL'))
        metrics.append(('ç¶œåˆè©•åˆ†', 'FINAL_SCORE'))

        for metric_name, metric_key in metrics:
            comparison_data.append({
                'è©•ä¼°æŒ‡æ¨™': f'ğŸ”´ åŸå§‹ç‰ˆæœ¬ - {metric_name}',
                'å¹³å‡åˆ†æ•¸': f"{results_df[f'{metric_key}_ORIGINAL'].mean():.1f}",
                'æœ€é«˜åˆ†': f"{results_df[f'{metric_key}_ORIGINAL'].max():.1f}",
                'æœ€ä½åˆ†': f"{results_df[f'{metric_key}_ORIGINAL'].min():.1f}",
                'æ¨™æº–å·®': f"{results_df[f'{metric_key}_ORIGINAL'].std():.1f}"
            })

            comparison_data.append({
                'è©•ä¼°æŒ‡æ¨™': f'ğŸŸ¢ å„ªåŒ–ç‰ˆæœ¬ - {metric_name}',
                'å¹³å‡åˆ†æ•¸': f"{results_df[f'{metric_key}_OPTIMIZED'].mean():.1f}",
                'æœ€é«˜åˆ†': f"{results_df[f'{metric_key}_OPTIMIZED'].max():.1f}",
                'æœ€ä½åˆ†': f"{results_df[f'{metric_key}_OPTIMIZED'].min():.1f}",
                'æ¨™æº–å·®': f"{results_df[f'{metric_key}_OPTIMIZED'].std():.1f}"
            })

            improvement = results_df[f'{metric_key}_OPTIMIZED'].mean() - results_df[f'{metric_key}_ORIGINAL'].mean()
            comparison_data.append({
                'è©•ä¼°æŒ‡æ¨™': f'ğŸ“Š æ”¹å–„å¹…åº¦ - {metric_name}',
                'å¹³å‡åˆ†æ•¸': f"{improvement:+.1f}",
                'æœ€é«˜åˆ†': f"{results_df[f'{metric_key.replace("SCORE", "IMPROVEMENT").replace("COVERAGE", "IMPROVEMENT").replace("SIMILARITY", "IMPROVEMENT").replace("OVERALL", "IMPROVEMENT")}'].max():+.1f}",
                'æœ€ä½åˆ†': f"{results_df[f'{metric_key.replace("SCORE", "IMPROVEMENT").replace("COVERAGE", "IMPROVEMENT").replace("SIMILARITY", "IMPROVEMENT").replace("OVERALL", "IMPROVEMENT")}'].min():+.1f}",
                'æ¨™æº–å·®': "-"
            })

        comparison_df = pd.DataFrame(comparison_data)
        st.dataframe(comparison_df, use_container_width=True, hide_index=True)

        # é›·é”åœ–å°æ¯”
        st.markdown("### ğŸ¯ å¤šç¶­åº¦é›·é”åœ–å°æ¯”")

        categories = []
        original_scores = []
        optimized_scores = []

        if True:  # é—œéµè©
            categories.append('é—œéµè©è¦†è“‹ç‡')
            original_scores.append(results_df['KEYWORD_COVERAGE_ORIGINAL'].mean())
            optimized_scores.append(results_df['KEYWORD_COVERAGE_OPTIMIZED'].mean())

        if enable_semantic:
            categories.append('èªç¾©ç›¸ä¼¼åº¦')
            original_scores.append(results_df['SEMANTIC_SIMILARITY_ORIGINAL'].mean())
            optimized_scores.append(results_df['SEMANTIC_SIMILARITY_OPTIMIZED'].mean())

        if enable_gpt:
            categories.append('GPT è©•åˆ†')
            original_scores.append(results_df['GPT_OVERALL_ORIGINAL'].mean())
            optimized_scores.append(results_df['GPT_OVERALL_OPTIMIZED'].mean())

        fig_radar = go.Figure()

        fig_radar.add_trace(go.Scatterpolar(
            r=original_scores + [original_scores[0]],
            theta=categories + [categories[0]],
            fill='toself',
            name='åŸå§‹ç‰ˆæœ¬',
            line_color='#e57373'
        ))

        fig_radar.add_trace(go.Scatterpolar(
            r=optimized_scores + [optimized_scores[0]],
            theta=categories + [categories[0]],
            fill='toself',
            name='å„ªåŒ–ç‰ˆæœ¬',
            line_color='#81c784'
        ))

        fig_radar.update_layout(
            polar=dict(radialaxis=dict(visible=True, range=[0, 100])),
            showlegend=True,
            height=500
        )

        st.plotly_chart(fig_radar, use_container_width=True)

    with tab3:
        st.markdown("### ğŸ” å±¤ç´šåˆ†æ")
        st.info("æ·±å…¥åˆ†æå„è©•ä¼°å±¤ç´šçš„è²¢ç»åº¦å’Œæ”¹å–„æ•ˆæœ")

        # å±¤ç´šè²¢ç»åº¦åˆ†æ
        st.markdown("#### ğŸ“Š å„å±¤ç´šè©•åˆ†è²¢ç»åº¦")

        layer_col1, layer_col2 = st.columns(2)

        with layer_col1:
            # åŸå§‹ç‰ˆæœ¬è²¢ç»åº¦
            original_contributions = []
            labels = []

            if weight_keyword > 0:
                original_contributions.append(
                    results_df['KEYWORD_COVERAGE_ORIGINAL'].mean() * weight_keyword
                )
                labels.append(f'é—œéµè© ({weight_keyword:.0%})')

            if weight_semantic > 0:
                original_contributions.append(
                    results_df['SEMANTIC_SIMILARITY_ORIGINAL'].mean() * weight_semantic
                )
                labels.append(f'èªç¾© ({weight_semantic:.0%})')

            if weight_gpt > 0:
                original_contributions.append(
                    results_df['GPT_OVERALL_ORIGINAL'].mean() * weight_gpt
                )
                labels.append(f'GPT ({weight_gpt:.0%})')

            fig_orig = go.Figure(data=[go.Pie(
                labels=labels,
                values=original_contributions,
                title='åŸå§‹ç‰ˆæœ¬è²¢ç»åº¦'
            )])

            st.plotly_chart(fig_orig, use_container_width=True)

        with layer_col2:
            # å„ªåŒ–ç‰ˆæœ¬è²¢ç»åº¦
            optimized_contributions = []

            if weight_keyword > 0:
                optimized_contributions.append(
                    results_df['KEYWORD_COVERAGE_OPTIMIZED'].mean() * weight_keyword
                )

            if weight_semantic > 0:
                optimized_contributions.append(
                    results_df['SEMANTIC_SIMILARITY_OPTIMIZED'].mean() * weight_semantic
                )

            if weight_gpt > 0:
                optimized_contributions.append(
                    results_df['GPT_OVERALL_OPTIMIZED'].mean() * weight_gpt
                )

            fig_opt = go.Figure(data=[go.Pie(
                labels=labels,
                values=optimized_contributions,
                title='å„ªåŒ–ç‰ˆæœ¬è²¢ç»åº¦'
            )])

            st.plotly_chart(fig_opt, use_container_width=True)

        # æ”¹å–„åˆ†å¸ƒåˆ†æ
        st.markdown("#### ğŸ“ˆ å„å±¤ç´šæ”¹å–„åˆ†å¸ƒ")

        improvement_cols = []
        improvement_names = []

        if True:  # é—œéµè©
            improvement_cols.append('KEYWORD_IMPROVEMENT')
            improvement_names.append('é—œéµè©è¦†è“‹ç‡')

        if enable_semantic:
            improvement_cols.append('SEMANTIC_IMPROVEMENT')
            improvement_names.append('èªç¾©ç›¸ä¼¼åº¦')

        if enable_gpt:
            improvement_cols.append('GPT_IMPROVEMENT')
            improvement_names.append('GPT è©•åˆ†')

        fig_improvements = make_subplots(
            rows=1,
            cols=len(improvement_cols),
            subplot_titles=improvement_names
        )

        for idx, (col, name) in enumerate(zip(improvement_cols, improvement_names), 1):
            fig_improvements.add_trace(
                go.Histogram(
                    x=results_df[col],
                    name=name,
                    nbinsx=20
                ),
                row=1,
                col=idx
            )

        fig_improvements.update_layout(height=400, showlegend=False)
        st.plotly_chart(fig_improvements, use_container_width=True)

    with tab4:
        st.markdown("### ğŸ’¬ å•é¡Œå°è¦½")
        st.info("ç€è¦½æ‰€æœ‰æ¸¬è©¦å•é¡Œçš„è©³ç´°è©•ä¼°çµæœ")

        # ç¯©é¸é¸é …
        filter_option = st.selectbox(
            "ç¯©é¸é¡¯ç¤º",
            ["æ‰€æœ‰å•é¡Œ", "é¡¯è‘—æ”¹å–„", "ç•¥æœ‰æ”¹å–„", "ç„¡è®ŠåŒ–", "æ•ˆæœé€€æ­¥"]
        )

        # æ ¹æ“šæ¢ä»¶ç¯©é¸
        if filter_option == "é¡¯è‘—æ”¹å–„":
            filtered_df = results_df[results_df['FINAL_IMPROVEMENT'] >= improvement_threshold]
        elif filter_option == "ç•¥æœ‰æ”¹å–„":
            filtered_df = results_df[(results_df['FINAL_IMPROVEMENT'] > 0) & (results_df['FINAL_IMPROVEMENT'] < improvement_threshold)]
        elif filter_option == "ç„¡è®ŠåŒ–":
            filtered_df = results_df[results_df['FINAL_IMPROVEMENT'] == 0]
        elif filter_option == "æ•ˆæœé€€æ­¥":
            filtered_df = results_df[results_df['FINAL_IMPROVEMENT'] < 0]
        else:
            filtered_df = results_df

        st.info(f"é¡¯ç¤º {len(filtered_df)} / {len(results_df)} å€‹å•é¡Œ")

        # é¡¯ç¤ºå•é¡Œåˆ—è¡¨
        for idx, row in filtered_df.iterrows():
            with st.expander(f"å•é¡Œ {row['åºè™Ÿ']}: {row['æ¸¬è©¦å•é¡Œ'][:50]}..."):
                # å•é¡Œè³‡è¨Š
                st.markdown(f"**æ¸¬è©¦å•é¡Œ**: {row['æ¸¬è©¦å•é¡Œ']}")
                st.markdown(f"**æ‡‰å›ç­”è©å½™**: {row['æ‡‰å›ç­”ä¹‹è©å½™']}")

                # è©•åˆ†å°æ¯”
                score_col1, score_col2, score_col3 = st.columns(3)

                with score_col1:
                    st.metric(
                        "é—œéµè©è¦†è“‹ç‡",
                        f"{row['KEYWORD_COVERAGE_OPTIMIZED']:.1f}%",
                        f"{row['KEYWORD_IMPROVEMENT']:.1f}%"
                    )

                with score_col2:
                    if enable_semantic:
                        st.metric(
                            "èªç¾©ç›¸ä¼¼åº¦",
                            f"{row['SEMANTIC_SIMILARITY_OPTIMIZED']:.1f}%",
                            f"{row['SEMANTIC_IMPROVEMENT']:.1f}%"
                        )

                with score_col3:
                    if enable_gpt:
                        st.metric(
                            "GPT è©•åˆ†",
                            f"{row['GPT_OVERALL_OPTIMIZED']:.1f}",
                            f"{row['GPT_IMPROVEMENT']:.1f}"
                        )

                # ç¶œåˆè©•åˆ†
                st.metric(
                    "ğŸ“Š ç¶œåˆè©•åˆ†",
                    f"{row['FINAL_SCORE_OPTIMIZED']:.1f}",
                    f"{row['FINAL_IMPROVEMENT']:.1f}"
                )

                # GPT æ¨ç†ï¼ˆå¦‚æœæœ‰ï¿½ï¿½
                if enable_gpt and row['GPT_REASONING_OPTIMIZED']:
                    st.markdown("**ğŸ¤– GPT è©•å¯©æ„è¦‹**")
                    st.info(row['GPT_REASONING_OPTIMIZED'])

    with tab5:
        st.markdown("### ğŸ“¥ ä¸‹è¼‰çµæœ")
        st.info("åŒ¯å‡ºå®Œæ•´è©•ä¼°å ±å‘Š")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### ğŸ“Š è©•ä¼°å ±å‘Šï¼ˆExcelï¼‰")

            if st.button("ç”Ÿæˆè©•ä¼°å ±å‘Š", type="primary"):
                filename = f'RAGè©•ä¼°å ±å‘Š_v2_{datetime.now().strftime("%Y%m%d_%H%M%S")}.xlsx'
                evaluator.save_results(filename)

                with open(filename, 'rb') as f:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰è©•ä¼°å ±å‘Š",
                        data=f,
                        file_name=filename,
                        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                    )

                if os.path.exists(filename):
                    os.remove(filename)

                st.success("âœ… è©•ä¼°å ±å‘Šå·²ç”Ÿæˆ")

        with col2:
            st.markdown("#### ğŸ“ˆ çµ±è¨ˆæ‘˜è¦ï¼ˆJSONï¼‰")

            if st.button("ç”Ÿæˆçµ±è¨ˆæ‘˜è¦", type="secondary"):
                stats = evaluator.generate_summary_stats()

                json_filename = f'çµ±è¨ˆæ‘˜è¦_v2_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
                with open(json_filename, 'w', encoding='utf-8') as f:
                    json.dump(stats, f, ensure_ascii=False, indent=2)

                with open(json_filename, 'rb') as f:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰çµ±è¨ˆæ‘˜è¦",
                        data=f,
                        file_name=json_filename,
                        mime='application/json'
                    )

                if os.path.exists(json_filename):
                    os.remove(json_filename)

                st.success("âœ… çµ±è¨ˆæ‘˜è¦å·²ç”Ÿæˆ")

else:
    # æœªä¸Šå‚³æª”æ¡ˆæ™‚çš„æç¤º
    st.info("ğŸ‘ˆ è«‹å¾å´é‚Šæ¬„ä¸Šå‚³æ¸¬è©¦çµæœæª”æ¡ˆé–‹å§‹è©•ä¼°")

    # ä½¿ç”¨èªªæ˜
    with st.expander("ğŸ“– ä½¿ç”¨èªªæ˜ v2.0", expanded=True):
        st.markdown("""
        ### ğŸ¯ ç³»çµ±ç‰¹æ€§

        æœ¬ç³»çµ±æ¡ç”¨**ä¸‰å±¤è©•ä¼°æ¶æ§‹**ï¼Œæä¾›å…¨æ–¹ä½çš„ RAG ç³»çµ±å“è³ªè©•ä¼°ï¼š

        #### ğŸ“Š ä¸‰å±¤è©•ä¼°æ¶æ§‹

        1. **ç¬¬ä¸€å±¤ï¼šé—œéµè©åŒ¹é…**ï¼ˆå¿…é¸ï¼Œå¿«é€Ÿï¼‰
           - è©•ä¼°å›ç­”ä¸­åŒ…å«çš„é—œéµè©æ¯”ä¾‹
           - æ”¯æ´åŒç¾©è©è­˜åˆ¥
           - è©•ä¼°é€Ÿåº¦ï¼šæ¥µå¿«

        2. **ç¬¬äºŒå±¤ï¼šèªç¾©ç›¸ä¼¼åº¦**ï¼ˆå¯é¸ï¼Œæ¨è–¦ï¼‰
           - ä½¿ç”¨ Sentence Transformers è¨ˆç®—èªç¾©ç›¸ä¼¼åº¦
           - æ•æ‰èªç¾©å±¤é¢çš„åŒ¹é…åº¦
           - è©•ä¼°é€Ÿåº¦ï¼šä¸­ç­‰
           - éœ€è¦ï¼šå®‰è£ sentence-transformers

        3. **ç¬¬ä¸‰å±¤ï¼šGPT as a Judge**ï¼ˆå¯é¸ï¼Œæ·±åº¦ï¼‰
           - å¤šç¶­åº¦è©•ä¼°ï¼šç›¸é—œæ€§ã€å®Œæ•´æ€§ã€æº–ç¢ºæ€§ã€å¿ å¯¦åº¦
           - æä¾›è³ªåŒ–åé¥‹å’Œæ”¹é€²å»ºè­°
           - è©•ä¼°é€Ÿåº¦ï¼šè¼ƒæ…¢
           - éœ€è¦ï¼šOpenAI API é‡‘é‘°ï¼ˆæœƒç”¢ç”Ÿè²»ç”¨ï¼‰

        #### ğŸš€ é–‹å§‹ä½¿ç”¨

        1. é¸æ“‡è©•ä¼°å±¤ç´šï¼ˆå»ºè­°å•Ÿç”¨èªç¾©ç›¸ä¼¼åº¦ï¼‰
        2. ä¸Šå‚³æ¸¬è©¦çµæœ Excel/CSV æª”æ¡ˆ
        3. è¨­å®šè©•åˆ†æ¬Šé‡ï¼ˆç³»çµ±æœƒè‡ªå‹•å»ºè­°ï¼‰
        4. æŸ¥çœ‹å¤šç¶­åº¦è©•ä¼°çµæœ
        5. å°å‡ºå®Œæ•´å ±å‘Š

        #### ğŸ“ æª”æ¡ˆæ ¼å¼è¦æ±‚

        - **æ¸¬è©¦å•é¡Œ**: æ¸¬è©¦çš„å•é¡Œå…§å®¹
        - **æ‡‰å›ç­”è©å½™**: æœŸæœ›å›ç­”åŒ…å«çš„é—œéµè©å½™
        - **å‘é‡çŸ¥è­˜åº«ï¼ˆåŸå§‹ç‰ˆï¼‰**: åŸå§‹ç‰ˆæœ¬çš„å›ç­”
        - **æ™ºæ…§æ–‡æª”çŸ¥è­˜åº«ï¼ˆå½™æ•´ç‰ˆï¼‰**: å„ªåŒ–ç‰ˆæœ¬çš„å›ç­”

        #### ğŸ’¡ æœ€ä½³å¯¦è¸

        - **å¿«é€Ÿè©•ä¼°**: åƒ…ä½¿ç”¨é—œéµè©åŒ¹é…
        - **æ¨è–¦é…ç½®**: é—œéµè© + èªç¾©ç›¸ä¼¼åº¦ï¼ˆå¹³è¡¡é€Ÿåº¦å’Œæº–ç¢ºåº¦ï¼‰
        - **æ·±åº¦åˆ†æ**: å•Ÿç”¨æ‰€æœ‰ä¸‰å±¤è©•ä¼°ï¼ˆæœ€æº–ç¢ºï¼Œä½†è¼ƒæ…¢ï¼‰

        #### ğŸ’° æˆæœ¬ä¼°ç®—ï¼ˆGPT è©•å¯©ï¼‰

        - ç´„ $0.002 USD / å•é¡Œï¼ˆä½¿ç”¨ GPT-3.5-turboï¼‰
        - 100 é¡Œæ¸¬è©¦é›†ç´„ $0.20 USD
        """)

# é å°¾
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>RAG è©•ä¼°å„€è¡¨æ¿ v2.0 - ä¸‰å±¤è©•ä¼°æ¶æ§‹</p>
    <p>Â© 2024 | é—œéµè©åŒ¹é… + èªç¾©ç›¸ä¼¼åº¦ + GPT è©•å¯©</p>
</div>
""", unsafe_allow_html=True)
