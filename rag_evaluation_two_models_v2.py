"""
RAG è©•ä¼°å™¨ v2.0 - ä¸‰å±¤è©•ä¼°æ¶æ§‹
=================================

å‡ç´šç‰¹æ€§ï¼š
1. ç¬¬ä¸€å±¤ï¼šé—œéµè©åŒ¹é…è©•ä¼°ï¼ˆå¿«é€Ÿï¼‰
2. ç¬¬äºŒå±¤ï¼šèªç¾©ç›¸ä¼¼åº¦è©•ä¼°ï¼ˆä¸­ç­‰é€Ÿåº¦ï¼‰
3. ç¬¬ä¸‰å±¤ï¼šGPT as a Judge è©•ä¼°ï¼ˆæ·±åº¦åˆ†æï¼Œå¯é¸ï¼‰
4. éˆæ´»çš„æ¬Šé‡é…ç½®ç³»çµ±
5. å®Œæ•´çš„è³‡æ–™è¼¸å…¥è¼¸å‡ºæ”¯æ´

ä½œè€…ï¼šAI çŸ¥è­˜åº«å„ªåŒ–åœ˜éšŠ
ç‰ˆæœ¬ï¼š2.0
æ—¥æœŸï¼š2024
"""

import pandas as pd
import re
import jieba
import numpy as np
from typing import List, Dict, Tuple, Optional
import streamlit as st
from datetime import datetime
import json
import os

# ç¬¬äºŒå±¤ï¼šèªç¾©ç›¸ä¼¼åº¦
try:
    from sentence_transformers import SentenceTransformer, util
    SEMANTIC_AVAILABLE = True
except ImportError:
    SEMANTIC_AVAILABLE = False
    print("âš ï¸ è­¦å‘Š: sentence-transformers æœªå®‰è£ï¼Œèªç¾©ç›¸ä¼¼åº¦åŠŸèƒ½å°‡è¢«åœç”¨")
    print("å®‰è£æ–¹å¼: pip install sentence-transformers")

# ç¬¬ä¸‰å±¤ï¼šGPT è©•å¯©
try:
    import openai
    GPT_AVAILABLE = True
except ImportError:
    GPT_AVAILABLE = False
    print("âš ï¸ è­¦å‘Š: openai æœªå®‰è£ï¼ŒGPT è©•å¯©åŠŸèƒ½å°‡è¢«åœç”¨")
    print("å®‰è£æ–¹å¼: pip install openai")


class RAGEvaluatorV2:
    """
    RAG è©•ä¼°å™¨ v2.0 - ä¸‰å±¤è©•ä¼°æ¶æ§‹

    è©•ä¼°å±¤ç´šï¼š
    - Layer 1: é—œéµè©åŒ¹é…ï¼ˆå¿…é¸ï¼Œå¿«é€Ÿï¼‰
    - Layer 2: èªç¾©ç›¸ä¼¼åº¦ï¼ˆå¯é¸ï¼Œæ¨è–¦ï¼‰
    - Layer 3: GPT Judgeï¼ˆå¯é¸ï¼Œæ·±åº¦ï¼‰
    """

    def __init__(
        self,
        excel_path: str,
        model_type: str = "cross",
        enable_semantic: bool = True,
        enable_gpt: bool = False,
        openai_api_key: Optional[str] = None,
        weights: Optional[Dict[str, float]] = None
    ):
        """
        åˆå§‹åŒ– RAG è©•ä¼°å™¨ v2.0

        åƒæ•¸:
            excel_path: Excel æˆ– CSV æª”æ¡ˆè·¯å¾‘
            model_type: "vector", "smart_doc", æˆ– "cross"ï¼ˆè·¨æŠ€è¡“æ¯”è¼ƒï¼‰
            enable_semantic: æ˜¯å¦å•Ÿç”¨èªç¾©ç›¸ä¼¼åº¦è©•ä¼°
            enable_gpt: æ˜¯å¦å•Ÿç”¨ GPT è©•å¯©
            openai_api_key: OpenAI API é‡‘é‘°ï¼ˆå•Ÿç”¨ GPT è©•å¯©æ™‚éœ€è¦ï¼‰
            weights: è©•åˆ†æ¬Šé‡é…ç½® {"keyword": 0.3, "semantic": 0.3, "gpt": 0.4}
        """
        # è®€å–è³‡æ–™
        if excel_path.lower().endswith('.csv'):
            self.df = pd.read_csv(excel_path, encoding='utf-8-sig')
        else:
            self.df = pd.read_excel(excel_path)

        self.model_type = model_type
        jieba.setLogLevel(20)

        # è©•ä¼°å±¤ç´šé…ç½®
        self.enable_semantic = enable_semantic and SEMANTIC_AVAILABLE
        self.enable_gpt = enable_gpt and GPT_AVAILABLE

        # åˆå§‹åŒ–èªç¾©æ¨¡å‹
        if self.enable_semantic:
            try:
                print("ğŸ”„ è¼‰å…¥èªç¾©ç›¸ä¼¼åº¦æ¨¡å‹...")
                # ä½¿ç”¨ device='cpu' é¿å… GPU ç›¸é—œéŒ¯èª¤
                self.semantic_model = SentenceTransformer(
                    'paraphrase-multilingual-MiniLM-L12-v2',
                    device='cpu'
                )
                print("âœ… èªç¾©ç›¸ä¼¼åº¦æ¨¡å‹è¼‰å…¥å®Œæˆ")
            except Exception as e:
                print(f"âŒ èªç¾©æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}")
                print("âš ï¸ å°‡åœç”¨èªç¾©ç›¸ä¼¼åº¦è©•ä¼°")
                self.enable_semantic = False
                self.semantic_model = None
        else:
            self.semantic_model = None

        # åˆå§‹åŒ– GPT é…ç½®
        if self.enable_gpt:
            if openai_api_key:
                openai.api_key = openai_api_key
                print("âœ… GPT è©•å¯©å·²å•Ÿç”¨")
            else:
                print("âš ï¸ è­¦å‘Š: æœªæä¾› OpenAI API é‡‘é‘°ï¼ŒGPT è©•å¯©å°‡è¢«åœç”¨")
                self.enable_gpt = False

        # è¨­å®šè©•åˆ†æ¬Šé‡
        self.weights = self._initialize_weights(weights)

        # è‡ªå‹•åµæ¸¬æ¬„ä½
        self._detect_columns()

        print(f"\nğŸ“Š è©•ä¼°é…ç½®æ‘˜è¦:")
        print(f"  - é—œéµè©åŒ¹é…: âœ… (æ¬Šé‡: {self.weights['keyword']:.0%})")
        print(f"  - èªç¾©ç›¸ä¼¼åº¦: {'âœ…' if self.enable_semantic else 'âŒ'} (æ¬Šé‡: {self.weights['semantic']:.0%})")
        print(f"  - GPT è©•å¯©: {'âœ…' if self.enable_gpt else 'âŒ'} (æ¬Šé‡: {self.weights['gpt']:.0%})")

    def _initialize_weights(self, weights: Optional[Dict[str, float]]) -> Dict[str, float]:
        """åˆå§‹åŒ–è©•åˆ†æ¬Šé‡"""
        if weights:
            return weights

        # æ ¹æ“šå•Ÿç”¨çš„è©•ä¼°å±¤ç´šè‡ªå‹•é…ç½®æ¬Šé‡
        if self.enable_semantic and self.enable_gpt:
            return {"keyword": 0.3, "semantic": 0.3, "gpt": 0.4}
        elif self.enable_semantic:
            return {"keyword": 0.5, "semantic": 0.5, "gpt": 0.0}
        elif self.enable_gpt:
            return {"keyword": 0.4, "semantic": 0.0, "gpt": 0.6}
        else:
            return {"keyword": 1.0, "semantic": 0.0, "gpt": 0.0}

    def _detect_columns(self):
        """è‡ªå‹•åµæ¸¬è³‡æ–™æ¬„ä½"""
        available_columns = self.df.columns.tolist()
        print(f"\nğŸ” åµæ¸¬åˆ°çš„æ¬„ä½: {available_columns}")

        # è·¨æŠ€è¡“æ¯”è¼ƒæ¨¡å¼
        if self.model_type == "cross":
            self.original_col = None
            self.optimized_col = None

            # å°‹æ‰¾å‘é‡åŸå§‹ç‰ˆ
            for col in available_columns:
                if 'å‘é‡' in col and ('åŸå§‹' in col or 'Original' in col):
                    self.original_col = col
                    break

            # å°‹æ‰¾æ™ºæ…§æ–‡æª”å½™æ•´ç‰ˆ
            for col in available_columns:
                if ('æ™ºæ…§' in col or 'æ–‡æª”' in col) and ('å½™æ•´' in col or 'Optimized' in col):
                    self.optimized_col = col
                    break

            self.model_name = "è·¨æŠ€è¡“æ¯”è¼ƒ"

            if not self.original_col or not self.optimized_col:
                raise ValueError(f"âŒ ç„¡æ³•æ‰¾åˆ°è·¨æŠ€è¡“æ¯”è¼ƒæ‰€éœ€çš„æ¬„ä½ã€‚å¯ç”¨æ¬„ä½: {available_columns}")

        elif self.model_type == "vector":
            # å‘é‡çŸ¥è­˜åº«æ¬„ä½åµæ¸¬
            self.original_col = None
            self.optimized_col = None

            for col in available_columns:
                if 'å‘é‡' in col and 'åŸå§‹' in col:
                    self.original_col = col
                elif 'å‘é‡' in col and 'å½™æ•´' in col:
                    self.optimized_col = col

            self.model_name = "å‘é‡çŸ¥è­˜åº«"

            if not self.original_col or not self.optimized_col:
                raise ValueError(f"âŒ ç„¡æ³•æ‰¾åˆ°å‘é‡çŸ¥è­˜åº«æ¬„ä½ã€‚å¯ç”¨æ¬„ä½: {available_columns}")

        else:  # smart_doc
            # æ™ºæ…§æ–‡æª”çŸ¥è­˜åº«æ¬„ä½åµæ¸¬
            self.original_col = None
            self.optimized_col = None

            for col in available_columns:
                if ('æ™ºæ…§' in col or 'æ–‡æª”' in col) and 'åŸå§‹' in col:
                    self.original_col = col
                elif ('æ™ºæ…§' in col or 'æ–‡æª”' in col) and 'å½™æ•´' in col:
                    self.optimized_col = col

            self.model_name = "æ™ºæ…§æ–‡æª”çŸ¥è­˜åº«"

            if not self.original_col or not self.optimized_col:
                raise ValueError(f"âŒ ç„¡æ³•æ‰¾åˆ°æ™ºæ…§æ–‡æª”çŸ¥è­˜åº«æ¬„ä½ã€‚å¯ç”¨æ¬„ä½: {available_columns}")

        print(f"âœ… ä½¿ç”¨æ¬„ä½ - åŸå§‹: {self.original_col}, å„ªåŒ–: {self.optimized_col}")

    # ==================== ç¬¬ä¸€å±¤ï¼šé—œéµè©åŒ¹é…è©•ä¼° ====================

    def extract_keywords(self, text: str) -> List[str]:
        """å¾æ‡‰å›ç­”è©å½™ä¸­æå–é—œéµè©"""
        if pd.isna(text):
            return []

        # ç§»é™¤ç·¨è™Ÿå’Œæ¨™é»ç¬¦è™Ÿ
        text = re.sub(r'\d+\.', '', text)
        text = re.sub(r'[ï¼š:ã€‚ï¼Œ,ã€\(\)]', ' ', text)

        keywords = []

        # ä¿ç•™å®Œæ•´çš„å°ˆæœ‰åè©
        special_terms = [
            "å·¥ä½œè¨±å¯è­‰", "æ–½å·¥è½„å€", "åŒ…å•†åç¨±", "ä½œæ¥­å…§å®¹",
            "æ‰¿åŒ…å•†ç¾å ´è² è²¬äºº", "å·¥å®‰æ¥­å‹™ä¸»ç®¡", "æ–½å·¥äººå“¡",
            "ç…™ç«ç®¡åˆ¶å€", "é›»ç„Š", "åˆ‡å‰²", "çƒ˜çƒ¤"
        ]

        for term in special_terms:
            if term in text:
                keywords.append(term)
                text = text.replace(term, " ")

        # ä½¿ç”¨ jieba åˆ†è©è™•ç†å‰©é¤˜æ–‡å­—
        words = jieba.cut(text)
        for word in words:
            if len(word.strip()) > 1 and word.strip() not in keywords:
                keywords.append(word.strip())

        return keywords

    def calculate_keyword_coverage(
        self,
        answer: str,
        keywords: List[str]
    ) -> Tuple[float, List[str], Dict]:
        """
        ç¬¬ä¸€å±¤è©•ä¼°ï¼šé—œéµè©åŒ¹é…è¦†è“‹ç‡

        è¿”å›:
            - coverage_score: è¦†è“‹ç‡åˆ†æ•¸ (0-100)
            - matched_keywords: åŒ¹é…åˆ°çš„é—œéµè©åˆ—è¡¨
            - details: è©³ç´°åˆ†ææ•¸æ“š
        """
        if pd.isna(answer) or not keywords:
            return 0.0, [], {"total": 0, "matched": 0, "missing": keywords}

        matched_keywords = []
        answer_lower = answer.lower()

        for keyword in keywords:
            if keyword.lower() in answer_lower:
                matched_keywords.append(keyword)
            elif self._is_similar_term(keyword, answer):
                matched_keywords.append(keyword)

        missing_keywords = [k for k in keywords if k not in matched_keywords]
        coverage_rate = len(matched_keywords) / len(keywords) if keywords else 0

        details = {
            "total_keywords": len(keywords),
            "matched_keywords": len(matched_keywords),
            "missing_keywords": len(missing_keywords),
            "missing_list": missing_keywords,
            "found_list": matched_keywords,
            "matched_ratio": coverage_rate
        }

        return coverage_rate * 100, matched_keywords, details

    def _is_similar_term(self, keyword: str, answer: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦æœ‰ç›¸ä¼¼è©å½™"""
        synonyms = {
            "åŒ…å•†": ["æ‰¿åŒ…å•†", "å» å•†", "æ‰¿æ”¬å•†"],
            "è² è²¬äºº": ["ä¸»ç®¡", "ç®¡ç†äºº", "è¯çµ¡äºº"],
            "å·¥å®‰": ["å®‰å…¨", "è·å®‰", "å·¥æ¥­å®‰å…¨"],
            "è¨±å¯è­‰": ["è¨±å¯", "è­‰æ˜", "æ ¸å‡†"],
        }

        answer_lower = answer.lower()
        for key, similar_terms in synonyms.items():
            if key in keyword:
                for term in similar_terms:
                    if term in answer_lower:
                        return True
        return False

    # ==================== ç¬¬äºŒå±¤ï¼šèªç¾©ç›¸ä¼¼åº¦è©•ä¼° ====================

    def calculate_semantic_similarity(
        self,
        reference_text: str,
        answer: str
    ) -> Tuple[float, Dict]:
        """
        ç¬¬äºŒå±¤è©•ä¼°ï¼šèªç¾©ç›¸ä¼¼åº¦åˆ†æ

        åƒæ•¸:
            reference_text: æ‡‰å›ç­”çš„è©å½™/åƒè€ƒæ–‡æœ¬
            answer: å¯¦éš›å›ç­”å…§å®¹

        è¿”å›:
            - similarity_score: èªç¾©ç›¸ä¼¼åº¦åˆ†æ•¸ (0-100)
            - details: è©³ç´°åˆ†ææ•¸æ“š
        """
        if not self.enable_semantic:
            return 0.0, {"error": "èªç¾©ç›¸ä¼¼åº¦åŠŸèƒ½æœªå•Ÿç”¨"}

        if pd.isna(answer) or pd.isna(reference_text):
            return 0.0, {"error": "ç©ºç™½å…§å®¹"}

        try:
            # è¨ˆç®— embeddingï¼ˆä¸è½‰ç‚º tensorï¼Œé¿å…è¨­å‚™å•é¡Œï¼‰
            embedding_ref = self.semantic_model.encode(
                reference_text,
                convert_to_tensor=False,
                device='cpu'
            )
            embedding_ans = self.semantic_model.encode(
                answer,
                convert_to_tensor=False,
                device='cpu'
            )

            # ä½¿ç”¨ numpy è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
            import numpy as np
            from numpy.linalg import norm

            # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
            similarity = np.dot(embedding_ref, embedding_ans) / (norm(embedding_ref) * norm(embedding_ans))

            # è½‰æ›ç‚º 0-100 åˆ†æ•¸
            similarity_score = max(0, min(100, float(similarity) * 100))

            details = {
                "raw_similarity": float(similarity),
                "normalized_score": similarity_score,
                "reference_length": len(reference_text),
                "answer_length": len(answer)
            }

            return similarity_score, details

        except Exception as e:
            print(f"âš ï¸ èªç¾©ç›¸ä¼¼åº¦è¨ˆç®—éŒ¯èª¤: {str(e)}")
            return 0.0, {"error": str(e)}

    # ==================== ç¬¬ä¸‰å±¤ï¼šGPT as a Judge è©•ä¼° ====================

    def gpt_as_judge(
        self,
        question: str,
        reference_keywords: str,
        answer: str
    ) -> Tuple[Dict[str, float], str]:
        """
        ç¬¬ä¸‰å±¤è©•ä¼°ï¼šGPT as a Judge å¤šç¶­åº¦è©•ä¼°

        åƒæ•¸:
            question: æ¸¬è©¦å•é¡Œ
            reference_keywords: æ‡‰å›ç­”çš„è©å½™
            answer: å¯¦éš›å›ç­”å…§å®¹

        è¿”å›:
            - scores: å¤šç¶­åº¦åˆ†æ•¸å­—å…¸
            - reasoning: è©•åˆ†ç†ç”±
        """
        if not self.enable_gpt:
            return {
                "relevance": 0,
                "completeness": 0,
                "accuracy": 0,
                "faithfulness": 0,
                "overall": 0
            }, "GPT è©•å¯©åŠŸèƒ½æœªå•Ÿç”¨"

        if pd.isna(answer):
            return {
                "relevance": 0,
                "completeness": 0,
                "accuracy": 0,
                "faithfulness": 0,
                "overall": 0
            }, "ç„¡å›ç­”å…§å®¹"

        try:
            prompt = f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ RAG ç³»çµ±è©•ä¼°å°ˆå®¶ã€‚è«‹è©•ä¼°ä»¥ä¸‹å›ç­”çš„å“è³ªã€‚

ã€å•é¡Œã€‘
{question}

ã€æ‡‰åŒ…å«çš„é—œéµè³‡è¨Šã€‘
{reference_keywords}

ã€å¯¦éš›å›ç­”ã€‘
{answer}

è«‹å¾ä»¥ä¸‹å››å€‹ç¶­åº¦è©•åˆ†ï¼ˆ0-100åˆ†ï¼‰ï¼š

1. **ç›¸é—œæ€§ (Relevance)**: å›ç­”æ˜¯å¦åˆ‡é¡Œã€æ˜¯å¦å›æ‡‰äº†å•é¡Œæ ¸å¿ƒ
2. **å®Œæ•´æ€§ (Completeness)**: æ˜¯å¦åŒ…å«äº†æ‰€æœ‰å¿…è¦çš„é—œéµè³‡è¨Š
3. **æº–ç¢ºæ€§ (Accuracy)**: è³‡è¨Šæ˜¯å¦æ­£ç¢ºã€ç„¡æ˜é¡¯éŒ¯èª¤
4. **å¿ å¯¦åº¦ (Faithfulness)**: æ˜¯å¦åŸºæ–¼åŸå§‹è³‡æ–™ï¼Œç„¡è™›æ§‹æˆ–éåº¦æ¨æ¸¬

è«‹ä»¥ JSON æ ¼å¼å›å‚³è©•åˆ†çµæœï¼š
{{
  "relevance": <0-100>,
  "completeness": <0-100>,
  "accuracy": <0-100>,
  "faithfulness": <0-100>,
  "overall": <0-100>,
  "reasoning": "ç°¡çŸ­èªªæ˜è©•åˆ†ç†ç”±ï¼ˆ2-3å¥è©±ï¼‰"
}}

æ³¨æ„ï¼šoverall æ˜¯å››å€‹ç¶­åº¦çš„å¹³å‡åˆ†æ•¸ã€‚"""

            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0,
                response_format={"type": "json_object"}
            )

            result = json.loads(response.choices[0].message.content)

            scores = {
                "relevance": result.get("relevance", 0),
                "completeness": result.get("completeness", 0),
                "accuracy": result.get("accuracy", 0),
                "faithfulness": result.get("faithfulness", 0),
                "overall": result.get("overall", 0)
            }

            reasoning = result.get("reasoning", "")

            return scores, reasoning

        except Exception as e:
            print(f"âŒ GPT è©•å¯©éŒ¯èª¤: {str(e)}")
            return {
                "relevance": 0,
                "completeness": 0,
                "accuracy": 0,
                "faithfulness": 0,
                "overall": 0
            }, f"è©•ä¼°å¤±æ•—: {str(e)}"

    # ==================== ç¶œåˆè©•ä¼°ç³»çµ± ====================

    def evaluate_answer(
        self,
        question: str,
        reference_keywords: str,
        answer: str
    ) -> Dict:
        """
        ç¶œåˆè©•ä¼°å–®å€‹å›ç­”ï¼ˆä¸‰å±¤è©•ä¼°ï¼‰

        è¿”å›å®Œæ•´çš„è©•ä¼°çµæœå­—å…¸
        """
        keywords = self.extract_keywords(reference_keywords)

        # ç¬¬ä¸€å±¤ï¼šé—œéµè©åŒ¹é…
        keyword_score, matched, keyword_details = self.calculate_keyword_coverage(answer, keywords)

        # ç¬¬äºŒå±¤ï¼šèªç¾©ç›¸ä¼¼åº¦
        semantic_score, semantic_details = (0.0, {})
        if self.enable_semantic:
            semantic_score, semantic_details = self.calculate_semantic_similarity(
                reference_keywords, answer
            )

        # ç¬¬ä¸‰å±¤ï¼šGPT è©•å¯©
        gpt_scores, gpt_reasoning = ({}, "")
        if self.enable_gpt:
            gpt_scores, gpt_reasoning = self.gpt_as_judge(
                question, reference_keywords, answer
            )

        # è¨ˆç®—ç¶œåˆè©•åˆ†
        final_score = (
            keyword_score * self.weights['keyword'] +
            semantic_score * self.weights['semantic'] +
            gpt_scores.get('overall', 0) * self.weights['gpt']
        )

        return {
            # ç¬¬ä¸€å±¤çµæœ
            "keyword_coverage": keyword_score,
            "matched_keywords": matched,
            "keyword_details": keyword_details,

            # ç¬¬äºŒå±¤çµæœ
            "semantic_similarity": semantic_score,
            "semantic_details": semantic_details,

            # ç¬¬ä¸‰å±¤çµæœ
            "gpt_scores": gpt_scores,
            "gpt_reasoning": gpt_reasoning,

            # ç¶œåˆçµæœ
            "final_score": final_score,
            "weights_used": self.weights.copy()
        }

    def evaluate_all(self) -> pd.DataFrame:
        """åŸ·è¡Œå®Œæ•´è©•ä¼° - è©•ä¼°æ‰€æœ‰å•é¡Œ"""
        print(f"\nğŸš€ é–‹å§‹è©•ä¼° {len(self.df)} å€‹å•é¡Œ...")

        # åˆå§‹åŒ–çµæœæ¬„ä½
        result_columns = {
            # åŸå§‹ç‰ˆæœ¬
            'KEYWORD_COVERAGE_ORIGINAL': 0.0,
            'SEMANTIC_SIMILARITY_ORIGINAL': 0.0,
            'GPT_OVERALL_ORIGINAL': 0.0,
            'FINAL_SCORE_ORIGINAL': 0.0,
            'MATCHED_KEYWORDS_ORIGINAL': "",
            'GPT_REASONING_ORIGINAL': "",
            'ANSWER_ORIGINAL': self.df[self.original_col],

            # å„ªåŒ–ç‰ˆæœ¬
            'KEYWORD_COVERAGE_OPTIMIZED': 0.0,
            'SEMANTIC_SIMILARITY_OPTIMIZED': 0.0,
            'GPT_OVERALL_OPTIMIZED': 0.0,
            'FINAL_SCORE_OPTIMIZED': 0.0,
            'MATCHED_KEYWORDS_OPTIMIZED': "",
            'GPT_REASONING_OPTIMIZED': "",
            'ANSWER_OPTIMIZED': self.df[self.optimized_col]
        }

        for col, default_val in result_columns.items():
            if col not in ['ANSWER_ORIGINAL', 'ANSWER_OPTIMIZED']:
                self.df[col] = default_val
            else:
                self.df[col] = default_val

        # é€è¡Œè©•ä¼°
        for idx, row in self.df.iterrows():
            if idx % 5 == 0:
                print(f"  é€²åº¦: {idx + 1}/{len(self.df)} ({(idx + 1) / len(self.df) * 100:.1f}%)")

            question = row['æ¸¬è©¦å•é¡Œ']
            reference_keywords = row['æ‡‰å›ç­”ä¹‹è©å½™']

            # è©•ä¼°åŸå§‹ç‰ˆæœ¬
            result_orig = self.evaluate_answer(
                question,
                reference_keywords,
                row[self.original_col]
            )

            self.df.at[idx, 'KEYWORD_COVERAGE_ORIGINAL'] = result_orig['keyword_coverage']
            self.df.at[idx, 'SEMANTIC_SIMILARITY_ORIGINAL'] = result_orig['semantic_similarity']
            self.df.at[idx, 'GPT_OVERALL_ORIGINAL'] = result_orig['gpt_scores'].get('overall', 0)
            self.df.at[idx, 'FINAL_SCORE_ORIGINAL'] = result_orig['final_score']
            self.df.at[idx, 'MATCHED_KEYWORDS_ORIGINAL'] = ', '.join(result_orig['matched_keywords'])
            self.df.at[idx, 'GPT_REASONING_ORIGINAL'] = result_orig['gpt_reasoning']

            # è©•ä¼°å„ªåŒ–ç‰ˆæœ¬
            result_opt = self.evaluate_answer(
                question,
                reference_keywords,
                row[self.optimized_col]
            )

            self.df.at[idx, 'KEYWORD_COVERAGE_OPTIMIZED'] = result_opt['keyword_coverage']
            self.df.at[idx, 'SEMANTIC_SIMILARITY_OPTIMIZED'] = result_opt['semantic_similarity']
            self.df.at[idx, 'GPT_OVERALL_OPTIMIZED'] = result_opt['gpt_scores'].get('overall', 0)
            self.df.at[idx, 'FINAL_SCORE_OPTIMIZED'] = result_opt['final_score']
            self.df.at[idx, 'MATCHED_KEYWORDS_OPTIMIZED'] = ', '.join(result_opt['matched_keywords'])
            self.df.at[idx, 'GPT_REASONING_OPTIMIZED'] = result_opt['gpt_reasoning']

        # è¨ˆç®—æ”¹å–„å¹…åº¦
        self.df['KEYWORD_IMPROVEMENT'] = (
            self.df['KEYWORD_COVERAGE_OPTIMIZED'] - self.df['KEYWORD_COVERAGE_ORIGINAL']
        )
        self.df['SEMANTIC_IMPROVEMENT'] = (
            self.df['SEMANTIC_SIMILARITY_OPTIMIZED'] - self.df['SEMANTIC_SIMILARITY_ORIGINAL']
        )
        self.df['GPT_IMPROVEMENT'] = (
            self.df['GPT_OVERALL_OPTIMIZED'] - self.df['GPT_OVERALL_ORIGINAL']
        )
        self.df['FINAL_IMPROVEMENT'] = (
            self.df['FINAL_SCORE_OPTIMIZED'] - self.df['FINAL_SCORE_ORIGINAL']
        )

        print("âœ… è©•ä¼°å®Œæˆï¼")
        return self.df

    def generate_summary_stats(self) -> Dict:
        """ç”Ÿæˆçµ±è¨ˆæ‘˜è¦"""
        stats = {
            'åŸå§‹ç‰ˆæœ¬': {
                'å¹³å‡é—œéµè©è¦†è“‹ç‡': self.df['KEYWORD_COVERAGE_ORIGINAL'].mean(),
                'å¹³å‡èªç¾©ç›¸ä¼¼åº¦': self.df['SEMANTIC_SIMILARITY_ORIGINAL'].mean(),
                'å¹³å‡GPTè©•åˆ†': self.df['GPT_OVERALL_ORIGINAL'].mean(),
                'å¹³å‡ç¶œåˆè©•åˆ†': self.df['FINAL_SCORE_ORIGINAL'].mean(),
                'é«˜åˆ†æ¯”ä¾‹(â‰¥80)': (self.df['FINAL_SCORE_ORIGINAL'] >= 80).sum() / len(self.df) * 100
            },
            'å½™æ•´å„ªåŒ–ç‰ˆæœ¬': {
                'å¹³å‡é—œéµè©è¦†è“‹ç‡': self.df['KEYWORD_COVERAGE_OPTIMIZED'].mean(),
                'å¹³å‡èªç¾©ç›¸ä¼¼åº¦': self.df['SEMANTIC_SIMILARITY_OPTIMIZED'].mean(),
                'å¹³å‡GPTè©•åˆ†': self.df['GPT_OVERALL_OPTIMIZED'].mean(),
                'å¹³å‡ç¶œåˆè©•åˆ†': self.df['FINAL_SCORE_OPTIMIZED'].mean(),
                'é«˜åˆ†æ¯”ä¾‹(â‰¥80)': (self.df['FINAL_SCORE_OPTIMIZED'] >= 80).sum() / len(self.df) * 100
            },
            'æ”¹å–„æ•ˆæœ': {
                'å¹³å‡é—œéµè©è¦†è“‹ç‡æå‡': self.df['KEYWORD_IMPROVEMENT'].mean(),
                'å¹³å‡èªç¾©ç›¸ä¼¼åº¦æå‡': self.df['SEMANTIC_IMPROVEMENT'].mean(),
                'å¹³å‡GPTè©•åˆ†æå‡': self.df['GPT_IMPROVEMENT'].mean(),
                'å¹³å‡ç¶œåˆè©•åˆ†æå‡': self.df['FINAL_IMPROVEMENT'].mean(),
                'é¡¯è‘—æ”¹å–„æ¯”ä¾‹(â‰¥10)': (self.df['FINAL_IMPROVEMENT'] >= 10).sum() / len(self.df) * 100,
                'æ•ˆæœé€€æ­¥æ¯”ä¾‹(<0)': (self.df['FINAL_IMPROVEMENT'] < 0).sum() / len(self.df) * 100
            },
            'è©•ä¼°é…ç½®': {
                'é—œéµè©æ¬Šé‡': self.weights['keyword'],
                'èªç¾©æ¬Šé‡': self.weights['semantic'],
                'GPTæ¬Šé‡': self.weights['gpt'],
                'èªç¾©ç›¸ä¼¼åº¦å•Ÿç”¨': self.enable_semantic,
                'GPTè©•å¯©å•Ÿç”¨': self.enable_gpt
            }
        }

        return stats

    def save_results(self, output_path: str):
        """ä¿å­˜è©•ä¼°çµæœ"""
        output_columns = ['åºè™Ÿ', 'æ¸¬è©¦è³‡æ–™', 'æ¸¬è©¦å•é¡Œ', 'æ‡‰å›ç­”ä¹‹è©å½™']

        # æ·»åŠ è©•åˆ†ç›¸é—œæ¬„ä½
        output_columns.extend([
            'KEYWORD_COVERAGE_ORIGINAL', 'SEMANTIC_SIMILARITY_ORIGINAL',
            'GPT_OVERALL_ORIGINAL', 'FINAL_SCORE_ORIGINAL',
            'KEYWORD_COVERAGE_OPTIMIZED', 'SEMANTIC_SIMILARITY_OPTIMIZED',
            'GPT_OVERALL_OPTIMIZED', 'FINAL_SCORE_OPTIMIZED',
            'KEYWORD_IMPROVEMENT', 'SEMANTIC_IMPROVEMENT',
            'GPT_IMPROVEMENT', 'FINAL_IMPROVEMENT',
            'MATCHED_KEYWORDS_ORIGINAL', 'MATCHED_KEYWORDS_OPTIMIZED'
        ])

        # å¦‚æœå•Ÿç”¨ GPTï¼Œæ·»åŠ æ¨ç†æ¬„ä½
        if self.enable_gpt:
            output_columns.extend(['GPT_REASONING_ORIGINAL', 'GPT_REASONING_OPTIMIZED'])

        output_df = self.df[[col for col in output_columns if col in self.df.columns]].copy()

        if output_path.lower().endswith('.csv'):
            output_df.to_csv(output_path, index=False, encoding='utf-8-sig')
        else:
            with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:
                output_df.to_excel(writer, sheet_name='è©•åˆ†çµæœ', index=False)

                workbook = writer.book
                worksheet = writer.sheets['è©•åˆ†çµæœ']

                # è¨­å®šæ¬„å¯¬
                worksheet.set_column('A:A', 8)
                worksheet.set_column('B:B', 20)
                worksheet.set_column('C:C', 40)
                worksheet.set_column('D:D', 50)
                worksheet.set_column('E:P', 15)

        print(f"âœ… è©•åˆ†çµæœå·²ä¿å­˜åˆ°: {output_path}")


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    # åŸºæœ¬ä½¿ç”¨ï¼ˆåƒ…é—œéµè©åŒ¹é… + èªç¾©ç›¸ä¼¼åº¦ï¼‰
    evaluator = RAGEvaluatorV2(
        'test_data/AIæŒ‡å°å“¡_æ¸¬è©¦è…³æœ¬_v2æ‹·è².xlsx',
        model_type='cross',
        enable_semantic=True,
        enable_gpt=False
    )

    results = evaluator.evaluate_all()
    evaluator.save_results(f'è©•ä¼°çµæœ_v2_{datetime.now().strftime("%Y%m%d_%H%M%S")}.xlsx')

    # é¡¯ç¤ºçµ±è¨ˆ
    print("\nğŸ“Š çµ±è¨ˆæ‘˜è¦:")
    stats = evaluator.generate_summary_stats()
    for category, metrics in stats.items():
        print(f"\n{category}:")
        for metric, value in metrics.items():
            if isinstance(value, (int, float)):
                print(f"  {metric}: {value:.2f}")
            else:
                print(f"  {metric}: {value}")
